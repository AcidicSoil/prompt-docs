{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Prompt Docs","text":"<p>A structured playbook for ideation \u2192 scaffold \u2192 implementation \u2192 refactor \u2192 testing \u2192 docs \u2192 release. Use the sidebar to explore, or jump straight into a workflow below.</p> <p>Get Started</p> <p>Browse Sections</p> <p>Contribute</p>"},{"location":"#quick-start","title":"Quick start","text":"<p>New Workflow!</p> <ul> <li>Sample workflow</li> <li>QA-ready_refactor-plan</li> <li>ops_apply</li> <li>ops_quality</li> </ul> Try these out first <ul> <li>Follow for successful prompting Sample workflow</li> <li>Need to refactor? Run first QA-ready_refactor-plan</li> <li>Then, Run second ops_apply</li> <li>If needed, run ops_quality</li> </ul> <p>First time here?</p> <ul> <li>Skim the 3 lanes below (Plan / Build / Ship).</li> <li>Use the search in the top-right.</li> <li>Every page is Markdown\u2014click Edit this page to propose improvements.</li> </ul> PlanBuildShip <ul> <li>Write a quick PRD \u2192 PRD generator</li> <li>Pick an architecture approach \u2192 ADR \u2013 new \u2022 Modular architecture</li> <li>Define logging &amp; SLOs \u2192 Logging strategy \u2022 SLO setup</li> </ul> <ul> <li>Bootstrap env &amp; CI \u2192 Env setup \u2022 DevOps automation</li> <li>Start coding prompts \u2192 Generate \u2022 Feature flags</li> <li>Review &amp; tighten \u2192 PR description \u2022 Audit</li> </ul> <ul> <li>Test coverage \u2192 Coverage guide</li> <li>Prepare release notes \u2192 Release notes (prepare)</li> <li>Versioning \u2192 Version proposal</li> </ul>"},{"location":"#whats-inside","title":"What\u2019s inside","text":"<ul> <li>Temp Prompts (organized) \u2014 curated, step-by-step:</li> <li>00 \u00b7 Ideation \u2192 Architecture, Design, Requirements</li> <li>10 \u00b7 Scaffold \u2192 CI setup, Conventions, Scaffold</li> <li>20 \u00b7 Implementation \u2192 Impl, Review, Spec-oriented</li> <li>30 \u00b7 Refactor \u2192 Refactor file, Perf eval</li> <li>40 \u00b7 Testing \u2192 Integration test, Flake fixes</li> <li>50 \u00b7 Docs \u2192 API docs (local)</li> <li> <p>60 \u00b7 Release \u2192 Changelog from commits, Post-release checks</p> </li> <li> <p>Temp Prompts (refactored) \u2014 same ideas, reworked as single-file flows:</p> </li> <li>Jump in: Action diagram, Prompt Optimizer, Scaffold (full-stack)</li> <li> <p>Docs helpers: Generate README, Docs 100%</p> </li> <li> <p>Shared &amp; Templates</p> </li> <li><code>_Shared</code> \u2192 TM overview, Reset strategy</li> <li><code>_Templates</code> \u2192 Instruction file, Prompt sequence generator</li> </ul>"},{"location":"#common-tasks","title":"Common tasks","text":"Plan a change (ADR + PRD checklist) <ol> <li>Start an ADR \u2192 ADR \u2013 new</li> <li>Draft PRD \u2192 PRD generator</li> <li>Stakeholder review \u2192 Planning process</li> </ol> Spin up a project scaffold <ul> <li>CI &amp; secrets \u2192 Secrets manager</li> <li>Monitoring &amp; SLOs \u2192 Monitoring setup \u2022 SLO setup</li> </ul> Run a crisp PR review <p>Use the trio: - PR description helper - Cross-check - Evidence capture</p>"},{"location":"#search-like-a-pro","title":"Search like a pro","text":"<ul> <li>Use filters in the search box (e.g. <code>flag lang:impl</code>), or just keywords like \u201crelease notes prepare\u201d.</li> <li>Prefer relative links when you add content (keeps GitHub Pages happy under <code>/prompt-docs/</code>).</li> <li>Add a short front-matter description on new pages to improve search snippets.</li> </ul> <p>Helpful deep links</p> <ul> <li>Spec-oriented helpers: Explain code \u2022 Changed files \u2022 Grep</li> <li>Testing: Integration test \u2022 Regression guard</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<ol> <li>Create a branch, add or edit Markdown under the appropriate section.</li> <li>Keep file names consistent with the existing pattern (e.g., <code>*.impl.md</code>, <code>*.review.md</code>).</li> <li>Submit a PR\u2014use the PR description helper.</li> <li>After merge, the site auto-deploys (using <code>mkdocs build</code> + Pages).</li> </ol> <p>Open a new issue Propose a change</p>"},{"location":"#release-versioning","title":"Release &amp; versioning","text":"<ul> <li>Draft notes \u2192 Release notes (prepare)</li> <li>Generate from commits \u2192 Changelog from commits</li> <li>Sanity pass \u2192 Verify</li> </ul>"},{"location":"#credits","title":"Credits","text":"<p>Built with MkDocs Material and maintained in the prompt-docs repo.</p>"},{"location":"temp-prompts-organized/00-ideation/architecture/adr-new.architecture/","title":"ADR \u2013 new","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Draft an Architecture Decision Record with pros/cons.\n\n1. Gather context by inspecting `README.md` for the project context.\n2. Draft a concise ADR including Context, Decision, Status, Consequences. Title: &lt;args&gt;.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Draft an Architecture Decision Record with pros/cons.\n- Highlight workflow triggers, failing jobs, and proposed fixes.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\nsrc/example.ts\n\nExpected Output:\n\n- Actionable summary aligned with the output section.\n</code></pre>"},{"location":"temp-prompts-organized/00-ideation/architecture/logging-strategy.architecture/","title":"Logging strategy","text":"<pre><code>phase: \"P7 Release &amp; Ops\"\ngate: \"Release Gate\"\nstatus: \"logging guardrails ready for canary/production checks; coordinate with P4 Frontend UX for client telemetry.\"\nprevious:\n\n- \"/monitoring-setup\"\n- \"/slo-setup\"\nnext:\n- \"/audit\"\n- \"/error-analysis\"\n\n---\n\n# Logging Strategy\n\nTrigger: /logging-strategy\n\nPurpose: Add or remove diagnostic logging cleanly with levels and privacy in mind.\n\n## Steps\n\n1. Identify hotspots from recent failures.\n2. Insert structured logs with contexts and correlation IDs.\n3. Remove noisy or PII-leaking logs.\n4. Document log levels and sampling in `OBSERVABILITY.md`.\n\n## Output format\n\n- Diff hunks and a short guideline section.\n</code></pre>"},{"location":"temp-prompts-organized/00-ideation/architecture/modular-architecture.architecture/","title":"Modular architecture","text":"<pre><code>phase: \"P2 App Scaffold &amp; Contracts\"\ngate: \"Test Gate lite\"\nstatus: \"boundaries documented and lint/build scripts still pass; revisit during P4 Frontend UX for UI seams.\"\nprevious:\n\n- \"/openapi-generate\"\nnext:\n- \"/db-bootstrap\"\n- \"/ui-screenshots\"\n- \"/design-assets\"\n\n---\n\n# Modular Architecture\n\nTrigger: /modular-architecture\n\nPurpose: Enforce modular boundaries and clear external interfaces.\n\n## Steps\n\n1. Identify services/modules and their public contracts.\n2. Flag cross-module imports and circular deps.\n3. Propose boundaries, facades, and internal folders.\n4. Add \"contract tests\" for public APIs.\n\n## Output format\n\n- Diagram-ready list of modules and edges, plus diffs.\n</code></pre>"},{"location":"temp-prompts-organized/00-ideation/architecture/stack-evaluation.architecture/","title":"Stack evaluation","text":"<pre><code>---\nphase: \"P1 Plan &amp; Scope\"\ngate: \"Scope Gate\"\nstatus: \"record recommended stack and top risks before building.\"\nprevious:\n  - \"/scope-control\"\nnext:\n  - \"/scaffold-fullstack\"\n  - \"/api-contract\"\n---\n\n# Stack Evaluation\n\nTrigger: /stack-evaluation\n\nPurpose: Evaluate language/framework choices relative to AI familiarity and repo goals.\n\n## Steps\n\n1. Detect current stack and conventions.\n2. List tradeoffs: maturity, tooling, available examples, hiring, and AI training coverage.\n3. Recommend stay-or-switch with migration outline if switching.\n\n## Output format\n\n- Decision memo with pros/cons and next steps.\n</code></pre>"},{"location":"temp-prompts-organized/00-ideation/design/action-diagram.design/","title":"Action diagram","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Explain workflow triggers and dependencies as a diagram\u2011ready outline.\n\n1. Gather context by inspecting `.github/workflows`.\n2. Explain workflow triggers and dependencies as a diagram\u2011ready outline.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Explain workflow triggers and dependencies as a diagram\u2011ready outline.\n- Organize details under clear subheadings so contributors can scan quickly.\n- List nodes and edges to make diagram creation straightforward.\n- Highlight workflow triggers, failing jobs, and proposed fixes.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n## Nodes\n\n- build\n- deploy\n\n## Edges\n\n- push -&gt; build\n- build -&gt; deploy\n</code></pre>"},{"location":"temp-prompts-organized/00-ideation/design/api-contract.design/","title":"API contract","text":"<pre><code>---\nphase: \"P2 App Scaffold &amp; Contracts\"\ngate: \"Test Gate lite\"\nstatus: \"contract checked into repo with sample generation running cleanly.\"\nprevious:\n  - \"/scaffold-fullstack\"\nnext:\n  - \"/openapi-generate\"\n  - \"/modular-architecture\"\n---\n\n# API Contract\n\nTrigger: /api-contract \"&lt;feature or domain&gt;\"\n\nPurpose: Author an initial OpenAPI 3.1 or GraphQL SDL contract from requirements.\n\n**Steps:**\n\n1. Parse inputs and existing docs. If REST, prefer OpenAPI 3.1 YAML; if GraphQL, produce SDL.\n2. Define resources, operations, request/response schemas, error model, auth, and rate limit headers.\n3. Add examples for each endpoint or type. Include pagination and filtering conventions.\n4. Save to `apis/&lt;domain&gt;/openapi.yaml` or `apis/&lt;domain&gt;/schema.graphql`.\n5. Emit changelog entry `docs/api/CHANGELOG.md` with rationale and breaking-change flags.\n\n**Output format:**\n\n- `Contract Path`, `Design Notes`, and a fenced code block with the spec body.\n\n**Examples:**\n\n- `/api-contract \"accounts &amp; auth\"` \u2192 `apis/auth/openapi.yaml` with OAuth 2.1 flows.\n\n**Notes:**\n\n- Follow JSON:API style for REST unless caller specifies otherwise. Include `429` and `5xx` models.\n</code></pre>"},{"location":"temp-prompts-organized/00-ideation/design/design-assets.design/","title":"Design assets","text":"<pre><code>---\nphase: \"P4 Frontend UX\"\ngate: \"Accessibility checks queued\"\nstatus: \"ensure assets support design review.\"\nprevious:\n  - \"/modular-architecture\"\nnext:\n  - \"/ui-screenshots\"\n  - \"/logging-strategy\"\n---\n\n# Design Assets\n\nTrigger: /design-assets\n\nPurpose: Generate favicons and small design snippets from product brand.\n\n## Steps\n\n1. Extract brand colors and name from README or config.\n2. Produce favicon set, social preview, and basic UI tokens.\n3. Document asset locations and references.\n\n## Output format\n\n- Asset checklist and generation commands.\n</code></pre>"},{"location":"temp-prompts-organized/00-ideation/design/ui-screenshots.design/","title":"UI screenshots","text":"<pre><code>---\nphase: \"P4 Frontend UX\"\ngate: \"Accessibility checks queued\"\nstatus: \"capture UX issues and backlog fixes.\"\nprevious:\n  - \"/design-assets\"\n  - \"/modular-architecture\"\nnext:\n  - \"/logging-strategy\"\n  - \"/e2e-runner-setup\"\n---\n\n# UI Screenshots\n\nTrigger: /ui-screenshots\n\nPurpose: Analyze screenshots for UI bugs or inspiration and propose actionable UI changes.\n\n## Steps\n\n1. Accept screenshot paths or links.\n2. Describe visual hierarchy, spacing, contrast, and alignment issues.\n3. Output concrete CSS or component changes.\n\n## Output format\n\n- Issue list and code snippets to fix visuals.\n</code></pre>"},{"location":"temp-prompts-organized/00-ideation/requirements/plan-delta.requirements/","title":"Plan delta","text":"<pre><code># plan-delta\n\nTrigger: /plan-delta\n\nPurpose: Orchestrate mid-project planning deltas on an existing task graph with history preservation, lineage, and readiness recalculation.\n\nSteps:\n\n1. Discover repository context:\n   1. Detect tasks file path: prefer `tasks.json`; else search `**/tasks.json`.\n   2. Detect latest plan doc: prefer `PRD.md` or `docs/PRD.md`; else `**/*(prd|spec|plan)*.md`.\n2. Snapshot:\n   1. Create `./artifacts/` if missing.\n   2. Copy the current tasks file to `./artifacts/tasks-$(date +%Y%m%d-%H%M%S).json` using: `cp -f &lt;tasks.json&gt; ./artifacts/tasks-$(date +%Y%m%d-%H%M%S).json`.\n3. Input collection:\n   1. Read new objectives, constraints, and findings from the user input or provided delta text.\n   2. Parse selection rules to choose mode: **Continue**, **Hybrid Rebaseline**, or **Full Rebaseline**.\n4. Delta Doc generation:\n   1. Create `./artifacts/delta-$(date +%Y%m%d-%H%M%S).md` containing sections:\n      - Objectives (new)\n      - Constraints (new)\n      - Impacts\n      - Decisions\n      - Evidence log (sources, dates, links)\n5. Task graph update:\n   1. Never alter historical states `done|in_progress|blocked` of existing tasks.\n   2. Do not reuse IDs. For any replaced task, set `superseded_by` on the old task and include its ID in the new task's `supersedes[]`.\n   3. Add `source_doc`, `lineage[]` on all new or changed tasks.\n   4. Create new tasks only for new or changed work. Link predecessors via `dependencies` or `relations`.\n   5. Keep deprecated tasks in graph with `status: \"deprecated\"` and a `reason`.\n6. Graph maintenance:\n   1. Recompute dependency order and validate acyclicity.\n   2. Flag contradictions or invalidated edges as `blocked` with a machine-readable `blocked_reason`.\n   3. Bubble critical-path tasks to the active frontier by recomputing earliest-start and slack.\n7. Readiness and selection:\n   1. Implement `ready/next()` over the graph: select tasks with all dependencies `done` and not `blocked`.\n   2. Produce a short readiness report grouped by `ready | blocked | deprecated`.\n8. Outputs:\n   1. Write the updated tasks file in-place, preserving formatting where possible.\n   2. Persist the Delta Doc under `./artifacts/`.\n   3. Emit decision hooks: one line per change stating what it enables.\n9. Termination:\n   - Stop when all deltas are merged and readiness recalculated, or when a prerequisite cannot be resolved with available evidence.\n\nOutput format:\n\n- Produce three artifacts:\n  1. **Updated tasks file**: valid JSON. Preserve existing fields. Append only the new or changed tasks and relations. Do not mutate historical statuses.\n  2. **Delta document**: Markdown with the exact headings `# Delta`, `## Objectives`, `## Constraints`, `## Impacts`, `## Decisions`, `## Evidence`.\n  3. **Readiness report**: Plain text with sections `READY`, `BLOCKED`, `DEPRECATED`. Each item as `- &lt;id&gt; &lt;title&gt;`; blocked items add `[reason=&lt;code&gt;]`.\n- Print **Decision hooks** as lines starting with `HOOK: &lt;id&gt; enables &lt;capability&gt;`.\n\nExamples:\n\n- Input \u2192\n\n  ```\n  Mode: Continue\n  New objectives: add offline export for tasks\n  Constraints: no DB migrations\n  Findings: existing export lib supports JSON only\n  ```\n\n  Output \u2192\n  - Updated `tasks.json` with new task `T-342` { title: \"Add CSV export\", dependencies: [\"T-120\"], source_doc: \"delta-20250921.md\", lineage: [\"T-120\"], supersedes: [] }.\n  - `artifacts/delta-20250921-160500.md` populated with objectives, constraints, impacts, decisions, evidence.\n  - Readiness report lists `T-342` under READY if deps done.\n\n- Input \u2192\n\n  ```\n  Mode: Hybrid Rebaseline\n  Changes: ~30% of scope affected by auth provider swap\n  ```\n\n  Output \u2192\n  - Minor-plan version bump recorded in Delta Doc.\n  - New tasks added for provider swap; prior tasks kept with `deprecated` or `blocked` and lineage links.\n\nNotes:\n\n- Never write outside the repo. Keep artifacts in `./artifacts/`.\n- Evidence log entries include `source`, `date`, `summary`, and optional `link`.\n- Selection rules: Continue (&lt;20% change), Hybrid (20\u201340%), Full (&gt;40% or goals/KPIs/architecture pivot).\n- If inputs are insufficient, emit a TERMINATION note with missing evidence keys.\n</code></pre>"},{"location":"temp-prompts-organized/00-ideation/requirements/planning-process.requirements/","title":"Planning process","text":"<pre><code>---\nphase: \"P1 Plan &amp; Scope\"\ngate: \"Scope Gate\"\nstatus: \"confirm problem, users, Done criteria, and stack risks are logged.\"\nprevious:\n  - \"Preflight Docs (AGENTS baseline)\"\nnext:\n  - \"/scope-control\"\n  - \"/stack-evaluation\"\n---\n\n# Planning Process\n\nTrigger: /planning-process\n\nPurpose: Draft, refine, and execute a feature plan with strict scope control and progress tracking.\n\n## Steps\n\n1. If no plan file exists, create `PLAN.md`. If it exists, load it.\n2. Draft sections: **Goal**, **User Story**, **Milestones**, **Tasks**, **Won't do**, **Ideas for later**, **Validation**, **Risks**.\n3. Trim bloat. Convert vague bullets into testable tasks with acceptance criteria.\n4. Tag each task with an owner and estimate. Link to files or paths that will change.\n5. Maintain two backlogs: **Won't do** (explicit non-goals) and **Ideas for later** (deferrable work).\n6. Mark tasks done after tests pass. Append commit SHAs next to completed items.\n7. After each milestone: run tests, update **Validation**, then commit `PLAN.md`.\n\n## Output format\n\n- Update or create `PLAN.md` with the sections above.\n- Include a checklist for **Tasks**. Keep lines under 100 chars.\n\n## Examples\n**Input**: \"Add OAuth login\"\n\n**Output**:\n\n- Goal: Let users sign in with Google.\n- Tasks: [ ] add Google client, [ ] callback route, [ ] session, [ ] E2E test.\n- Won't do: org SSO.\n- Ideas for later: Apple login.\n\n## Notes\n\n- Planning only. No code edits.\n- Assume a Git repo with test runner available.\n</code></pre>"},{"location":"temp-prompts-organized/00-ideation/requirements/prd-generator.requirements/","title":"PRD generator","text":"<pre><code># PRD Generator\nTrigger: /prd-generate\nPurpose: Produce a complete `prd.txt` in the exact section order, headers, and tone of the inline example PRD using only the repository README and visible link texts.\nSteps:\n\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; Updated upstream\n1. Read `README.md` at repo root; do not fetch external links.\n2. Extract: product name, problem, target users, value, scope, constraints, features, flows, integrations, data, non-functional needs, risks.\n3. If links exist, include their visible text or titles only as contextual hints.\n4. Fill gaps with conservative assumptions to keep the PRD complete; collect assumptions for the Appendix.\n5. Enforce strict structure identical to the example PRD\u2019s top-level headers and order.\n6. For each core feature, include What, Why, High-level How, and Acceptance criteria.\n7. In Technical Architecture, document optional platform-specific features and required fallbacks; mirror related risks.\n8. In Development Roadmap, group by phases (MVP and later); include acceptance criteria; exclude timelines.\n9. In Logical Dependency Chain, order from foundations to visible value; keep items atomic.\n10. Run an internal consistency check: features appear in roadmap; risks reflect platform and data concerns; all sections non-empty.\n11. Output only the final `prd.txt` content starting with `# Overview` and ending with `# Appendix`.\nOutput format:\n\n- Plain text PRD starting with `# Overview` and ending with `# Appendix`.\n- No preamble, no postscript, no meta commentary.\nNotes:\n- Reject generation if `README.md` is missing.\n- Do not browse external sources.\n- Derived from example_prd.txt, extracted summaries only; secrets redacted.\n=======\nOutput a plain-text file named `prd.txt` containing **only** these sections in this order (separated by one blank line):\n# Overview\n# Core Features\n# User Experience\n# Technical Architecture\n# Development Roadmap\n# Logical Dependency Chain\n# Risks and Mitigations\n# Appendix\n\n**Output Format**\n\n- `# Overview`: $3\n- `# Core Features`: Each includes *What*, *Why*, *High-level How*, and BDD criteria:\n  `Given ...`\n  `When ...`\n  `Then ...`\n- `# User Experience`: Personas, key flows, UI/UX, accessibility\n- `# Technical Architecture`: Components, data models, APIs/integrations, infrastructure, NFRs\n- `# Development Roadmap`: MVP and Future Enhancements with acceptance criteria (no dates)\n- `# Logical Dependency Chain`: Work ordering for foundations, earliest front end, extensible units\n- `# Risks and Mitigations`: Each includes *Description*, *Likelihood*, *Impact*, *Mitigation*\n- `# Appendix`:\n  \u2022 Assumptions (bulleted)\n  \u2022 Research findings from $1\n  \u2022 Context notes (`- &lt;visible text&gt; \u2014 inferred topic`)\n  \u2022 Technical specs\n\n**Validation Checks**\n\n- Headers present and ordered\n- All BDD criteria included for features/fallbacks\n- Risks include likelihood and impact\n- No URLs/secrets; exactly one blank line between sections\n- $1 contains **only** visible link text (no external browsing)\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; Stashed changes\n</code></pre>"},{"location":"temp-prompts-organized/00-ideation/requirements/scope-control.requirements/","title":"Scope control","text":"<pre><code>---\nphase: \"P1 Plan &amp; Scope\"\ngate: \"Scope Gate\"\nstatus: \"Done criteria, scope lists, and stack choices are committed.\"\nprevious:\n  - \"/planning-process\"\nnext:\n  - \"/stack-evaluation\"\n  - \"/scaffold-fullstack\"\n---\n\n# Scope Control\n\nTrigger: /scope-control\n\nPurpose: Enforce explicit scope boundaries and maintain \"won't do\" and \"ideas for later\" lists.\n\n## Steps\n\n1. Parse `PLAN.md` or create it if absent.\n2. For each open task, confirm linkage to the current milestone.\n3. Detect off-scope items and move them to **Won't do** or **Ideas for later** with rationale.\n4. Add a \"Scope Gate\" checklist before merging.\n\n## Output format\n\n- Patch to `PLAN.md` showing changes in sections and checklists.\n\n## Examples\nInput: off-scope request \"Add email templates\" during OAuth feature.\nOutput: Move to **Ideas for later** with reason \"Not needed for OAuth MVP\".\n\n## Notes\n\n- Never add new scope without recording tradeoffs.\n</code></pre>"},{"location":"temp-prompts-organized/10-scaffold/ci-setup/devops-automation.ci-setup/","title":"DevOps automation","text":"<pre><code>---\nphase: \"P6 CI/CD &amp; Env\"\ngate: \"Review Gate\"\nstatus: \"CI pipeline codified, rollback steps rehearsed.\"\nprevious:\n  - \"/version-control-guide\"\nnext:\n  - \"/env-setup\"\n  - \"/secrets-manager-setup\"\n  - \"/iac-bootstrap\"\n---\n\n# DevOps Automation\n\nTrigger: /devops-automation\n\nPurpose: Configure servers, DNS, SSL, CI/CD at a pragmatic level.\n\n## Steps\n\n1. Inspect repo for IaC or deploy scripts.\n2. Generate Terraform or Docker Compose templates if missing.\n3. Propose CI workflows for tests, builds, and deploys.\n4. Provide runbooks for rollback.\n\n## Output format\n\n- Infra plan with checkpoints and secrets placeholders.\n</code></pre>"},{"location":"temp-prompts-organized/10-scaffold/ci-setup/env-setup.ci-setup/","title":"Env setup","text":"<pre><code>---\nphase: \"P6 CI/CD &amp; Env\"\ngate: \"Review Gate\"\nstatus: \"environment schemas enforced and CI respects strict loading.\"\nprevious:\n  - \"/devops-automation\"\nnext:\n  - \"/secrets-manager-setup\"\n  - \"/iac-bootstrap\"\n---\n\n# Env Setup\n\nTrigger: /env-setup\n\nPurpose: Create .env.example, runtime schema validation, and per-env overrides.\n\n**Steps:**\n\n1. Scan repo for `process.env` usage and collected keys.\n2. Emit `.env.example` with comments and safe defaults.\n3. Add runtime validation via `zod` or `envsafe` in `packages/config`.\n4. Document `development`, `staging`, `production` precedence and loading order.\n\n**Output format:** `.env.example` content block and `config/env.ts` snippet.\n\n**Examples:** `/env-setup`.\n\n**Notes:** Do not include real credentials. Enforce `STRICT_ENV=true` in CI.\n</code></pre>"},{"location":"temp-prompts-organized/10-scaffold/ci-setup/monitoring-setup.ci-setup/","title":"Monitoring setup","text":"<pre><code>---\nphase: \"P7 Release &amp; Ops\"\ngate: \"Release Gate\"\nstatus: \"observability baselines ready before rollout.\"\nprevious:\n  - \"/version-proposal\"\nnext:\n  - \"/slo-setup\"\n  - \"/logging-strategy\"\n---\n\n# Monitoring Setup\n\nTrigger: /monitoring-setup\n\nPurpose: Bootstrap logs, metrics, and traces with dashboards per domain.\n\n**Steps:**\n\n1. Choose stack: OpenTelemetry \u2192 Prometheus/Grafana, or vendor.\n2. Instrument web and api for request latency, error rate, throughput, and core domain metrics.\n3. Provide default dashboards JSON and alert examples.\n\n**Output format:** instrumentation checklist and dashboard links/paths.\n\n**Examples:** `/monitoring-setup`.\n\n**Notes:** Avoid high\u2011cardinality labels. Sample traces selectively in prod.\n</code></pre>"},{"location":"temp-prompts-organized/10-scaffold/ci-setup/secrets-manager-setup.ci-setup/","title":"Secrets manager","text":"<pre><code>---\nphase: \"P6 CI/CD &amp; Env\"\ngate: \"Review Gate\"\nstatus: \"secret paths mapped and least-privilege policies drafted.\"\nprevious:\n  - \"/env-setup\"\nnext:\n  - \"/iac-bootstrap\"\n  - \"/owners\"\n---\n\n# Secrets Manager Setup\n\nTrigger: /secrets-manager-setup &lt;provider&gt;\n\nPurpose: Provision a secrets store and map application variables to it.\n\n**Steps:**\n\n1. Choose provider: 1Password, Doppler, AWS Secrets Manager, GCP Secret Manager, Vault.\n2. Define secret names and scopes. Generate read paths for web and api.\n3. Add dev bootstrap instructions and CI access policy docs.\n\n**Output format:** mapping table `ENV_VAR \u2192 provider path` and bootstrap steps.\n\n**Examples:** `/secrets-manager-setup doppler`.\n\n**Notes:** Never echo secret values. Include rotation policy.\n</code></pre>"},{"location":"temp-prompts-organized/10-scaffold/ci-setup/slo-setup.ci-setup/","title":"SLO setup","text":"<pre><code>---\nphase: \"P7 Release &amp; Ops\"\ngate: \"Release Gate\"\nstatus: \"SLOs and alerts reviewed before production rollout.\"\nprevious:\n  - \"/monitoring-setup\"\nnext:\n  - \"/logging-strategy\"\n  - \"/audit\"\n---\n\n# SLO Setup\n\nTrigger: /slo-setup\n\nPurpose: Define Service Level Objectives, burn alerts, and runbooks.\n\n**Steps:**\n\n1. Choose SLI/metrics per user journey. Define SLO targets and error budgets.\n2. Create burn alerts (fast/slow) and link to runbooks.\n3. Add `SLO.md` with rationale and review cadence.\n\n**Output format:** SLO table and alert rules snippet.\n\n**Examples:** `/slo-setup`.\n\n**Notes:** Tie SLOs to deploy gates and incident severity.\n</code></pre>"},{"location":"temp-prompts-organized/10-scaffold/conventions/version-control-guide.conventions/","title":"Version control guide","text":"<pre><code>---\nphase: \"P6 CI/CD &amp; Env\"\ngate: \"Review Gate\"\nstatus: \"clean diff, CI green, and approvals ready.\"\nprevious:\n  - \"/regression-guard\"\nnext:\n  - \"/devops-automation\"\n  - \"/env-setup\"\n---\n\n# Version Control Guide\n\nTrigger: /version-control-guide\n\nPurpose: Enforce clean incremental commits and clean-room re-implementation when finalizing.\n\n## Steps\n\n1. Start each feature from a clean branch: `git switch -c &lt;feat&gt;`.\n2. Commit in vertical slices with passing tests: `git add -p &amp;&amp; git commit`.\n3. When solution is proven, recreate a minimal clean diff: stash or copy results, reset, then apply only the final changes.\n4. Use `git revert` for bad commits instead of force-pushing shared branches.\n\n## Output format\n\n- Checklist plus suggested commands for the current repo state.\n\n## Examples\n\n- Convert messy spike into three commits: setup, feature, tests.\n\n## Notes\n\n- Never modify remote branches without confirmation.\n</code></pre>"},{"location":"temp-prompts-organized/10-scaffold/scaffold/auth.scaffold/","title":"Auth","text":"<pre><code>---\nphase: \"P3 Data &amp; Auth\"\ngate: \"Migration dry-run\"\nstatus: \"auth flows threat-modeled and test accounts wired.\"\nprevious:\n  - \"/migration-plan\"\nnext:\n  - \"/modular-architecture\"\n  - \"/ui-screenshots\"\n  - \"/e2e-runner-setup\"\n---\n\n# Auth Scaffold\n\nTrigger: /auth-scaffold &lt;oauth|email|oidc&gt;\n\nPurpose: Scaffold auth flows, routes, storage, and a basic threat model.\n\n**Steps:**\n\n1. Select provider (OAuth/OIDC/email) and persistence for sessions.\n2. Generate routes: login, callback, logout, session refresh.\n3. Add CSRF, state, PKCE where applicable. Include secure cookie flags.\n4. Document threat model: replay, fixation, token leakage, SSRF on callbacks.\n5. Wire to frontend with protected routes and user context.\n\n**Output format:** route list, config keys, and mitigations table.\n\n**Examples:** `/auth-scaffold oauth` \u2192 NextAuth/Passport/Custom adapter plan.\n\n**Notes:** Never print real secrets. Use placeholders in `.env.example`.\n</code></pre>"},{"location":"temp-prompts-organized/10-scaffold/scaffold/db-bootstrap.scaffold/","title":"DB bootstrap","text":"<pre><code>---\nphase: \"P3 Data &amp; Auth\"\ngate: \"Migration dry-run\"\nstatus: \"migrations apply/rollback cleanly with seeds populated.\"\nprevious:\n  - \"/modular-architecture\"\nnext:\n  - \"/migration-plan\"\n  - \"/auth-scaffold\"\n---\n\n# DB Bootstrap\n\nTrigger: /db-bootstrap &lt;postgres|mysql|sqlite|mongodb&gt;\n\nPurpose: Pick a database, initialize migrations, local compose, and seed scripts.\n\n**Steps:**\n\n1. Create `db/compose.yaml` for local dev (skip for sqlite).\n2. Choose ORM/driver (Prisma or Drizzle for SQL). Add migration config.\n3. Create `prisma/schema.prisma` or `drizzle/*.ts` with baseline tables (users, sessions, audit_log).\n4. Add `pnpm db:migrate`, `db:reset`, `db:seed` scripts. Write seed data for local admin user.\n5. Update `.env.example` with `DATABASE_URL` and test connection script.\n\n**Output format:** Migration plan list and generated file paths.\n\n**Examples:** `/db-bootstrap postgres` \u2192 Prisma + Postgres docker-compose.\n\n**Notes:** Avoid destructive defaults; provide `--preview-feature` warnings if relevant.\n</code></pre>"},{"location":"temp-prompts-organized/10-scaffold/scaffold/fullstack.scaffold/","title":"Full-stack","text":"<pre><code>---\nphase: \"P2 App Scaffold &amp; Contracts\"\ngate: \"Test Gate lite\"\nstatus: \"ensure lint/build scripts execute on the generated scaffold.\"\nprevious:\n  - \"/stack-evaluation\"\nnext:\n  - \"/api-contract\"\n  - \"/openapi-generate\"\n  - \"/modular-architecture\"\n---\n\n# Scaffold Full\u2011Stack App\n\nTrigger: /scaffold-fullstack &lt;stack&gt;\n\nPurpose: Create a minimal, production-ready monorepo template with app, API, tests, CI seeds, and infra stubs.\n\n**Steps:**\n\n1. Read repository context: `git rev-parse --is-inside-work-tree`.\n2. If repo is empty, initialize: `git init -b main` and create `.editorconfig`, `.gitignore`, `README.md`.\n3. For `&lt;stack&gt;` derive presets (examples):\n   - `ts-next-express-pg`: Next.js app, Express API, Prisma + PostgreSQL, Playwright, pnpm workspaces.\n   - `ts-vite-fastify-sqlite`: Vite + React app, Fastify API, Drizzle + SQLite.\n4. Create workspace layout:\n   - root: `package.json` with `pnpm` workspaces, `tsconfig.base.json`, `eslint`, `prettier`.\n   - apps/web, apps/api, packages/ui, packages/config.\n5. Add scripts:\n   - root: `dev`, `build`, `lint`, `typecheck`, `test`, `e2e`, `format`.\n   - web: Next/Vite scripts. api: dev with ts-node or tsx.\n6. Seed CI files: `.github/workflows/ci.yml` with jobs [lint, typecheck, test, build, e2e] and artifact uploads.\n7. Add example routes:\n   - web: `/health` page. api: `GET /health` returning `{ ok: true }`.\n8. Write docs to `README.md`: how to run dev, test, build, and env variables.\n9. Stage files, but do not commit. Output a tree and next commands.\n\n**Output format:**\n\n- Title line: `Scaffold created: &lt;stack&gt;`\n- Sections: `Repo Tree`, `Next Steps`, `CI Seeds`.\n- Include a fenced code block of the `tree` and sample scripts.\n\n**Examples:**\n\n- **Input:** `/scaffold-fullstack ts-next-express-pg`\n  **Output:** Summary + tree with `apps/web`, `apps/api`, `packages/ui`.\n- **Input:** `/scaffold-fullstack ts-vite-fastify-sqlite`\n  **Output:** Summary + tree + Drizzle config.\n\n**Notes:**\n\n- Assume pnpm and Node 20+. Do not run package installs automatically; propose commands instead.\n- Respect existing files; avoid overwriting without explicit confirmation.\n</code></pre>"},{"location":"temp-prompts-organized/10-scaffold/scaffold/iac-bootstrap.scaffold/","title":"IaC bootstrap","text":"<pre><code>---\nphase: \"P6 CI/CD &amp; Env\"\ngate: \"Review Gate\"\nstatus: \"IaC applied in staging with drift detection configured.\"\nprevious:\n  - \"/secrets-manager-setup\"\nnext:\n  - \"/owners\"\n  - \"/review\"\n---\n\n# IaC Bootstrap\n\nTrigger: /iac-bootstrap &lt;aws|gcp|azure|fly|render&gt;\n\nPurpose: Create minimal Infrastructure-as-Code for the chosen platform plus CI hooks.\n\n**Steps:**\n\n1. Select tool (Terraform, Pulumi). Initialize backend and state.\n2. Define stacks for `preview`, `staging`, `prod`. Add outputs (URLs, connection strings).\n3. Add CI jobs: plan on PR, apply on main with manual approval.\n4. Document rollback and drift detection.\n\n**Output format:** stack diagram, file list, CI snippets.\n\n**Examples:** `/iac-bootstrap aws`.\n\n**Notes:** Prefer least privilege IAM and remote state with locking.\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/impl/commit.impl/","title":"Commit","text":"<p><pre><code>---\nphase: \"P6 CI/CD &amp; Env\"\ngate: \"Review Gate\"\nstatus: \"clean diff, CI green, and approvals ready.\"\nprevious:\n  - \"/version-control-guide\"\nnext:\n  - \"/devops-automation\"\n  - \"/env-setup\"\n---\n\n# Commit Message Assistant\n\nTrigger: `commit`\n\nPurpose: Generate a conventional, review-ready commit message from the currently staged changes.\n\nOutput: A finalized commit message with a 50\u201372 character imperative subject line, optional scope, and supporting body lines describing the rationale, evidence, and tests.\n\n## Steps\n\n1. Verify there is staged work with `git status --short` and stop with guidance if nothing is staged.\n2. Inspect the staged diff with `git diff --staged` and identify the primary change type (feat, fix, chore, docs, refactor, etc.) and optional scope (e.g., package or module).\n3. Draft a concise subject line in the form `&lt;type&gt;(&lt;scope&gt;): &lt;imperative summary&gt;` or `&lt;type&gt;: &lt;imperative summary&gt;` when no scope applies. Keep the line under 73 characters.\n4. Capture essential details in the body as wrapped bullet points or paragraphs: what changed, why it was necessary, and any follow-up actions.\n5. Document validation in a trailing section (e.g., `Tests:`) noting commands executed or why tests were skipped.\n\n## Example Output\n</code></pre> fix(auth): prevent session expiration loop</p> <ul> <li>guard refresh flow against repeated 401 responses</li> <li>add regression coverage for expired refresh tokens</li> </ul> <p>Tests: npm test -- auth/session.test.ts ```</p>"},{"location":"temp-prompts-organized/20-implementation/impl/content-generation.impl/","title":"Content generation","text":"<pre><code>---\nphase: \"11) Evidence Log\"\ngate: \"Evidence Log\"\nstatus: \"Ensure docs stay synced with current phase deliverables.\"\nprevious:\n  - \"Stage-specific work just completed\"\nnext:\n  - \"/release-notes\"\n  - \"/summary (if sharing updates)\"\n---\n\n# Content Generation\n\nTrigger: /content-generation\n\nPurpose: Draft docs, blog posts, or marketing copy aligned with the codebase.\n\n## Steps\n\n1. Read repo README and recent CHANGELOG or commits.\n2. Propose outlines for docs and posts.\n3. Generate content with code snippets and usage examples.\n\n## Output format\n\n- Markdown files with frontmatter and section headings.\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/impl/feature-flags.impl/","title":"Feature flags","text":"<pre><code>---\nphase: \"P8 Post-release Hardening\"\ngate: \"Post-release cleanup\"\nstatus: \"guardrails added before toggling new flows.\"\nprevious:\n  - \"/cleanup-branches\"\nnext:\n  - \"/model-strengths\"\n  - \"/model-evaluation\"\n---\n\n# Feature Flags\n\nTrigger: /feature-flags &lt;provider&gt;\n\nPurpose: Integrate a flag provider, wire the SDK, and enforce guardrails.\n\n**Steps:**\n\n1. Select provider (LaunchDarkly, Unleash, Flagsmith, custom).\n2. Add SDK init in web/api with bootstrap values and offline mode for dev.\n3. Define flag naming and ownership. Add kill\u2011switch pattern and monitoring.\n\n**Output format:** SDK snippet, example usage, and guardrail checklist.\n\n**Examples:** `/feature-flags launchdarkly`.\n\n**Notes:** Ensure flags are typed and expire with tickets.\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/impl/fix.impl/","title":"Fix","text":"<p><pre><code>---\nphase: \"P8 Post-release Hardening\"\ngate: \"Post-release cleanup\"\nstatus: \"validated fix with regression coverage before closing incident.\"\nprevious:\n  - \"/error-analysis\"\nnext:\n  - \"/refactor-suggestions\"\n  - \"/file-modularity\"\n---\n\n# Fix\n\nTrigger: /fix \"&lt;bug summary&gt;\"\n\nPurpose: Propose a minimal, correct fix with diff-style patches.\n\nYou are a CLI assistant focused on helping contributors with the task: Propose a minimal, correct fix with patch hunks.\n\n1. Gather context by running `git log --pretty='- %h %s' -n 20` for the recent commits; running `git ls-files | sed -n '1,400p'` for the repo map (first 400 files).\n2. Bug summary: &lt;args&gt;. Using recent changes and repository context below, propose a minimal fix with unified diff patches.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Propose a minimal, correct fix with patch hunks.\n- Provide unified diff-style patches when recommending code changes.\n- Offer prioritized, actionable recommendations with rationale.\n\nExample Input:\nAuthentication failure after password reset\n\nExpected Output:\n</code></pre> diff - if (!user) return error; + if (!user) return { status: 401 }; <pre><code>Regression test: add case for missing user.\n</code></pre></p>"},{"location":"temp-prompts-organized/20-implementation/impl/generate.impl/","title":"Generate","text":"<p><pre><code>---\nphase: \"P5 Quality Gates &amp; Tests\"\ngate: \"Test Gate\"\nstatus: \"targeted unit tests authored for the specified module.\"\nprevious:\n  - \"/coverage-guide\"\nnext:\n  - \"/regression-guard\"\n---\n\n# Generate Unit Tests\n\nTrigger: /generate &lt;source-file&gt;\n\nPurpose: Generate unit tests for a given source file.\n\nYou are a CLI assistant focused on helping contributors with the task: Generate unit tests for a given source file.\n\n## Steps\n\n1. Inspect `package.json` to identify the unit test framework, runner scripts, and any helper utilities required for the suite.\n2. Review the target source file with `sed -n '1,400p' {{args}}` to catalog exported members, branching logic, and error handling paths that must be exercised.\n3. Outline the test file structure (location, naming, setup/teardown) and propose arrange/act/assert cases that cover happy paths, edge cases, and failure scenarios.\n4. Provide guidance on implementing the tests and how to validate them locally (e.g., `npm test -- &lt;pattern&gt;` or framework-specific commands).\n\n## Output\n\n- Begin with a concise summary that restates the goal: Generate unit tests for a given source file.\n- List the recommended test files, describe each test case, and highlight coverage gaps they close.\n- Call out the command(s) to run the new tests and any fixtures or mocks required.\n- Document the evidence you used (e.g., `package.json`, specific functions/branches in the source file) so maintainers can trust the conclusion.\n\n## Example\n\n**Input**\n</code></pre> src/components/Button.tsx <pre><code>**Output**\n\n- Summary: Author React Testing Library unit tests for `Button` to cover rendering, disabled behavior, and click handling.\n- Create `src/components/__tests__/Button.test.tsx` that:\n  - Renders the button label and asserts it matches `props.children`.\n  - Verifies `onClick` fires once when the button is enabled and is skipped when `disabled` is true.\n  - Confirms the `variant=\"primary\"` branch applies the `btn-primary` class.\n- Validation: Run `npm test -- Button.test.tsx` to execute the suite.\n- Evidence: `package.json` (scripts.test uses Jest + RTL), component branches in `src/components/Button.tsx` (disabled guard, variant styling).\n</code></pre></p>"},{"location":"temp-prompts-organized/20-implementation/impl/prototype-feature.impl/","title":"Prototype feature","text":"<pre><code>---\nphase:\n  - \"P1 Plan &amp; Scope\"\n  - \"P2 App Scaffold &amp; Contracts\"\ngate: \"Prototype review\"\nstatus: \"Validate spike outcomes before committing to scope.\"\nprevious:\n  - \"/planning-process\"\nnext:\n  - \"/scaffold-fullstack\"\n  - \"/api-contract\"\n---\n\n# Prototype Feature\n\nTrigger: /prototype-feature\n\nPurpose: Spin up a standalone prototype in a clean repo before merging into main.\n\n## Steps\n\n1. Create a scratch directory name suggestion and scaffolding commands.\n2. Generate minimal app with only the feature and hardcoded data.\n3. Add E2E test covering the prototype flow.\n4. When validated, list the minimal patches to port back.\n\n## Output format\n\n- Scaffold plan and migration notes.\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/impl/todos.impl/","title":"TODOs","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Find and group TODO/FIXME annotations.\n\n1. Gather context by running `rg -n \"TODO|FIXME\" -g '!node_modules' . || grep -RInE 'TODO|FIXME' .`.\n2. Find and group TODO/FIXME annotations.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Find and group TODO/FIXME annotations.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n- Group: Platform backlog \u2014 4 TODOs referencing auth migration (owner: @platform).\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/impl/voice-input.impl/","title":"Voice input","text":"<pre><code>---\nphase: \"Support\"\ngate: \"Support intake\"\nstatus: \"Clarify voice-derived requests before invoking gated prompts.\"\nprevious:\n  - \"Voice transcript capture\"\nnext:\n  - \"Any stage-specific command (e.g., /planning-process)\"\n---\n\n# Voice Input\n\nTrigger: /voice-input\n\nPurpose: Support interaction from voice capture and convert to structured prompts.\n\n## Steps\n\n1. Accept transcript text.\n2. Normalize to tasks or commands for other prompts.\n3. Preserve speaker intents and important entities.\n\n## Output format\n\n- Cleaned command list ready to execute.\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/review/audit.review/","title":"Audit","text":"<pre><code>---\nphase: \"P7 Release &amp; Ops\"\ngate: \"Release Gate\"\nstatus: \"readiness criteria before shipping.\"\nprevious:\n  - \"/logging-strategy\"\nnext:\n  - \"/error-analysis\"\n  - \"/fix\"\n---\n\n# Audit\n\nTrigger: /audit\n\nPurpose: Audit repository hygiene and suggest improvements.\n\n## Steps\n\n1. Gather context by running `ls -la` for the top-level listing. Inspect `.editorconfig`, `.gitignore`, `.geminiignore`, `.eslintrc.cjs`, `.eslintrc.js`, `tsconfig.json`, and `pyproject.toml` if present to understand shared conventions.\n2. Assess repository hygiene across documentation, testing, CI, linting, and security. Highlight gaps and existing automation.\n3. Synthesize the findings into a prioritized checklist with recommended next steps.\n\n## Output format\n\n- Begin with a concise summary that restates the goal: Audit repository hygiene and suggest improvements.\n- Offer prioritized, actionable recommendations with rationale.\n- Call out test coverage gaps and validation steps.\n- Highlight workflow triggers, failing jobs, and proposed fixes.\n\n## Example input\n\n(none \u2013 command runs without arguments)\n\n## Expected output\n\n- Structured report following the specified sections.\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/review/cross-check.review/","title":"Cross-check","text":"<pre><code># Conflict Resolver\n\nTrigger: /cross-check\n\nPurpose: Compare conflicting findings and decide which source prevails with rationale.\n\nSteps:\n\n1. Accept a list of SourceIDs or URLs with short findings.\n2. Evaluate publisher authority, recency, directness to primary data.\n3. Select the prevailing source; note contradictions and rationale.\n\nOutput format:\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/review/cross-check.review/#contradictions","title":"Contradictions","text":"<ul> <li>{S2 vs S5 \u2192 rationale}</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/review/cross-check.review/#prevails","title":"Prevails","text":"<ul> <li>{SourceID} because {reason} <pre><code>Examples:\n\n- Input: `/cross-check S2: blog vs S5: RFC`\n- Output: RFC prevails due to primary standard.\n\nNotes:\n\n- Always explain why one source prevails.\n</code></pre></li> </ul>"},{"location":"temp-prompts-organized/20-implementation/review/evidence-capture.review/","title":"Evidence capture","text":"<pre><code># Evidence Logger\n\nTrigger: /evidence-capture\n\nPurpose: Capture sources for a specified claim with dates, \u226425-word quotes, findings, relevance, and confidence.\n\nSteps:\n\n1. Read the claim text and optional URLs provided.\n2. For each source, record metadata and a \u226425-word quote.\n3. Add a brief Finding, Relevance (H/M/L), and Confidence (0.0\u20131.0).\n\nOutput format:\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/review/evidence-capture.review/#evidence-log","title":"Evidence Log","text":"SourceID Title Publisher URL PubDate Accessed Quote (\u226425w) Finding Rel Conf <pre><code>Examples:\n\n- Input: `/evidence-capture \"Next.js 15 requires React 19 RC\"` with official links.\n- Output: Evidence table entries with dates.\n\nNotes:\n\n- Mark missing PubDate as n/a. Prefer official documentation.\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/review/pr-desc.review/","title":"PR description","text":"<pre><code>---\nphase: \"P7 Release &amp; Ops\"\ngate: \"Review Gate\"\nstatus: \"PR narrative ready for approvals and release prep.\"\nprevious:\n  - \"/review-branch\"\nnext:\n  - \"/release-notes\"\n  - \"/version-proposal\"\n---\n\n# PR Description\n\nTrigger: /pr-desc &lt;context&gt;\n\nPurpose: Draft a PR description from the branch diff.\n\nYou are a CLI assistant focused on helping contributors with the task: Draft a PR description from the branch diff.\n\n1. Gather context by running `git diff --name-status origin/main...HEAD` for the changed files (name + status); running `git diff --shortstat origin/main...HEAD` for the high\u2011level stats.\n2. Create a crisp PR description following this structure: Summary, Context, Changes, Screenshots (if applicable), Risk, Test Plan, Rollback, Release Notes (if user\u2011facing). Base branch: origin/main User context: &lt;args&gt;.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Draft a PR description from the branch diff.\n- Offer prioritized, actionable recommendations with rationale.\n- Call out test coverage gaps and validation steps.\n- Highlight workflow triggers, failing jobs, and proposed fixes.\n\nExample Input:\nsrc/example.ts\n\nExpected Output:\n\n- Actionable summary aligned with the output section.\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/review/review-branch.review/","title":"Review branch","text":"<pre><code>---\nphase: \"P7 Release &amp; Ops\"\ngate: \"Review Gate\"\nstatus: \"branch scope validated before PR submission.\"\nprevious:\n  - \"/review\"\nnext:\n  - \"/pr-desc\"\n  - \"/release-notes\"\n---\n\n# Review Branch\n\nTrigger: /review-branch\n\nPurpose: Provide a high-level review of the current branch versus origin/main.\n\nYou are a CLI assistant focused on helping contributors with the task: Provide a high\u2011level review of the current branch vs origin/main.\n\n1. Gather context by running `git diff --stat origin/main...HEAD` for the diff stats; running `git diff origin/main...HEAD | sed -n '1,200p'` for the ```diff.\n2. Provide a reviewer\u2011friendly overview: goals, scope, risky areas, test impact.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Provide a high\u2011level review of the current branch vs origin/main.\n- Organize details under clear subheadings so contributors can scan quickly.\n- Call out test coverage gaps and validation steps.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n- Structured report following the specified sections.\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/review/review.review/","title":"Review guide","text":"<pre><code>---\nphase: \"P7 Release &amp; Ops\"\ngate: \"Review Gate\"\nstatus: \"peer review coverage met before merging.\"\nprevious:\n  - \"/owners\"\nnext:\n  - \"/review-branch\"\n  - \"/pr-desc\"\n---\n\n# Review\n\nTrigger: /review &lt;pattern&gt;\n\nPurpose: Review code matching a pattern and deliver actionable feedback.\n\nYou are a CLI assistant focused on helping contributors with the task: Review code matching a pattern and give actionable feedback.\n\n1. Gather context by running `rg -n {{args}} . || grep -RIn {{args}} .` for the search results for {{args}} (filename or regex).\n2. Perform a thorough code review. Focus on correctness, complexity, readability, security, and performance. Provide concrete patch suggestions.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Review code matching a pattern and give actionable feedback.\n- Provide unified diff-style patches when recommending code changes.\n- Organize details under clear subheadings so contributors can scan quickly.\n\nExample Input:\nHttpClient\n\nExpected Output:\n\n- Usage cluster in src/network/* with note on inconsistent error handling.\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/review/todo-report.review/","title":"TODO report","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Summarize TODO/FIXME/XXX annotations across the codebase.\n\n1. Gather context by running `rg -n \"TODO|FIXME|XXX\" -g '!node_modules' . || grep -RInE 'TODO|FIXME|XXX' .`.\n2. Aggregate and group TODO/FIXME/XXX by area and priority. Propose a triage plan.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Summarize TODO/FIXME/XXX annotations across the codebase.\n- Offer prioritized, actionable recommendations with rationale.\n- Organize details under clear subheadings so contributors can scan quickly.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n- Group: Platform backlog \u2014 4 TODOs referencing auth migration (owner: @platform).\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/review/tsconfig-review.review/","title":"TSConfig review","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Review tsconfig for correctness and DX.\n\n1. Gather context by inspecting `tsconfig.json`.\n2. Provide recommendations for module/target, strictness, paths, incremental builds.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Review tsconfig for correctness and DX.\n- Offer prioritized, actionable recommendations with rationale.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n- Structured report following the specified sections.\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/blame-summary.spec-orient/","title":"Blame summary","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Summarize authorship hotspots for a file using git blame.\n\n1. Gather context by running `git blame -w --line-porcelain {{args}} | sed -n 's/^author //p' | sort | uniq -c | sort -nr | sed -n '1,25p'` for the blame authors (top contributors first).\n2. Given the blame summary below, identify ownership hotspots and potential reviewers.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Summarize authorship hotspots for a file using git blame.\n- Organize details under clear subheadings so contributors can scan quickly.\n- Reference evidence from CODEOWNERS or git history for each owner suggestion.\n\nExample Input:\nsrc/components/Button.tsx\n\nExpected Output:\n\n- Refactor proposal extracting shared styling hook with before/after snippet.\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/changed-files.spec-orient/","title":"Changed files","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Summarize changed files between HEAD and origin/main.\n\n1. Gather context by running `git diff --name-status origin/main...HEAD`.\n2. List and categorize changed files: added/modified/renamed/deleted. Call out risky changes.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Summarize changed files between HEAD and origin/main.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n- Structured report following the specified sections.\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/explain-code.spec-orient/","title":"Explain code","text":"<pre><code>---\nphase: \"P7 Release &amp; Ops\"\ngate: \"Review Gate\"\nstatus: \"Improve reviewer comprehension before approvals.\"\nprevious:\n  - \"/owners\"\n  - \"/review\"\nnext:\n  - \"/review-branch\"\n  - \"/pr-desc\"\n---\n\n# Explain Code\n\nTrigger: /explain-code\n\nPurpose: Provide line-by-line explanations for a given file or diff.\n\n## Steps\n\n1. Accept a file path or apply to staged diff.\n2. Explain blocks with comments on purpose, inputs, outputs, and caveats.\n3. Highlight risky assumptions and complexity hot spots.\n\n## Output format\n\n- Annotated markdown with code fences and callouts.\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/explain-symbol.spec-orient/","title":"Explain symbol","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Explain where and how a symbol is defined and used.\n\n1. Gather context by running `rg -n {{args}} . || grep -RIn {{args}} .` for the results.\n2. Explain where and how a symbol is defined and used.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Explain where and how a symbol is defined and used.\n- Organize details under clear subheadings so contributors can scan quickly.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\nHttpClient\n\nExpected Output:\n\n- Definition: src/network/httpClient.ts line 42\n- Key usages: services/userService.ts, hooks/useRequest.ts\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/grep.spec-orient/","title":"Grep","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Recursive text search with ripgrep/grep injection.\n\n1. Gather context by running `rg -n {{args}} . || grep -RIn {{args}} .`.\n2. Show matched lines with file paths and line numbers.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Recursive text search with ripgrep/grep injection.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\nHttpClient\n\nExpected Output:\n\n- Usage cluster in src/network/* with note on inconsistent error handling.\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/research-batch.spec-orient/","title":"Research batch","text":"<pre><code># Conversation-Aware Research \u2014 Batch WBRO\n\nTrigger: /research-batch\n\nPurpose: Process a numbered work-breakdown list of objectives with carry-forward context across items and produce a roll-up summary.\n\nSteps:\n\n1. Parse numbered WBRO items from the input after the trigger.\n2. Before Item 1: list \u22645 bullets of starting context.\n3. For each item i: execute the per-item workflow and include a Conversation State Update.\n4. If blocked by prior gaps, emit **Dependency Blocked** with a minimal micro-query.\n5. After all items: emit a Roll-up Summary with per-item status, enabled decisions, unresolved risks, and a domain-type count of sources.\n\nOutput format:\n\n- Repeat the single-item format per item.\n- End with:\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/research-batch.spec-orient/#roll-up-summary","title":"Roll-up Summary","text":"<ul> <li>Item {n}: {status} \u2014 decision enabled: {\u2026}; risks: {\u2026}</li> <li>Sources by domain type: {gov, org, docs, blog, news} <pre><code>Examples:\n\n- Input: `/research-batch 1) Validate Next.js 15 stability. 2) Compare Bun vs Node for CI. 3) Licensing risks for MIT vs Apache-2.0.`\n- Output: Per-item sections plus roll-up.\n\nNotes:\n\n- Keep quotes \u226425 words. Prefer primary docs.\n</code></pre></li> </ul>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/research-item.spec-orient/","title":"Research item","text":"<pre><code># Conversation-Aware Research \u2014 Single Item\n\nTrigger: /research-item\n\nPurpose: Run the full per-item research workflow for one objective and return queries, evidence, synthesis, contradictions, gaps, decision hook, plus a conversation state update.\n\nSteps:\n\n1. Read the objective text following the trigger.\n2. Capture starting context if provided.\n3. Apply the Process (per item): Goal, Assumptions, Query Set (4\u20138), Search Plan, Run &amp; Capture, Cross-check, Synthesis, Gaps &amp; Next, Decision Hook.\n4. Track PubDate and Accessed (ISO) for every source; prefer primary docs.\n5. Enforce quotes \u226425 words; mark inferences as \"Inference\".\n\nOutput format:\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/research-item.spec-orient/#item-1","title":"Item 1:","text":""},{"location":"temp-prompts-organized/20-implementation/spec-orient/research-item.spec-orient/#goal","title":"Goal","text":"<p>{1 sentence}</p>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/research-item.spec-orient/#assumptions","title":"Assumptions","text":"<ul> <li>{only if needed}</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/research-item.spec-orient/#query-set","title":"Query Set","text":"<ul> <li>{Q1}</li> <li>{Q2}</li> <li>{Q3}</li> <li>{Q4\u2013Q8}</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/research-item.spec-orient/#evidence-log","title":"Evidence Log","text":"SourceID Title Publisher URL PubDate Accessed Quote (\u226425w) Finding Rel Conf"},{"location":"temp-prompts-organized/20-implementation/spec-orient/research-item.spec-orient/#synthesis","title":"Synthesis","text":"<ul> <li>{claim with [S1,S3]}</li> <li>{finding with [S2]}</li> <li>{risk/edge with [S4]}</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/research-item.spec-orient/#contradictions","title":"Contradictions","text":"<ul> <li>{S2 vs S5 \u2192 rationale}</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/research-item.spec-orient/#gaps-next","title":"Gaps &amp; Next","text":"<ul> <li>{follow-up or test}</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/research-item.spec-orient/#decision-hook","title":"Decision Hook","text":"<p>{one line}</p>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/research-item.spec-orient/#conversation-state-update","title":"Conversation State Update","text":"<ul> <li>New facts: {bullets}</li> <li>Constraints learned: {bullets}</li> <li>Entities normalized: {canonical forms} <pre><code>Examples:\n\n- Input: `/research-item Compare OpenAPI 3.1 tooling for Python clients in 2024; budget $0; prefer official docs.`\n- Output: As per format with SourceIDs and dates.\n\nNotes:\n\n- Safety: No personal data. Do not fabricate sources.\n- Provenance: Cite reputable sources; record n/a for missing PubDate.\n</code></pre></li> </ul>"},{"location":"temp-prompts-organized/30-refactor/perf/compare-outputs.perf/","title":"Compare outputs","text":"<pre><code>---\nphase: \"P9 Model Tactics\"\ngate: \"Model uplift\"\nstatus: \"comparative data compiled before switching defaults.\"\nprevious:\n  - \"/model-evaluation\"\nnext:\n  - \"/switch-model\"\n---\n\n# Compare Outputs\n\nTrigger: /compare-outputs\n\nPurpose: Run multiple models or tools on the same prompt and summarize best output.\n\n## Steps\n\n1. Define evaluation prompts and expected properties.\n2. Record outputs from each model/tool with metadata.\n3. Score using a rubric: correctness, compile/run success, edits required.\n4. Recommend a winner and suggested settings.\n\n## Output format\n\n- Matrix comparison and a one-paragraph decision.\n</code></pre>"},{"location":"temp-prompts-organized/30-refactor/perf/model-evaluation.perf/","title":"Model evaluation","text":"<pre><code>---\nphase: \"P9 Model Tactics\"\ngate: \"Model uplift\"\nstatus: \"experiments must beat baseline quality metrics.\"\nprevious:\n  - \"/model-strengths\"\nnext:\n  - \"/compare-outputs\"\n  - \"/switch-model\"\n---\n\n# Model Evaluation\n\nTrigger: /model-evaluation\n\nPurpose: Try a new model and compare outputs against a baseline.\n\n## Steps\n\n1. Define a benchmark set from recent tasks.\n2. Run candidates and collect outputs and metrics.\n3. Analyze failures and summarize where each model excels.\n\n## Output format\n\n- Summary table and recommendations to adopt or not.\n</code></pre>"},{"location":"temp-prompts-organized/30-refactor/perf/model-strengths.perf/","title":"Model strengths","text":"<pre><code>---\nphase: \"P9 Model Tactics\"\ngate: \"Model uplift\"\nstatus: \"capture baseline routing before experimentation.\"\nprevious:\n  - \"/feature-flags (optional)\"\n  - \"Stage-specific blockers\"\nnext:\n  - \"/model-evaluation\"\n  - \"/compare-outputs\"\n---\n\n# Model Strengths\n\nTrigger: /model-strengths\n\nPurpose: Choose model per task type.\n\n## Steps\n\n1. Classify task: UI, API, data, testing, docs, refactor.\n2. Map historical success by model.\n3. Recommend routing rules and temperatures.\n\n## Output format\n\n- Routing guide with examples.\n</code></pre>"},{"location":"temp-prompts-organized/30-refactor/refactor/adr-new.refactor/","title":"ADR \u2013 new","text":"<pre><code>**{$2 or Inferred Name}**\n\nYou are a CLI assistant to draft an Architecture Decision Record with pros/cons using the following inputs:\n\n1. Analyze project context from $1.\n2. Generate a concise ADR with Context, Decision, Status, Consequences. Title: $3.\n3. Synthesize insights into the output format with clear priorities and next steps.\n\n**Output Requirements**:\n- Provide a summary restating the goal.\n- Highlight $4, $5, and $6.\n- Document $7 to ensure maintainability.\n\n**Example Input**: $2\n\n**Expected Output**: Actionable summary aligned with output requirements.\n</code></pre>"},{"location":"temp-prompts-organized/30-refactor/refactor/file-modularity.refactor/","title":"File modularity","text":"<pre><code>---\nphase: \"P8 Post-release Hardening\"\ngate: \"Post-release cleanup\"\nstatus: \"structure debt addressed without destabilizing prod.\"\nprevious:\n  - \"/refactor-suggestions\"\nnext:\n  - \"/dead-code-scan\"\n  - \"/cleanup-branches\"\n---\n\n# File Modularity\n\nTrigger: /file-modularity\n\nPurpose: Enforce smaller files and propose safe splits for giant files.\n\n## Steps\n\n1. Find files over thresholds (e.g., &gt;500 lines).\n2. Suggest extraction targets: components, hooks, utilities, schemas.\n3. Provide before/after examples and import updates.\n\n## Output format\n\n- Refactor plan with patches for file splits.\n</code></pre>"},{"location":"temp-prompts-organized/30-refactor/refactor/prettier-adopt-migration-report.refactor/","title":"Prettier adopt migration","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Plan a Prettier adoption or migration with minimal churn.\n\n1. Gather context by inspecting `package.json`; running `git ls-files '*.*' | sed -n '1,400p'`.\n2. Given the files and package.json, propose a rollout plan and ignore patterns.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Plan a Prettier adoption or migration with minimal churn.\n- Offer prioritized, actionable recommendations with rationale.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n- Structured report following the specified sections.\n</code></pre>"},{"location":"temp-prompts-organized/30-refactor/refactor/refactor-file.refactor/","title":"Refactor file","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Suggest targeted refactors for a single file.\n\n1. Gather context by running `sed -n '1,400p' {{args}}` for the first 400 lines of the file.\n2. Suggest refactors that reduce complexity and improve readability without changing behavior. Provide before/after snippets.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Suggest targeted refactors for a single file.\n- Include before/after snippets or diffs with commentary.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\nsrc/components/Button.tsx\n\nExpected Output:\n\n- Refactor proposal extracting shared styling hook with before/after snippet.\n</code></pre>"},{"location":"temp-prompts-organized/30-refactor/refactor-candidates/dead-code-scan.refactor-candidates/","title":"Dead code scan","text":"<pre><code>---\nphase: \"P8 Post-release Hardening\"\ngate: \"Post-release cleanup\"\nstatus: \"ensure code removals keep prod stable.\"\nprevious:\n  - \"/file-modularity\"\nnext:\n  - \"/cleanup-branches\"\n  - \"/feature-flags\"\n---\n\n# Dead Code Scan\n\nTrigger: /dead-code-scan\n\nPurpose: Identify likely dead or unused files and exports using static signals.\n\nYou are a CLI assistant focused on helping contributors with the task: List likely dead or unused files and exports (static signals).\n\n1. Gather context by running `rg -n \"export |module.exports|exports\\.|require\\(|import \" -g '!node_modules' .` for the file reference graph (best\u2011effort).\n2. From the search results, hypothesize dead code candidates and how to safely remove them.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: List likely dead or unused files and exports (static signals).\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n- Structured report following the specified sections.\n</code></pre>"},{"location":"temp-prompts-organized/30-refactor/refactor-candidates/migration-plan.refactor-candidates/","title":"Migration plan","text":"<pre><code>---\nphase: \"P3 Data &amp; Auth\"\ngate: \"Migration dry-run\"\nstatus: \"validated rollback steps and safety checks documented.\"\nprevious:\n  - \"/db-bootstrap\"\nnext:\n  - \"/auth-scaffold\"\n  - \"/e2e-runner-setup\"\n---\n\n# Migration Plan\n\nTrigger: /migration-plan \"&lt;change summary&gt;\"\n\nPurpose: Produce safe up/down migration steps with checks and rollback notes.\n\n**Steps:**\n\n1. Describe current vs target schema, include data volume and lock risk.\n2. Plan: deploy empty columns, backfill, dual-write, cutover, cleanup.\n3. Provide SQL snippets and PR checklist. Add `can_rollback: true|false` flag.\n\n**Output format:** `Plan`, `SQL`, `Rollback`, `Checks` sections.\n\n**Examples:** `/migration-plan \"orders add status enum\"`.\n\n**Notes:** Include online migration strategies for large tables.\n</code></pre>"},{"location":"temp-prompts-organized/30-refactor/refactor-candidates/refactor-suggestions.refactor-candidates/","title":"Suggestions","text":"<pre><code>---\nphase: \"P8 Post-release Hardening\"\ngate: \"Post-release cleanup\"\nstatus: \"plan high-leverage refactors once Sev-1 issues settle.\"\nprevious:\n  - \"/fix\"\nnext:\n  - \"/file-modularity\"\n  - \"/dead-code-scan\"\n---\n\n# Refactor Suggestions\n\nTrigger: /refactor-suggestions\n\nPurpose: Propose repo-wide refactoring opportunities after tests exist.\n\n## Steps\n\n1. Map directory structure and large files.\n2. Identify duplication, data clumps, and god objects.\n3. Suggest phased refactors with safety checks and tests.\n\n## Output format\n\n- Ranked list with owners and effort estimates.\n</code></pre>"},{"location":"temp-prompts-organized/40-testing/coverage/guide.coverage/","title":"Guide","text":"<pre><code>---\nphase: \"P5 Quality Gates &amp; Tests\"\ngate: \"Test Gate\"\nstatus: \"coverage targets and regression guard plan recorded.\"\nprevious:\n  - \"/integration-test\"\nnext:\n  - \"/regression-guard\"\n  - \"/version-control-guide\"\n---\n\n# Coverage Guide\n\nTrigger: /coverage-guide\n\nPurpose: Propose high-ROI tests to raise coverage using uncovered areas.\n\nYou are a CLI assistant focused on helping contributors with the task: Suggest a plan to raise coverage based on uncovered areas.\n\n1. Gather context by running `find . -name 'coverage*' -type f -maxdepth 3 -print -exec head -n 40 {} \\; 2&gt;/dev/null` for the coverage hints; running `git ls-files | sed -n '1,400p'` for the repo map.\n2. Using coverage artifacts (if available) and repository map, propose the highest\u2011ROI tests to add.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Suggest a plan to raise coverage based on uncovered areas.\n- Offer prioritized, actionable recommendations with rationale.\n- Call out test coverage gaps and validation steps.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n- Focus on src/auth/login.ts \u2014 0% branch coverage; add error path test.\n</code></pre>"},{"location":"temp-prompts-organized/40-testing/coverage/regression-guard.coverage/","title":"Regression guard","text":"<pre><code>---\nphase: \"P5 Quality Gates &amp; Tests\"\ngate: \"Test Gate\"\nstatus: \"regression coverage in place before CI hand-off.\"\nprevious:\n  - \"/coverage-guide\"\nnext:\n  - \"/version-control-guide\"\n  - \"/devops-automation\"\n---\n\n# Regression Guard\n\nTrigger: /regression-guard\n\nPurpose: Detect unrelated changes and add tests to prevent regressions.\n\n## Steps\n\n1. Run `git diff --name-status origin/main...HEAD` and highlight unrelated files.\n2. Propose test cases that lock current behavior for touched modules.\n3. Suggest CI checks to block large unrelated diffs.\n\n## Output format\n\n- Report with file groups, risk notes, and test additions.\n\n## Notes\n\n- Keep proposed tests minimal and focused.\n</code></pre>"},{"location":"temp-prompts-organized/40-testing/fix-flakes/error-analysis.fix-flakes/","title":"Error analysis","text":"<pre><code>---\nphase: \"P8 Post-release Hardening\"\ngate: \"Post-release cleanup\"\nstatus: \"Sev-1 incidents triaged with fixes scheduled.\"\nprevious:\n  - \"/logging-strategy\"\n  - \"/audit\"\nnext:\n  - \"/fix\"\n  - \"/refactor-suggestions\"\n---\n\n# Error Analysis\n\nTrigger: /error-analysis\n\nPurpose: Analyze error logs and enumerate likely root causes with fixes.\n\n## Steps\n\n1. Collect last test logs or application stack traces if present.\n2. Cluster errors by symptom. For each cluster list 2\u20133 plausible causes.\n3. Propose instrumentation or inputs to disambiguate.\n4. Provide minimal patch suggestions and validation steps.\n\n## Output format\n\n- Table: error \u2192 likely causes \u2192 next checks \u2192 candidate fix.\n\n## Examples\n\n- \"TypeError: x is not a function\" \u2192 wrong import, circular dep, stale build.\n</code></pre>"},{"location":"temp-prompts-organized/40-testing/fix-flakes/explain-failures.fix-flakes/","title":"Explain failures","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Analyze recent test failures and propose fixes.\n\n1. Gather context by running `ls -1 test-results 2&gt;/dev/null || echo 'no test-results/ directory'` for the recent test output (if present); running `find . -maxdepth 2 -name 'junit*.xml' -o -name 'TEST-*.xml' -o -name 'last-test.log' -print -exec tail -n 200 {} \\; 2&gt;/dev/null` for the recent test output (if present).\n2. From the following logs, identify root causes and propose concrete fixes.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Analyze recent test failures and propose fixes.\n- Offer prioritized, actionable recommendations with rationale.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n- Structured report following the specified sections.\n</code></pre>"},{"location":"temp-prompts-organized/40-testing/gen-tests/check.gen-tests/","title":"Check","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Check adherence to .editorconfig across the repo.\n\n1. Gather context by inspecting `.editorconfig`; running `git ls-files | sed -n '1,400p'`.\n2. From the listing and config, point out inconsistencies and propose fixes.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Check adherence to .editorconfig across the repo.\n- Offer prioritized, actionable recommendations with rationale.\n- Highlight workflow triggers, failing jobs, and proposed fixes.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n- Structured report following the specified sections.\n</code></pre>"},{"location":"temp-prompts-organized/40-testing/gen-tests/integration-test.gen-tests/","title":"Integration test","text":"<pre><code>---\nphase: \"P5 Quality Gates &amp; Tests\"\ngate: \"Test Gate\"\nstatus: \"happy path E2E must pass locally and in CI.\"\nprevious:\n  - \"/e2e-runner-setup\"\nnext:\n  - \"/coverage-guide\"\n  - \"/regression-guard\"\n---\n\n# Integration Test\n\nTrigger: /integration-test\n\nPurpose: Generate E2E tests that simulate real user flows.\n\n## Steps\n\n1. Detect framework from `package.json` or repo (Playwright/Cypress/Vitest).\n2. Identify critical path scenarios from `PLAN.md`.\n3. Produce test files under `e2e/` with arrange/act/assert and selectors resilient to DOM changes.\n4. Include login helpers and data setup. Add CI commands.\n\n## Output format\n\n- Test files with comments and a README snippet on how to run them.\n\n## Examples\n\n- Login, navigate to dashboard, create record, assert toast.\n\n## Notes\n\n- Prefer data-test-id attributes. Avoid brittle CSS selectors.\n</code></pre>"},{"location":"temp-prompts-organized/40-testing/test-plan/e2e-runner-setup.test-plan/","title":"E2E runner setup","text":"<pre><code>---\nphase: \"P5 Quality Gates &amp; Tests\"\ngate: \"Test Gate\"\nstatus: \"runner green locally and wired into CI before expanding coverage.\"\nprevious:\n  - \"/auth-scaffold\"\n  - \"/ui-screenshots\"\nnext:\n  - \"/integration-test\"\n  - \"/coverage-guide\"\n---\n\n# E2E Runner Setup\n\nTrigger: /e2e-runner-setup &lt;playwright|cypress&gt;\n\nPurpose: Configure an end-to-end test runner with fixtures and a data sandbox.\n\n**Steps:**\n\n1. Install runner and add config with baseURL, retries, trace/videos on retry only.\n2. Create fixtures for auth, db reset, and network stubs. Add `test:serve` script.\n3. Provide CI job that boots services, runs E2E, uploads artifacts.\n\n**Output format:** file list, scripts, and CI snippet fenced code block.\n\n**Examples:** `/e2e-runner-setup playwright`.\n\n**Notes:** Keep runs under 10 minutes locally; parallelize spec files.\n</code></pre>"},{"location":"temp-prompts-organized/40-testing/test-plan/query-set.test-plan/","title":"Query set","text":"<pre><code># High-Yield Query Generator\n\nTrigger: /query-set\n\nPurpose: Generate 4\u20138 targeted web search queries with operators, entity variants, and recency filters for a given objective.\n\nSteps:\n\n1. Restate the goal with entities and time window.\n2. Produce queries using operators: site:, filetype:, inurl:, quotes, OR, date filters.\n3. Include synonyms and common misspellings.\n4. Mix intents: define, compare, integrate, configure, limitations, pricing, API, case study.\n\nOutput format:\n</code></pre>"},{"location":"temp-prompts-organized/40-testing/test-plan/query-set.test-plan/#goal","title":"Goal","text":"<p>{1 sentence}</p>"},{"location":"temp-prompts-organized/40-testing/test-plan/query-set.test-plan/#query-set","title":"Query Set","text":"<ul> <li>{Q1}</li> <li>{Q2}</li> <li>\u2026 up to 8 <pre><code>Examples:\n\n- Input: `/query-set \"OpenAI Responses API streaming server-sent events\" past year`\n- Output: Goal + 6\u20138 queries with operators.\n\nNotes:\n\n- No evidence logging here. Use /research-item to execute.\n</code></pre></li> </ul>"},{"location":"temp-prompts-organized/40-testing/test-plan/secrets-scan.test-plan/","title":"Secrets scan","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Review secret scan output and highlight real leaks.\n\n1. Gather context by running `gitleaks detect --no-banner --redact 2&gt;/dev/null || echo 'gitleaks not installed'` for the if gitleaks is available, output will appear below.\n2. Interpret the scanner results, de\u2011dupe false positives, and propose rotations/remediation.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Review secret scan output and highlight real leaks.\n- Offer prioritized, actionable recommendations with rationale.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n- Structured report following the specified sections.\n</code></pre>"},{"location":"temp-prompts-organized/50-docs/api-docs/api-docs-local.api-docs/","title":"Local API docs","text":"<pre><code>---\nphase: \"P2 App Scaffold &amp; Contracts\"\ngate: \"Test Gate lite\"\nstatus: \"contracts cached locally for repeatable generation.\"\nprevious:\n  - \"/scaffold-fullstack\"\nnext:\n  - \"/api-contract\"\n  - \"/openapi-generate\"\n---\n\n# API Docs Local\n\nTrigger: /api-docs-local\n\nPurpose: Fetch API docs and store locally for offline, deterministic reference.\n\n## Steps\n\n1. Create `docs/apis/` directory.\n2. For each provided URL or package, write retrieval commands (curl or `npm view` docs links). Do not fetch automatically without confirmation.\n3. Add `DOCS.md` index linking local copies.\n\n## Output format\n\n- Command list and file paths to place docs under `docs/apis/`.\n</code></pre>"},{"location":"temp-prompts-organized/50-docs/api-docs/openapi-generate.api-docs/","title":"OpenAPI generate","text":"<pre><code>---\nphase: \"P2 App Scaffold &amp; Contracts\"\ngate: \"Test Gate lite\"\nstatus: \"generated code builds and CI checks cover the new scripts.\"\nprevious:\n  - \"/api-contract\"\nnext:\n  - \"/modular-architecture\"\n  - \"/db-bootstrap\"\n---\n\n# OpenAPI Generate\n\nTrigger: /openapi-generate &lt;server|client&gt; &lt;lang&gt; &lt;spec-path&gt;\n\nPurpose: Generate server stubs or typed clients from an OpenAPI spec.\n\n**Steps:**\n\n1. Validate `&lt;spec-path&gt;`; fail with actionable errors.\n2. For `server`, generate controllers, routers, validation, and error middleware into `apps/api`.\n3. For `client`, generate a typed SDK into `packages/sdk` with fetch wrapper and retry/backoff.\n4. Add `make generate-api` or `pnpm sdk:gen` scripts and CI step to verify no drift.\n5. Produce a diff summary and TODO list for unimplemented handlers.\n\n**Output format:** summary table of generated paths, scripts to add, and next actions.\n\n**Examples:** `/openapi-generate client ts apis/auth/openapi.yaml`.\n\n**Notes:** Prefer openapi-typescript + zod for TS clients when possible.\n</code></pre>"},{"location":"temp-prompts-organized/50-docs/doc-plan/gemini-map.doc-plan/","title":"Gemini map","text":"<pre><code>name: Gemini\u2192Codex Mapper\ncommand: /gemini-map\ntags: migration, prompts, tooling\nscope: toml-to-codex\n\nYou are a translator that converts a Gemini CLI TOML command into a Codex prompt file.\n\nSteps:\n\n1) Read TOML with `description` and `prompt`.\n2) Extract the task, inputs, and outputs implied by the TOML.\n3) Write a Codex prompt file \u2264 300 words:\n\n    - Role line `You are ...`\n    - Numbered steps\n    - Output section\n    - Example input and expected output\n    - `Usage: /&lt;command&gt;` line\n    - YAML-like metadata at top\n\n4) Choose a short, hyphenated filename \u2264 32 chars.\n5) Emit a ready-to-run bash snippet:\n`cat &gt; ~/.codex/prompts/&lt;filename&gt;.md &lt;&lt; 'EOF'` \u2026 `EOF`.\n6) Do not include destructive commands or secrets.\n\nExample input:\n\n```toml\ndescription = \"Draft a PR description\"\nprompt = \"Create sections Summary, Context, Changes from diff stats\"\nExpected output:\n\nA pr-desc.md file with the structure above and a bash cat &gt; block.\n\nUsage: /gemini-map\n</code></pre>"},{"location":"temp-prompts-organized/50-docs/doc-plan/owners.doc-plan/","title":"Owners","text":"<pre><code>---\nphase: \"P7 Release &amp; Ops\"\ngate: \"Review Gate\"\nstatus: \"confirm approvers and escalation paths before PR submission.\"\nprevious:\n  - \"/iac-bootstrap\"\nnext:\n  - \"/review\"\n  - \"/review-branch\"\n  - \"/pr-desc\"\n---\n\n# Owners\n\nTrigger: /owners &lt;path&gt;\n\nPurpose: Suggest likely owners or reviewers for the specified path.\n\nYou are a CLI assistant focused on helping contributors with the task: Suggest likely owners/reviewers for a path.\n\n1. Gather context by inspecting `.github/CODEOWNERS` for the codeowners (if present); running `git log --pretty='- %an %ae: %s' -- {{args}} | sed -n '1,50p'` for the recent authors for the path.\n2. Based on CODEOWNERS and git history, suggest owners.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Suggest likely owners/reviewers for a path.\n- Reference evidence from CODEOWNERS or git history for each owner suggestion.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\nsrc/components/Button.tsx\n\nExpected Output:\n\n- Likely reviewers: @frontend-team (CODEOWNERS), @jane (last 5 commits).\n</code></pre>"},{"location":"temp-prompts-organized/50-docs/examples/api-usage.examples/","title":"API usage","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Show how an internal API is used across the codebase.\n\n1. Gather context by running `rg -n {{args}} . || grep -RIn {{args}} .`.\n2. Summarize common usage patterns and potential misuses for the symbol.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Show how an internal API is used across the codebase.\n- Organize details under clear subheadings so contributors can scan quickly.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\nHttpClient\n\nExpected Output:\n\n- Definition: src/network/httpClient.ts line 42\n- Key usages: services/userService.ts, hooks/useRequest.ts\n</code></pre>"},{"location":"temp-prompts-organized/50-docs/examples/reference-implementation.examples/","title":"Reference implementation","text":"<pre><code>---\nphase: \"P2 App Scaffold &amp; Contracts\"\ngate: \"Test Gate lite\"\nstatus: \"align new modules with proven patterns before deeper work.\"\nprevious:\n  - \"/scaffold-fullstack\"\n  - \"/api-contract\"\nnext:\n  - \"/modular-architecture\"\n  - \"/openapi-generate\"\n---\n\n# Reference Implementation\n\nTrigger: /reference-implementation\n\nPurpose: Mimic the style and API of a known working example.\n\n## Steps\n\n1. Accept a path or URL to an example. Extract its public API and patterns.\n2. Map target module\u2019s API to the reference.\n3. Generate diffs that adopt the same structure and naming.\n\n## Output format\n\n- Side-by-side API table and patch suggestions.\n</code></pre>"},{"location":"temp-prompts-organized/60-release/changelog/from-commits.changelog/","title":"From commits","text":"<p><pre><code># Draft CHANGELOG From Commits\n\nTrigger: /changelog-from-commits\n\nPurpose: Produce a first-draft six-section CHANGELOG block from commit messages and PR titles between two refs.\n\nSteps:\n\n1. Inputs: `since=&lt;ref or tag&gt;` optional, `until=&lt;ref&gt;` default HEAD, `include_prs=true|false` default true.\n2. Gather data with:\n   - `git log --pretty=%H%x09%s%x09%b &lt;since&gt;.. &lt;until&gt;`\n   - If available, `gh pr view` for merged PR titles by commit SHA; else rely on merge commit subjects.\n3. Heuristics:\n   - Map types: `feat|add`\u2192Added, `fix|bug`\u2192Fixed, `perf|refactor|opt`\u2192Changed, `deprecate`\u2192Deprecated, `remove|drop`\u2192Removed, `sec|cve|security`\u2192Security.\n   - Shorten to 12\u201380 chars. Strip scope parentheses.\n4. Emit Markdown with only non-empty sections and a short preface noting the range.\n\nOutput format:\n\n- Range preface line\n- Six-section Markdown block\n\nExamples:\nInput \u2192 `/changelog-from-commits since=v2.0.0 until=HEAD`\nOutput \u2192\n</code></pre> Range: v2.0.0..HEAD</p>"},{"location":"temp-prompts-organized/60-release/changelog/from-commits.changelog/#added","title":"Added","text":"<ul> <li>Import data from XLSX (#612)</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/from-commits.changelog/#fixed","title":"Fixed","text":"<ul> <li>Correct null check in OAuth callback (#615) <pre><code>Notes:\n\n- This is a draft; run `/update-changelog` to finalize and create links.\n- Keep bullets user-facing; avoid internal refactor noise.\n</code></pre></li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/project.changelog/","title":"Project","text":"<pre><code># Changelog\n\nAll notable changes to this project will be documented in this file.\n\nThe format is based on Keep a Changelog, and this project adheres to Semantic Versioning when applicable.\n\n## [Unreleased]\n### Added\n- Introduce interactive `prompts scaffold &lt;slug&gt;` command for creating and managing prompt metadata\n- Add prompt scaffolding workflow and metadata guardrails\n- Add task enrichment pipeline to augment task data during ingestion\n- Add local script execution tools (`workflow_run_script`, `workflow_run_task_action`, `workflow_run_tests`, `workflow_run_build`, `workflow_run_lint`; originally published with `workflow/` prefixes)\n- Add abstraction layer for LLM providers\n- Add `--verbose` and `--unsafe-logs` flags to CLI and MCP server for improved observability\n- Add `docs/client_setup.md` and `docs/observability.md`\n- Add new `@prompts/tools` package to expose core task management logic\n- Implement a stateful workflow engine with a dedicated CLI and MCP server\n- Introduce structured research and planning workflow with new prompt tools\n- Add a comprehensive CLI and MCP server guide\n- Introduce Task-Master CLI and MCP server\n- Implement Task-Master ingest adapter with schema validation and status normalization\n- Implement Jest testing framework and define a canonical JSON schema for tasks\n- Rebaseline project with a new Product Requirements Document (PRDv2) for Task-Master interoperability\n- Introduce Task-Master state engine and a suite of `/tm-*` slash commands\n- Add `/plan-delta` prompt for mid-project planning changes\n- Prepare for initial npm publish by updating `package.json` and adding a release runbook\n- Complete and verify the CLI distribution workflow\n- Introduce `prompts` CLI for workflow management\n- Add `/docfetch-check` prompt to enforce documentation freshness\n- Implement a graph-based workflow planner and state management engine\n- Dynamically register prompts from YAML as executable MCP tools\n- Implement a robust `StateStore` for managing project state\n- Implement a dynamic, stateful prompt workflow and automation engine\n- Initialize project tasks from a Product Requirements Document (PRD)\n- Add initial Product Requirements Document (PRD) for the prompt pack\n- Add research report for building a proactive workflow assistant\n- Automate README table generation from the prompt catalog\n- Add a script to build the prompt catalog\n- Add trigger and purpose metadata to prompts\n- Add a guide for converting prompt libraries into MCP servers\n- Document `actions.json` mapping format for `workflow_run_task_action` (formerly `workflow/run_task_action`) and add sample file under `examples/actions.json`. Clarifies default lookup, `actionsPath` override, and execution gating via `--exec-enabled` + allowlist.\n- CI: add pack contents check to ensure `schemas/` and `dist/mcp/server.js` are included in the npm package (GitHub Actions + verify-pack-contains.mjs).\n- Add `workflow_run_lint` tool paralleling test/build wrappers (initially published as `workflow/run_lint`); register on server; document in docs/mcp-cli.md; add integration tests for dry-run and exec-gate behaviour.\n- Tests: add live execution test for `workflow_run_script` with `PROMPTS_EXEC_ALLOW=1` using allowlisted `noop` script.\n- Introduce the MCP workflow assistant concept\n- Add lifecycle metadata front matter to prompts and a validator script\n- Implement a dynamic router for documentation MCP servers\n- Add a future enhancements roadmap\n- Add `/prd-generate` prompt to create a PRD from a README\n- Introduce a self-contained MCP server for managing and serving prompts\n- Add `/pr-desc` prompt for generating pull request descriptions\n- Integrate Task Master AI for managing agentic workflows\n- Implement a structured instruction and execution framework for the agent\n- Add a comprehensive set of prompts for building an application from scratch\n- Introduce a comprehensive end-to-end development workflow guide\n- Define an end-to-end application development workflow document\n- Add full reference implementation documentation for a Prompts MCP server\n- Add `GEMINI.md` and `AGENTS.md` for project context\n\n### Changed\n- Update `package.json` for public publishing and modernize `tsconfig.json` to use `NodeNext` module resolution\n- Rename workflow execution tools to use underscores (e.g. `workflow_run_script`) for compatibility with OpenAI tool name validation.\n- `workflow_run_task_action` (formerly `workflow/run_task_action`) now resolves actions from a new `actions.json` file\n- Centralize state management into a new `TaskService`\n- Implement batched memory updates for the agent, synchronized with Task Master status\n- Update README with usage examples and server launch instructions\n- Update `AGENTS.md` with Task Master integration guides\n- Formalize PRD in Markdown and refactor research log\n- Implement a more efficient batched memory update system for the agent\n- Improve prompt metadata validation with `zod` and `glob`\n- Automate workflow phase synchronization\n- Describe catalog maintenance workflow in documentation\n- Align `generate` prompt with unit test workflow\n- Clarify commit assistant workflow in documentation\n- Update README to clarify `/gemini-map` usage\n- Update `/audit` prompt for direct slash command usage\n- Align prompts with the gated lifecycle workflow\n- Refactor agent's instructional context and planning artifacts with a formal PRD\n- Overhaul and categorize the prompt catalog in the README\n\n### Deprecated\n- Deprecate previous prompt-authoring workstream as part of PRDv2 rebaseline\n\n### Removed\n- Revert prompt scaffolding workflow and metadata guardrails\n- Remove the automated documentation maintenance flow in favor of a dynamic router\n- Remove obsolete workflow and PRD documentation\n- Remove duplicate `/pr-desc` prompt\n- Delete old `PRD-v2.txt` file\n\n### Fixed\n- Correct the Zod schema for the `advance_state` tool's `outputs` field to prevent JSON schema generation errors\n- Make schema path resolution more robust\n- Consolidate and fix the test suite to run via Jest\n- Correct test limit for multi-byte character truncation\n- Improve payload capping logic for UTF-8 character boundaries and edge cases\n- Correct Mermaid syntax in workflow diagrams\n\n### Security\n- Placeholder for upcoming changes.\n\n## [0.1.0] - 2025-09-22\n### Added\n\n- MCP/acidic_soil_prompts_integration_rollup_2025_09_21_america_chicago.md\n- cross-check.md\n- evidence-capture.md\n- query-set.md\n- research-batch.md\n- research-item.md\n- roll-up.md\n\n&lt;!--\nMaintenance notes:\n- When merging changes, add entries under Added/Changed/Deprecated/Removed/Fixed/Security.\n- Prefer concise, user-facing descriptions over commit-level details.\n- Optionally link PR numbers or commit hashes if helpful.\n--&gt;\n</code></pre>"},{"location":"temp-prompts-organized/60-release/changelog/release-notes-prepare.changelog/","title":"Prepare notes","text":"<p><pre><code># Prepare Release Notes From CHANGELOG\n\nTrigger: /release-notes-prepare\n\nPurpose: Convert the latest CHANGELOG section into release notes suitable for GitHub Releases with the six-section layout.\n\nSteps:\n\n1. Detect latest version heading and extract its section.\n2. Normalize bullets to sentence fragments without trailing periods.\n3. Add short highlights at top (3 bullets max) derived from Added/Changed.\n4. Emit a \"copy-ready\" Markdown body.\n\nOutput format:\n\n- Title line: `Release X.Y.Z \u2014 YYYY-MM-DD`\n- Highlights list\n- Six sections with bullets\n\nExamples:\nInput \u2192 `/release-notes-prepare`\nOutput \u2192\n</code></pre> Release 1.6.0 \u2014 2025-09-22</p> <p>Highlights - Custom roles and permissions - Faster cold starts</p>"},{"location":"temp-prompts-organized/60-release/changelog/release-notes-prepare.changelog/#added","title":"Added","text":"<ul> <li>Role-based access control <pre><code>Notes:\n\n- Strictly derived from `CHANGELOG.md`. Do not invent content.\n- If no version is found, fall back to Unreleased with a warning.\n</code></pre></li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/release-notes.changelog/","title":"Release notes","text":"<pre><code>---\nphase: \"P7 Release &amp; Ops\"\ngate: \"Release Gate\"\nstatus: \"notes compiled for staging review and production rollout.\"\nprevious:\n  - \"/pr-desc\"\nnext:\n  - \"/version-proposal\"\n  - \"/monitoring-setup\"\n---\n\n# Release Notes\n\nTrigger: /release-notes &lt;git-range&gt;\n\nPurpose: Generate human-readable release notes from recent commits.\n\nYou are a CLI assistant focused on helping contributors with the task: Generate human\u2011readable release notes from recent commits.\n\n1. Gather context by running `git log --pretty='* %s (%h) \u2014 %an' --no-merges {{args}}` for the commit log (no merges).\n2. Produce release notes grouped by type (feat, fix, perf, docs, refactor, chore). Include a Highlights section and a full changelog list.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Generate human\u2011readable release notes from recent commits.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\nsrc/example.ts\n\nExpected Output:\n## Features\n\n- Add SSO login flow (PR #42)\n\n## Fixes\n\n- Resolve logout crash (PR #57)\n</code></pre>"},{"location":"temp-prompts-organized/60-release/changelog/update.changelog/","title":"Update","text":"<p><pre><code># Update CHANGELOG\n\nTrigger: /update-changelog\n\nPurpose: Generate a user-facing CHANGELOG entry for the latest merge range and insert under the correct version or Unreleased with the six standard sections.\n\nSteps:\n\n1. Inspect repo state:\n   - Detect current branch and latest tag: `git describe --tags --abbrev=0`.\n   - Identify range: `${SINCE:-&lt;latest-tag&gt;}..HEAD`. If a merge commit hash or tag is provided, use that.\n2. Collect changes:\n   - Prefer Conventional Commits in `git log --pretty=%s %b` over the range.\n   - Map commit types to sections: feat\u2192Added, perf/refactor\u2192Changed, deprecate\u2192Deprecated, remove\u2192Removed, fix\u2192Fixed, security\u2192Security.\n   - Merge PR titles: `git log --merges --pretty=%s` and include PR numbers.\n3. De-dupe and rewrite:\n   - Collapse internal-only chatter. Use terse, user-facing wording. No file paths unless end-user relevant.\n   - Keep bullets short. One line each. Present tense. No trailing periods.\n4. Emit Markdown snippet with the six sections. Omit empty sections.\n5. Decide placement:\n   - If a release tag was created in this merge, use `## [X.Y.Z] - YYYY-MM-DD`.\n   - Else place under `## [Unreleased]`.\n6. Provide a unified diff showing insertion into `CHANGELOG.md`. Do not run it; just output the patch.\n\nOutput format:\n\n- Heading line with target section (Unreleased or version)\n- Six-section block in Markdown with only non-empty sections in order: Added, Changed, Deprecated, Removed, Fixed, Security\n- A short \"Link references\" block suggestion for `[Unreleased]` and new version comparison links\n- A unified diff (context 3) for `CHANGELOG.md`\n\nExamples:\nInput \u2192\n</code></pre> /update-changelog since=v1.4.2 notes=include-prs <pre><code>Output \u2192\n</code></pre></p>"},{"location":"temp-prompts-organized/60-release/changelog/update.changelog/#unreleased","title":"Unreleased","text":""},{"location":"temp-prompts-organized/60-release/changelog/update.changelog/#added","title":"Added","text":"<ul> <li>Export CSV from reports page (#482)</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/update.changelog/#changed","title":"Changed","text":"<ul> <li>Speed up dashboard load times on first visit (#479)</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/update.changelog/#fixed","title":"Fixed","text":"<ul> <li>Resolve 500 error when saving profile with empty bio (#481)</li> </ul> <pre><code>Notes:\n\n- Assumes git repository is available and tags follow SemVer.\n- Keep content end-user focused. Avoid internal file names and refactor notes.\n- If no Conventional Commits, infer section from message heuristics.\n- Do not include secrets or internal ticket links.\n</code></pre>"},{"location":"temp-prompts-organized/60-release/changelog/verify.changelog/","title":"Verify","text":"<p><pre><code># Verify CHANGELOG Completeness\n\nTrigger: /changelog-verify\n\nPurpose: Check that the latest merge introduced a CHANGELOG entry with the six-section policy and that sections are concise and non-empty where applicable.\n\nSteps:\n\n1. Parse `CHANGELOG.md` and locate `## [Unreleased]` or the latest version heading.\n2. Validate presence and order of sections: Added, Changed, Deprecated, Removed, Fixed, Security.\n3. Flag anti-patterns: paragraphs longer than 2 lines, trailing periods, internal-only jargon, file paths, or empty sections left in place.\n4. Cross-check against commits since last tag to detect missing items.\n5. Emit a diagnostic report and a suggested patch to fix ordering and brevity issues.\n\nOutput format:\n\n- \"Status: PASS|FAIL\"\n- Table of findings with line numbers and reasons\n- Suggested normalized Markdown block\n- Unified diff to apply\n\nExamples:\nInput \u2192 `/changelog-verify`\nOutput \u2192\n</code></pre> Status: FAIL - L42: Section order incorrect (Found Fixed before Removed) - Missing Security section stub</p> <p>Suggested block:</p>"},{"location":"temp-prompts-organized/60-release/changelog/verify.changelog/#added","title":"Added","text":"<ul> <li>Bulk upload for SKUs</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/verify.changelog/#security","title":"Security","text":"<ul> <li>Bump OpenSSL to 3.0.14 <pre><code>Notes:\n\n- Static analysis only; no network calls.\n- Treat any section with 0 bullets as removable unless policy requires stubs.\n</code></pre></li> </ul>"},{"location":"temp-prompts-organized/60-release/post-release-checks/cleanup-branches.post-release-checks/","title":"Cleanup branches","text":"<pre><code>---\nphase: \"P8 Post-release Hardening\"\ngate: \"Post-release cleanup\"\nstatus: \"repo tidy with stale branches archived.\"\nprevious:\n  - \"/dead-code-scan\"\nnext:\n  - \"/feature-flags\"\n  - \"/model-strengths\"\n---\n\n# Cleanup Branches\n\nTrigger: /cleanup-branches\n\nPurpose: Recommend which local branches are safe to delete and which to keep.\n\nYou are a CLI assistant focused on helping contributors with the task: Suggest safe local branch cleanup (merged/stale).\n\n1. Gather context by running `git branch --merged` for the merged into current upstream; running `git branch --no-merged` for the branches not merged; running `git for-each-ref --sort=-authordate --format='%(refname:short) \u2014 %(authordate:relative)' refs/heads` for the recently updated (last author dates).\n2. Using the lists below, suggest local branches safe to delete and which to keep. Include commands to remove them if desired (DO NOT execute).\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Suggest safe local branch cleanup (merged/stale).\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n- Structured report following the specified sections.\n</code></pre>"},{"location":"temp-prompts-organized/60-release/post-release-checks/license-report.post-release-checks/","title":"License report","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Summarize third\u2011party licenses and risk flags.\n\n1. Gather context by running `npx --yes license-checker --summary 2&gt;/dev/null || echo 'license-checker not available'` for the if license tools are present, their outputs; inspecting `package.json` for the if license tools are present, their outputs.\n2. Create a license inventory with notices of copyleft/unknown licenses.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Summarize third\u2011party licenses and risk flags.\n- Organize details under clear subheadings so contributors can scan quickly.\n- Flag copyleft or unknown licenses and suggest remediation timelines.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n- MIT (12) \u2014 low risk\n- GPL-3.0 (1) \u2014 requires legal review\n</code></pre>"},{"location":"temp-prompts-organized/60-release/versioning/version-proposal.versioning/","title":"Version proposal","text":"<pre><code>---\nphase: \"P7 Release &amp; Ops\"\ngate: \"Release Gate\"\nstatus: \"version bump decision recorded before deployment.\"\nprevious:\n  - \"/release-notes\"\nnext:\n  - \"/monitoring-setup\"\n  - \"/slo-setup\"\n---\n\n# Version Proposal\n\nTrigger: /version-proposal\n\nPurpose: Propose the next semantic version based on commit history.\n\nYou are a CLI assistant focused on helping contributors with the task: Propose next version (major/minor/patch) from commit history.\n\n1. Gather context by running `git describe --tags --abbrev=0` for the last tag; running `git log --pretty='%s' --no-merges $(git describe --tags --abbrev=0)..HEAD` for the commits since last tag (no merges).\n2. Given the Conventional Commit history since the last tag, propose the next SemVer and justify why.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Propose next version (major/minor/patch) from commit history.\n- Offer prioritized, actionable recommendations with rationale.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n- Structured report following the specified sections.\n</code></pre>"},{"location":"temp-prompts-organized/_experimental/QA-ready_refactor-plan.experimental/","title":"QA ready refactor plan.experimental","text":"<pre><code>&lt;!--\n$1 = goal\n$2 = scope\n$3 = API contracts to keep stable\n$4 = performance guardrails\n$5 = quality commands pipeline (lint then tests)\n$6 = thresholds (coverage target and per-step change budget for lines and files)\n$7 = per-step details bundle (title, files touched, reused symbols, patch summary, tests, risk, rollback note)\n--&gt;\n\n# {$2 or QA-Ready Refactor Plan}\n\n**Inputs**\n\n- Objective: $1\n- Area: $2\n- Contracts: $3\n- Performance: $4\n- Quality run: $5\n- Thresholds: $6\n\n**Guardrails**\n\n- Reuse first: move, extract, or facade. Avoid new patterns unless justified.\n- Small deltas: each step stays within $6 across limited files.\n- Stability: keep $3 intact; add shims if needed.\n- Gate per step: run $5 then enforce $6.\n\n## 1) Assessment\n\n- Seams within $2\n- Safe extraction points\n- Test gaps to close first\n- Affected files\n- Root cause summary\n- Proposed fix outline\n\n## 2) Stepwise Plan\n\n*For each step i:*\n\n- Name: $7\n- Change type: extract | rename | move | inline | split\n- Files: $7\n- Reuse targets: $7\n- Patch outline: $7\n- Tests to add or update: $7\n- Risk and rollback: $7\n- Validation: run $5 and record result\n\n## 3) Execution Log\n\n- Step i \u2192 status, notes, follow-ups\n\n## 4) Exit Report\n\n- What changed and what stayed invariant\n- Performance check against $4\n- Coverage and thresholds met: $6\n- Open items\n- Docs to update\n\n**Acceptance Criteria**\n\n- All steps pass gates.\n- No ABI/API break beyond approved list for $3.\n- Coverage and limits meet $6.\n\n---\n\n### Output format\n\n- Plan table of steps with $7 fields\n- Minimal diffs per step\n- Test and coverage summary from $5\n- Prune ledger: path | evidence | action | owner\n</code></pre>"},{"location":"temp-prompts-organized/_experimental/ops_apply.experimental/","title":"Ops apply.experimental","text":"<pre><code>&lt;!--\n$1 = plan identifier (string or path/URL)\n$2 = apply mode: \"dry-run\" | \"apply\"\n$3 = step selector: \"all\" | comma list (e.g., \"1,2,5\") | range (e.g., \"3-7\")\n$4 = patch strategy: \"git-apply\" | \"unified-diff\" | \"fs-write\"\n$5 = stop policy: \"fail-fast\" | \"continue-on-error\"\n$6 = artifact dir (e.g., \".ops/artifacts\")\n$7 = notes (optional free text)\n--&gt;\n\n/ops:apply \"$1\" \"$2\" \"$3\" \"$4\" \"$5\" \"$6\" \"$7\"\n\nGoal\n\n- Apply the planned patches stepwise and emit verifiable artifacts. Do not execute build/test commands.\n\nInputs\n\n- Plan: $1  (must resolve to a QA-Ready Refactor Plan doc)\n- Mode: $2\n- Steps: $3\n- Patch strategy: $4\n- Stop policy: $5\n- Artifacts dir: $6\n- Notes: $7\n\nPlan contract (must match):\n\n- Use step schema and gates from the QA-Ready Refactor Plan: name, files, reuse targets, patch outline, tests, risk, validation. Each step stays within thresholds and respects stable contracts.\n\nAlgorithm\n\n1) Load plan $1 and parse step table + $7 fields per step. Validate thresholds and invariant contracts before any write.\n2) Select steps per $3. Preserve original ordering.\n3) For each step i:\n   a) Generate minimal patch from \u201cPatch outline\u201d against listed Files.\n   b) If $2 == \"dry-run\": produce diffs only.\n   c) If $2 == \"apply\": apply using $4.\n   d) Record \u201cExecution Log\u201d entry with status, touched files count, LOC delta, and any deviations from thresholds.\n   e) Emit artifacts: `step-i.diff`, `step-i.patch.json` (metadata), `step-i.report.md`.\n   f) If $5 == \"fail-fast\" and a step violates plan guardrails, stop and mark remaining as pending.\n4) After final step, write `exit-report.md` with what changed vs invariants, perf and coverage placeholders, open items, and docs updates needed. Do not run tests here.\n\nOutputs\n\n- `apply-summary.md`: table of steps \u2192 status, files, LOC, notes.\n- Per-step diffs and metadata under $6.\n- `prune-ledger.md`: path | evidence | action | owner (aggregated from plan).\n\nConstraints\n\n- No shell or node execution. No `pnpm` invocation.\n- Respect stable API/ABI contracts listed in plan.\n- Enforce per-step thresholds before writing.\n\nFallback when no executor exists\n\n- Always succeed in producing diffs and manual apply instructions:\n  - For each step, include a ready-to-run `git apply step-i.diff` and, if not applicable, a file-by-file patch block.\n\nFailure handling\n\n- Produce `apply-error.md` with failing step id, reason, and next actions.\n- If plan structure is invalid, emit `plan-parse-error.md` and exit.\n\nExamples\n\n- Dry run for all steps with unified diffs to `.ops`:\n  /ops:apply \"./plans/refactor-plan.md\" \"dry-run\" \"all\" \"unified-diff\" \"fail-fast\" \".ops\" \"\"\n- Apply steps 1\u20133 using git apply and continue on errors:\n  /ops:apply \"plan-123\" \"apply\" \"1-3\" \"git-apply\" \"continue-on-error\" \".ops\" \"hotfix window\"\n\nNotes\n\n- Pair with `/ops:quality &lt;step-id&gt; \"&lt;commands&gt;\"` to run quality gates separately, e.g.:\n  /ops:quality 2 \"pnpm run lint &amp;&amp; pnpm test &amp;&amp; pnpm run e2e\"\n</code></pre>"},{"location":"temp-prompts-organized/_experimental/ops_quality.experimental/","title":"Ops quality.experimental","text":"<pre><code>&lt;!--\n$1 = target: \"plan-id:step-id\" | \"plan-id:range\" | \"plan-id:all\" | bare step-id(s) (\"2\" or \"1,3-5\")\n$2 = commands string (e.g., \"pnpm run lint &amp;&amp; pnpm test &amp;&amp; pnpm run e2e\")\n$3 = exec driver: \"detect\" | \"local\" | \"codex\" | \"none\" (emit script only)\n$4 = working directory (e.g., \".\")\n$5 = artifacts dir (e.g., \".ops/quality\")\n$6 = timeout seconds per step (e.g., \"3600\")\n$7 = retries on failure per step (e.g., \"0\")\n$8 = parallelism: integer \u22651 (e.g., \"2\")\n$9 = environment: \"inherit\" | path to .env | inline \"KEY=VAL,KEY2=VAL2\"\n--&gt;\n\n/ops:quality \"$1\" \"$2\" \"$3\" \"$4\" \"$5\" \"$6\" \"$7\" \"$8\" \"$9\"\n\nGoal\n\n- Execute step-scoped quality checks and normalize results. Preserve logs and metrics for CI or manual review.\n\nInputs\n\n- Target: $1\n- Commands: $2\n- Driver: $3\n- CWD: $4\n- Artifacts: $5\n- Timeout: $6\n- Retries: $7\n- Parallelism: $8\n- Env: $9\n\nContract\n\n- Read thresholds and gates from the referenced plan steps when present (coverage, lint, perf, memory, LOC caps).\n- Do not modify source files.\n\nAlgorithm\n\n1) Resolve $1 to an ordered step list. Load declared gates for each step when available.\n2) Prepare run context:\n   - Apply env from $9 (merge with inherit if a file is provided).\n   - Ensure $4 exists; create $5 with subdirs per step: `$5/step-&lt;id&gt;/`.\n3) For each step (\u2264 $8 in parallel):\n   a) Compose a POSIX shell script: `set -euo pipefail; $2`.\n   b) If $3 == \"none\": write`run.sh` and skip execution.\n      Else execute via driver ($3). Enforce per-step timeout $6.\n   c) Capture stdout and stderr to `stdout.log` and `stderr.log`.\n   d) Collect common artifacts if present:\n      - JUnit XML \u2192 `junit.xml`\n      - Coverage summaries \u2192 `coverage-summary.json` or `lcov.info`\n      - Lint reports \u2192 `lint.json` or `lint.txt`\n      - Perf/profiling \u2192 `perf.json`\n   e) Evaluate gates against collected artifacts. Compute PASS/FAIL with reasons.\n   f) On failure and retries remaining ($7): rerun with exponential backoff and tag attempt N.\n4) Write `step-report.json` with: timings, attempts, exit code, gate results, and file counts.\n5) Aggregate into `$5/quality-summary.md` and `$5/quality-summary.json`:\n   - step \u2192 status, duration, retries, failing gates, pointers to logs.\n6) Exit non-zero if any mandatory gate fails.\n\nOutputs\n\n- `$5/step-&lt;id&gt;/stdout.log`, `stderr.log`, `run.sh`, `step-report.json`, collected tool artifacts.\n- `$5/quality-summary.md` and `$5/quality-summary.json`.\n- If $3 == \"none\": also emit `manual-run.md` with copy-paste commands and expected artifacts.\n\nConstraints\n\n- No source writes. No network unless commands require it.\n- Respect per-step thresholds from the plan when available; otherwise do best-effort parsing from artifacts.\n- Keep per-step log files \u226410 MB by truncation with notice.\n\nFailure handling\n\n- On driver error or timeout, mark step as ERROR with captured diagnostics; continue other steps.\n- Produce `$5/quality-error.md` summarizing root causes and next actions.\n\nExamples\n\n- Run quality for step 2 with local execution and default env:\n  /ops:quality \"plan-123:2\" \"pnpm run lint &amp;&amp; pnpm test\" \"local\" \".\" \".ops/quality\" \"1800\" \"0\" \"1\" \"inherit\"\n\n- Emit manual script for steps 1\u20133, no execution:\n  /ops:quality \"plan-123:1-3\" \"pnpm run lint &amp;&amp; pnpm test &amp;&amp; pnpm run e2e\" \"none\" \".\" \".ops/quality\" \"3600\" \"0\" \"1\" \".env\"\n\n- Parallel run for all steps with retries:\n  /ops:quality \"plan-123:all\" \"pnpm run -s lint &amp;&amp; pnpm -s test\" \"detect\" \".\" \".ops/quality\" \"2400\" \"1\" \"3\" \"KEY=A,CI=1\"\n</code></pre>"},{"location":"temp-prompts-organized/_experimental/sample_workflow.experimental/","title":"Sample workflow.experimental","text":"<pre><code># Workflow Sequence\n\nUsers request/idea --&gt; gemini-2.5:pro\n\nTM parses prd into tasks.json\n\n## Response item from gemini\n\ngemini's response is sent to GPT-5 for enhancements\n\nDelivers --&gt; &lt;gpt5-reviewed-gemini-refact&gt;.md\n\n## POST PRD PARSING WITH TM\n\n### Users Query to gpt-5\n\n```md\n\"Does the prd.md and tasks.json reflect the &lt;gpt5-reviewed-gemini-ui-refact&gt;.md and honor its requests?\"\n</code></pre>"},{"location":"temp-prompts-organized/_experimental/sample_workflow.experimental/#optional-highly-recommended","title":"OPTIONAL (Highly Recommended)","text":"<p>Better output on iterations</p> <ul> <li>curated prompt templates specific to scope of user</li> <li>general gpt-5 response and Q&amp;A</li> <li>Outputs --&gt; discrepancies surfaced from tasks.json</li> </ul>"},{"location":"temp-prompts-organized/_experimental/sample_workflow.experimental/#rinse-repeat-w-complexity-report","title":"Rinse &amp; Repeat w/ Complexity Report","text":""},{"location":"temp-prompts-organized/_experimental/sample_workflow.experimental/#optional-provide-curated-kickoff-prompt-template","title":"Optional (Provide curated kickoff prompt template)","text":""},{"location":"temp-prompts-organized/_experimental/sample_workflow.experimental/#if-template-method","title":"If template method","text":"<ul> <li>Give prompt template to GPT-5 and take the output and add to the template file.</li> </ul> <p>Query</p> <pre><code>\"instructions on it's usage for user?\"\n</code></pre> <ul> <li> <p>Drag copy of the template into codebase Provide gemini your session id and edit the settings.json to allow as a working directory (location of the session)</p> </li> <li> <p>Once gemini-2.5:Pro is fully configured and primed have gemini fill out the template.</p> </li> <li> <p>Take the inputs and use the a notepad to draft your query to codex and send.</p> </li> </ul>"},{"location":"temp-prompts-organized/_experimental/sample_workflow.experimental/#feed-the-preprompt-to-codex","title":"Feed the prePrompt to codex","text":""},{"location":"temp-prompts-organized/_experimental/sample_workflow.experimental/#refactor-workflow-examples","title":"Refactor workflow examples","text":""},{"location":"temp-prompts-organized/_experimental/sample_workflow.experimental/#prompts","title":"/prompts:&lt;&gt;","text":"<pre><code>/prompts:QA-ready_refactor-plan \"Inventory and harden the existing app to support the UI refactor without reinitializing the project.\" \"Entire `codex-session-viewer` application.\" \"All public-facing\n  components and their props, especially `&lt;codex-session-viewer&gt;`.\" \"Virtualized timeline rendering should remain &gt;55 FPS on 1,000 events, and memory usage should stay under 300 MB with a 10k-event\n  dataset.\" \"`pnpm run lint &amp;&amp; pnpm test &amp;&amp; pnpm run e2e`\" \"Coverage \u2265 85%; \u2264 150 LOC touched per step; \u2264 5 files per step.\"\n</code></pre> <pre><code>/prompts:&lt;NameOfPrompt&gt; \"Inventory and harden the existing app to support the UI refactor without reinitializing the project.\" \"Entire `codex-session-viewer` application.\" \"All public-facing\n  components and their props, especially `&lt;codex-session-viewer&gt;`.\" \"Virtualized timeline rendering should remain &gt;55 FPS on 1,000 events, and memory usage should stay under 300 MB with a 10k-event\n  dataset.\" \"`pnpm run lint &amp;&amp; pnpm test &amp;&amp; pnpm run e2e`\" \"Coverage \u2265 85%; \u2264 150 LOC touched per step; \u2264 5 files per step.\"\n</code></pre>"},{"location":"temp-prompts-organized/_experimental/sample_workflow.experimental/#promptsops_apply","title":"/prompts:ops_apply","text":"<pre><code># 1) Dry-run all steps, emit unified diffs to .ops\n/ops:apply \"./plans/refactor-plan.md\" \"dry-run\" \"all\" \"unified-diff\" \"fail-fast\" \".ops\" \"\"\n\n# 2) Apply steps 1\u20133 via git apply, continue on errors\n/ops:apply \"plan-123\" \"apply\" \"1-3\" \"git-apply\" \"continue-on-error\" \".ops\" \"hotfix window\"\n\n# 3) Apply a single step using filesystem writes (no VCS), fail fast\n/ops:apply \"plan-123\" \"apply\" \"2\" \"fs-write\" \"fail-fast\" \".ops\" \"surgical change\"\n\n# 4) Dry-run selected steps 1,4,7 to review patches only\n/ops:apply \"plan-123\" \"dry-run\" \"1,4,7\" \"unified-diff\" \"fail-fast\" \".ops\" \"review before apply\"\n\n# 5) Apply remaining steps after a pause; keep artifacts separate\n/ops:apply \"plan-123\" \"apply\" \"5-9\" \"git-apply\" \"continue-on-error\" \".ops/phase-2\" \"phase 2 rollout\"\n\n# 6) Plan resolved from URL; generate diffs only for compliance sign-off\n/ops:apply \"https://example.com/plan-123.md\" \"dry-run\" \"all\" \"unified-diff\" \"fail-fast\" \".ops/signoff\" \"audit\"\n\n# 7) Create manual-apply packets when Git patches won\u2019t fit (fs-write)\n/ops:apply \"./plans/edge-cases.md\" \"dry-run\" \"3\" \"fs-write\" \"fail-fast\" \".ops/manual\" \"legacy tree shape\"\n\n# 8) Canary apply a single risky step with rich notes\n/ops:apply \"plan-123\" \"apply\" \"6\" \"git-apply\" \"fail-fast\" \".ops/canary\" \"canary on small cohort\"\n</code></pre>"},{"location":"temp-prompts-organized/_experimental/sample_workflow.experimental/#promptsops_quality","title":"/prompts:ops_quality","text":"<pre><code># 1) Run step 2 locally with default env\n/ops:quality \"plan-123:2\" \"pnpm run lint &amp;&amp; pnpm test\" \"local\" \".\" \".ops/quality\" \"1800\" \"0\" \"1\" \"inherit\"\n\n# 2) All steps via auto driver detection, with retries and parallelism\n/ops:quality \"plan-123:all\" \"pnpm run -s lint &amp;&amp; pnpm -s test\" \"detect\" \".\" \".ops/quality\" \"2400\" \"1\" \"3\" \"CI=1,FORCE_COLOR=1\"\n\n# 3) Steps 1\u20133, emit script only (no execution)\n/ops:quality \"plan-123:1-3\" \"pnpm run lint &amp;&amp; pnpm run e2e\" \"none\" \".\" \".ops/quality\" \"3600\" \"0\" \"1\" \".env\"\n\n# 4) Comma list selection with longer timeout\n/ops:quality \"plan-123:1,4,7\" \"pnpm test\" \"local\" \".\" \".ops/quality\" \"5400\" \"0\" \"2\" \"inherit\"\n\n# 5) Bare step IDs resolved against current plan\n/ops:quality \"2,5-6\" \"npm run test\" \"local\" \".\" \".ops/quality\" \"1800\" \"0\" \"1\" \"inherit\"\n\n# 6) Perf-heavy checks with capped logs via env var\n/ops:quality \"plan-abc:all\" \"make lint test perf\" \"detect\" \".\" \".ops/quality\" \"7200\" \"0\" \"2\" \"CI=1,LOG_MAX=10485760\"\n\n# 7) Single step with custom working dir and artifacts path\n/ops:quality \"plan-xyz:3\" \"pytest -q &amp;&amp; coverage xml\" \"local\" \"services/api\" \".ops/api-quality\" \"1800\" \"0\" \"1\" \"inherit\"\n\n# 8) Generate manual packet for offline runner\n/ops:quality \"plan-123:all\" \"pnpm run lint &amp;&amp; pnpm test &amp;&amp; pnpm run e2e\" \"none\" \".\" \".ops/manual-quality\" \"3600\" \"0\" \"1\" \"KEY=A,CI=1\"\n\n# 9) Re-run flaky step with retries\n/ops:quality \"plan-123:7\" \"pnpm test --filter '@app/*'\" \"local\" \".\" \".ops/quality\" \"1800\" \"2\" \"1\" \"inherit\"\n</code></pre> <p>Run these next</p> <ul> <li>QA-ready_refactor-plan</li> <li>ops_apply</li> <li>ops_quality</li> </ul> What's next <ul> <li>Need to refactor? Run first QA-ready_refactor-plan</li> <li>Then, Run second ops_apply</li> <li>If needed, run ops_quality</li> </ul> <p>```</p>"},{"location":"temp-prompts-organized/_shared/rank-root-prompts.shared/","title":"Rank root prompts","text":"<pre><code>&lt;!--\n$1 = command name/identifier\n$2 = example user question\n$3 = project CWD path to scan for context (defaults to current directory)\n$4 = prompt directory path (defaults to \"~/.codex/prompts\")\n$5 = minimum relevance threshold (0\u20131)\n--&gt;\n\n# {Context-Aware Prompt Ranking Command}\n\n```md\n# Command: $1\n\n# Usage: $1 \"$2\" \"$3\" \"$4\" \"$5\"\n\n# Args:\n\n# - {{query}}: $2\n# - {{project_path}}: $3\n# - {{prompt_path}}: $4\n# - {{threshold}}: $5\n\nprompt = \"\"\"\nTask:\nGiven a user inquiry ({{query}}) and the context of a software project located at {{project_path}}, your goal is to identify the most relevant prompt-definition file from the directory {{prompt_path}}.\n\nDefaults:\n* If {{project_path}} is missing or blank, use the current working directory.\n* If {{prompt_path}} is missing or blank, use \"~/.codex/prompts\".\n\nDo the following:\n1) **Analyze Project Context**: Recursively scan {{project_path}} to understand its structure, languages, and purpose. Create a concise summary of the project context.\n2) **Scan Prompts**: List all candidate prompt files in {{prompt_path}} (non-recursively).\n3) **Evaluate Prompts**: For each candidate prompt file:\n    a) Read its content.\n    b) Create a one-sentence summary of its purpose and domain.\n    c) Compute a relevance score from 0 to 1. This score must measure how well the prompt's purpose aligns with the user's {{query}}, considering the project context summary. A higher score means the prompt is a better fit for solving the query within the given project.\n4) **Rank and Filter**: Order the prompts by their relevance score in descending order.\n5) **Generate Output**: Emit a compact markdown table with the columns: `filename | description | match_score` (rounded to 2 decimals).\n\nRules:\n* The description must be 1\u20132 sentences capturing the prompt's purpose and domain.\n* Only include prompts in the table where `match_score` is greater than or equal to {{threshold}}.\n* If no prompts meet the threshold, output a single line: \"No prompt exceeds threshold {{threshold}} \u2014 recommend creating a new prompt.\"\n\nAcceptance:\n* If one or more matches meet the {{threshold}}, a markdown table sorted by descending `match_score` is produced.\n* Otherwise, the single-line fallback message is produced.\n\n!{echo \"Scanning project: ${PROJECT_PATH_ARG:-.}\"}\n!{echo \"Searching for prompts in: ${PROMPT_PATH_ARG:-~/.codex/prompts}\"}\n\"\"\"\n</code></pre>"},{"location":"temp-prompts-organized/_shared/rank-root-prompts.shared/#output-format","title":"Output format","text":"<ul> <li>Preferred: a markdown table with columns <code>filename | description | match_score</code> sorted by <code>match_score</code> (desc) and filtered by <code>{{threshold}}</code>.</li> <li>Fallback: the exact one-line message when no entries meet <code>{{threshold}}</code>. ```</li> </ul>"},{"location":"temp-prompts-organized/_shared/reset-strategy.shared/","title":"Reset strategy","text":"<pre><code>---\nphase: \"Reset Playbook\"\ngate: \"Clean restart\"\nstatus: \"triggered when gate criteria stall for &gt;60 minutes.\"\nprevious:\n  - \"Any blocked stage\"\nnext:\n  - \"Restart with /planning-process then follow the gated flow\"\n---\n\n# Reset Strategy\n\nTrigger: /reset-strategy\n\nPurpose: Decide when to hard reset and start clean to avoid layered bad diffs.\n\n## Steps\n\n1. Run: `git status -sb` and `git diff --stat` to assess churn.\n2. If many unrelated edits or failing builds, propose: `git reset --hard HEAD` to discard working tree.\n3. Save any valuable snippets to `scratch/` before reset.\n4. Re-implement the minimal correct fix from a clean state.\n\n## Output format\n\n- A short decision note and exact commands. Never execute resets automatically.\n\n## Examples\n\n- Recommend reset after repeated failing refactors touching 15+ files.\n\n## Notes\n\n- Warn about destructive nature. Require user confirmation.\n</code></pre>"},{"location":"temp-prompts-organized/_shared/roll-up.shared/","title":"Roll-up","text":"<pre><code># Research Roll-up Summary\n\nTrigger: /roll-up\n\nPurpose: Summarize per-item statuses, enabled decisions, unresolved risks, and count sources by domain type.\n\nSteps:\n\n1. Aggregate Conversation State Updates from prior items.\n2. Produce per-item status lines and decisions.\n3. Tally sources by domain type: gov, org, docs, blog, news, academic.\n\nOutput format:\n</code></pre>"},{"location":"temp-prompts-organized/_shared/roll-up.shared/#roll-up-summary","title":"Roll-up Summary","text":"<ul> <li>Item {n}: {status} \u2014 decision enabled: {\u2026}; risks: {\u2026}</li> <li>Sources by domain type: {gov:X, org:Y, docs:Z, blog:A, news:B, academic:C} <pre><code>Examples:\n\n- Input: `/roll-up from items 1\u20133`\n- Output: Summary block as above.\n\nNotes:\n\n- Use counts derived from the Evidence Logs.\n</code></pre></li> </ul>"},{"location":"temp-prompts-organized/_shared/summary.shared/","title":"Summary","text":"<pre><code>You are a CLI assistant focused on helping contributors with the task: Produce a README\u2011level summary of the repo.\n\n1. Gather context by running `git ls-files | sed -n '1,400p'` for the repo map (first 400 files); inspecting `README.md` for the key docs if present; inspecting `docs` for the key docs if present.\n2. Generate a high\u2011level summary (What, Why, How, Getting Started).\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Produce a README\u2011level summary of the repo.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n- Structured report following the specified sections.\n</code></pre>"},{"location":"temp-prompts-organized/_shared/switch-model.shared/","title":"Switch model","text":"<pre><code>---\nphase: \"P9 Model Tactics\"\ngate: \"Model uplift\"\nstatus: \"document rollback/guardrails before flipping defaults.\"\nprevious:\n  - \"/compare-outputs\"\nnext:\n  - \"Return to the blocked stage (e.g., /integration-test) to apply learnings\"\n---\n\n# Switch Model\n\nTrigger: /switch-model\n\nPurpose: Decide when to try a different AI backend and how to compare.\n\n## Steps\n\n1. Define task type: frontend codegen, backend reasoning, test writing, refactor.\n2. Select candidate models and temperature/tooling options.\n3. Run a fixed input suite and measure latency, compile success, and edits needed.\n4. Recommend a model per task with rationale.\n\n## Output format\n\n- Table: task \u2192 model \u2192 settings \u2192 win reason.\n</code></pre>"},{"location":"temp-prompts-organized/_shared/tm/advance.tm/","title":"Advance","text":"<pre><code># Advance Task(s)\n\nTrigger: /tm-advance\n\nPurpose: For given task id(s), produce a concrete work plan, acceptance criteria, tests, and a Conventional Commits message to move status toward done.\n\nSteps:\n\n1. Read tasks.json; resolve each provided id. If none provided, pick the top item from /tm-next.\n2. For each task: restate title, goals, and related dependencies.\n3. Draft a step-by-step plan with file touch-points and test hooks.\n4. Provide a minimal commit plan and a Conventional Commits message with scope and short body.\n5. List measurable acceptance criteria.\n\nOutput format:\n\n- One section per task: \"## &lt;id&gt; \u2014 &lt;title&gt;\"\n- Subsections: Plan, Files, Tests, Acceptance, Commit Message (fenced), Risks.\n\nExamples:\n\n- Input: /tm-advance TM-42 TM-43\n- Output: structured sections with a commit message like `feat(parser): implement rule X`.\n\nNotes:\n\n- Do not mutate tasks.json. Emit proposed changes only.\n</code></pre>"},{"location":"temp-prompts-organized/_shared/tm/blockers.tm/","title":"Blockers","text":"<pre><code># Blocker Diagnosis\n\nTrigger: /tm-blockers\n\nPurpose: Diagnose why a task is blocked and propose the shortest path to unblock it.\n\nSteps:\n\n1. Load tasks.json and the target id.\n2. Enumerate unmet dependencies and missing artifacts (tests, docs, approvals).\n3. Classify each blocker: dependency, ambiguity, environment, CI, external.\n4. Propose 1\u20133 minimal unblocking actions, each with owner, effort, and success check.\n\nOutput format:\n\n- \"# Blocker Report: &lt;id&gt;\"\n- Tables: blockers (type | item | evidence), actions (step | owner | effort | success_criteria).\n\nExamples:\n\n- Input: /tm-blockers TM-17\n- Output: two tables and a short narrative under \"Findings\".\n\nNotes:\n\n- If the task is not actually blocked, state why and redirect to /tm-advance.\n</code></pre>"},{"location":"temp-prompts-organized/_shared/tm/ci.tm/","title":"CI","text":"<pre><code># CI/Test Checklist from Tasks\n\nTrigger: /tm-ci\n\nPurpose: Derive a near-term CI and test checklist from ready and in-progress tasks.\n\nSteps:\n\n1. Compute ready tasks (see /tm-next) and collect any testStrategy fields.\n2. Group by component or tag if available; otherwise by path keywords in titles.\n3. Propose CI jobs and test commands with approximate runtimes and gating rules.\n4. Include a smoke-test matrix and minimal code coverage targets if relevant.\n\nOutput format:\n\n- \"# CI Plan\"\n- Tables: jobs (name | trigger | commands | est_time) and tests (scope | command | expected_artifacts).\n- \"## Risk Areas\" bullets and \"## Follow-ups\".\n\nExamples:\n\n- Input: /tm-ci\n- Output: one CI plan with 3\u20138 jobs and a test table.\n\nNotes:\n\n- Non-binding guidance. Adapt to the repo\u2019s actual CI system.\n</code></pre>"},{"location":"temp-prompts-organized/_shared/tm/delta.tm/","title":"Delta","text":"<pre><code># PRD \u2192 Tasks Delta\n\nTrigger: /tm-delta\n\nPurpose: Compare a PRD text against tasks.json and propose add/update/remove operations.\n\nSteps:\n\n1. Accept PRD content pasted by the user or a path like ./prd.txt. If absent, output a short template asking for PRD input.\n2. Extract objectives, constraints, deliverables, and milestones from the PRD.\n3. Map them to existing tasks by fuzzy match on title and keywords; detect gaps.\n4. Propose: new tasks, updates to titles/descriptions/priority, and deprecations.\n\nOutput format:\n\n- \"# Delta Summary\"\n- Tables: adds | updates | removals.\n- \"## JSON Patch\" with an ordered list of operations: add/replace/remove.\n- \"## Assumptions\" and \"## Open Questions\".\n\nExamples:\n\n- Input: /tm-delta ./prd.txt\n- Output: tables with a small JSON Patch block.\n\nNotes:\n\n- Keep patches minimal and reversible. Flag any destructive changes explicitly.\n</code></pre>"},{"location":"temp-prompts-organized/_shared/tm/docs.tm/","title":"Docs","text":"<pre><code># Generate Status Docs\n\nTrigger: /tm-docs\n\nPurpose: Emit a project status document from tasks.json for README or STATUS.md.\n\nSteps:\n\n1. Parse tasks.json; collect done, in_progress, blocked, and ready_next (per /tm-next logic).\n2. Compose a concise narrative: current focus, recent wins, top risks.\n3. Produce status boards for each status with id, title, and owner if present.\n4. Add a 7-day changelog if timestamps exist; otherwise, summarize recent done items.\n\nOutput format:\n\n- \"# Project Status \u2014 &lt;date&gt;\"\n- Sections: Summary, Ready Next, In Progress, Blocked, Done, Changelog.\n\nExamples:\n\n- Input: /tm-docs\n- Output: a single Markdown document suitable for commit as STATUS.md.\n\nNotes:\n\n- Avoid leaking secrets. Do not invent owners; omit unknown fields.\n</code></pre>"},{"location":"temp-prompts-organized/_shared/tm/next.tm/","title":"Next","text":"<pre><code># Next Ready Tasks\n\nTrigger: /tm-next\n\nPurpose: List tasks that are ready to start now (no unmet dependencies), ordered by priority and dependency depth.\n\nSteps:\n\n1. Load tasks.json and build a map of id \u2192 task.\n2. A task is ready if status \u2208 {pending, blocked} AND all dependencies are done.\n3. Order by: priority desc, then shortest path length to completion, then title.\n4. For each ready task, include why it is ready and the prerequisites satisfied.\n\nOutput format:\n\n- \"# Ready Now\"\n- Table: id | title | priority | why_ready | prereqs\n- \"## Notes\" for tie-break rules and data gaps.\n\nExamples:\n\n- Input: /tm-next\n- Output: a table of 5\u201320 items. If none, say \"No ready tasks\" and list nearest-unblock candidates.\n\nNotes:\n\n- Treat missing or null priority as 0. If custom scales exist, describe them in Notes.\n</code></pre>"},{"location":"temp-prompts-organized/_shared/tm/overview.tm/","title":"Overview","text":"<pre><code># TaskMaster Overview\n\nTrigger: /tm-overview\n\nPurpose: Summarize the current TaskMaster tasks.json by status, priority, dependency health, and critical path to orient work.\n\nSteps:\n\n1. Locate the active tasks.json at repo root or the path supplied in the user message. Do not modify it.\n2. Parse fields: id, title, description, status, priority, dependencies, subtasks.\n3. Compute counts per status and a table of top pending items by priority.\n4. Detect dependency issues: cycles, missing ids, orphans (no deps and not depended on).\n5. Approximate a critical path: longest dependency chain among pending\u2192in_progress tasks.\n\nOutput format:\n\n- \"# Overview\" then a bullets summary.\n- \"## Totals\" as a 4-column table: status | count | percent | notes.\n- \"## Top Pending\" table: id | title | priority | unblockers.\n- \"## Critical Path\" as an ordered list of ids with short titles.\n- \"## Issues\" list for cycles, missing references, duplicates.\n\nExamples:\n\n- Input (Codex TUI): /tm-overview\n- Output: tables and lists as specified. Keep to &lt;= 200 lines.\n\nNotes:\n\n- Read-only. Assume statuses: pending | in_progress | blocked | done.\n- If tasks.json is missing or invalid, output an \"## Errors\" section with a concise diagnosis.\n</code></pre>"},{"location":"temp-prompts-organized/_shared/tm/refine.tm/","title":"Refine","text":"<pre><code># Refine Task into Subtasks\n\nTrigger: /tm-refine\n\nPurpose: Expand a vague or large task into actionable subtasks with clear acceptance criteria.\n\nSteps:\n\n1. Load the task by id and analyze description for ambiguity and scope.\n2. Propose 3\u20138 subtasks with titles, brief descriptions, and dependencies between them.\n3. Define acceptance criteria per subtask using Given/When/Then or bullet checks.\n4. Suggest test coverage and doc updates triggered by completion.\n\nOutput format:\n\n- \"# Refinement: &lt;id&gt;\"\n- Subtasks as a Markdown table: id_suggested | title | depends_on | acceptance.\n- \"## JSON Patch\" fenced code of suggested additions suitable for tasks.json editing.\n\nExamples:\n\n- Input: /tm-refine TM-09\n- Output: table plus a minimal JSON Patch array.\n\nNotes:\n\n- Do not assume authority to change files; provide patches the user can apply.\n</code></pre>"},{"location":"temp-prompts-organized/_templates/instruction-file.templates/","title":"Instruction file","text":"<pre><code>---\nphase: \"P0 Preflight Docs\"\ngate: \"DocFetchReport\"\nstatus: \"capture approved instructions before proceeding.\"\nprevious:\n  - \"Preflight discovery (AGENTS baseline)\"\nnext:\n  - \"/planning-process\"\n  - \"/scope-control\"\n---\n\n# Instruction File\n\nTrigger: /instruction-file\n\nPurpose: Generate or update `cursor.rules`, `windsurf.rules`, or `claude.md` with project-specific instructions.\n\n## Steps\n\n1. Scan repo for existing instruction files.\n2. Compose sections: Context, Coding Standards, Review Rituals, Testing, Security, Limits.\n3. Include \"Reset and re-implement cleanly\" guidance and scope control.\n4. Write to chosen file and propose a commit message.\n\n## Output format\n\n- Markdown instruction file with stable headings.\n</code></pre>"},{"location":"temp-prompts-organized/_templates/prompt-sequence-generator.templates/","title":"Prompt sequence generator","text":"<pre><code># Prompt: Generate Prompt Execution Sequence\n\n**Purpose:** Given a high-level goal and a set of available prompts, generate the logical execution sequence required to accomplish that goal by chaining the prompts together.\n\n---\n\n### **Inputs**\n\n*   **High-Level Goal:** {{high_level_goal}}\n    *   *A clear, one-sentence description of the final outcome the user wants to achieve.*\n    *   *Example: \"Create and document a pull request for the currently staged changes.\"*\n\n*   **Available Prompts:**\n    ```\n    {{available_prompts}}\n    ```\n    *   *A list of candidate prompt names (e.g., from the output of `rank-root-prompts`).*\n    *   *Example: ['pr-desc.md', 'commit-msg.md', 'changed-files.md', 'review.md', 'release-notes.md']*\n\n*   **Context (Optional):** {{context}}\n    *   *Any additional context, such as the current state of the git repository or specific files of interest.*\n    *   *Example: \"The user has already staged files using `git add`.\"*\n\n---\n\n### **Instructions for the AI**\n\n1.  **Analyze the Goal:** Deconstruct the `{{high_level_goal}}` into a series of logical steps required to get from the starting state to the final outcome.\n\n2.  **Map Prompts to Steps:** For each logical step, identify the most suitable prompt from the `{{available_prompts}}` list that can perform that step.\n    *   Consider the inputs and outputs of each prompt to determine dependencies. A prompt's input is often the output of a previous one.\n\n3.  **Establish Order:** Arrange the selected prompts into a numbered sequence based on their dependencies. The sequence should represent a complete and logical workflow.\n\n4.  **Identify Gaps:** If any necessary step in the workflow cannot be fulfilled by one of the available prompts, explicitly state what action or prompt is missing.\n\n---\n\n### **Required Output Format**\n\n**Execution Sequence:**\n\n1.  **`[prompt_name_1.md]`**: [Brief justification for why this prompt is first and what it accomplishes.]\n2.  **`[prompt_name_2.md]`**: [Brief justification for why this prompt is second, and how it uses the output of the previous step.]\n3.  ...\n\n**Identified Gaps (if any):**\n\n*   [Description of a missing step or prompt needed to complete the workflow.]\n</code></pre>"},{"location":"temp-prompts-organized/_templates/system-level-instruction-editor.templates/","title":"System-level instruction editor","text":"<pre><code>phase: \"P0 Preflight Docs\"\ngate: \"Scope Gate\"\nstatus: \"draft\"\nowner: \"Prompt Ops\"\ndate: \"2025-09-20\"\nprevious:\n  - \"/instruction-file.md\"\n  - \"/planning-process.md\"\nnext:\n  - \"/AGENTS.md\"\n  - \"/GEMINI.md\"\ntags:\n  - \"instructions\"\n  - \"editor\"\n---\n\n# System Instruction: Canonical Instruction File Editor\n\nTrigger: /&lt;slash-command&gt;\n\nPurpose: &lt;1\u20132 lines describing the objective and outcome criteria.&gt;\n\n## Inputs\n\n- &lt;logs/artifacts to collect&gt;\n- &lt;affected services/modules&gt;\n- &lt;build/version/commit&gt;\n- &lt;time window/region/tenant&gt;\n- &lt;SLO/SLA impacted&gt;\n\n## Steps\n\n1. Collect relevant data (&lt;test logs, traces, metrics, dumps, repro steps&gt;).\n2. Group by symptom/pattern; for each group, list 2\u20133 plausible causes.\n3. Propose disambiguators (instrumentation, targeted inputs, experiments).\n4. Sketch minimal fixes (patches/config toggles/rollbacks) with risk notes.\n5. Validate fixes (tests to run, monitors to watch, acceptance criteria).\n6. Roll out &amp; verify (staged rollout plan, owners, ETA).\n7. Capture follow-ups (refactors, docs, guardrails).\n\n1. **Deconstruct the request:** Identify the user\u2019s intent and the minimal set of sections that should be added or updated.\n2. **Locate insertion points:** Use semantic matching on headings and content to find the best-fit sections for the user\u2019s request. If no clear section exists, create a new minimal section with a logically consistent title.\n3. **Apply minimal coherent change:** Insert or modify content to satisfy the request while preserving tone, structure, and cross-references. Keep unrelated sections unchanged.\n4. **Run invariants:**\n\n   - The entire file must be present (no placeholders, no truncation).\n   - Markdown structure and formatting must remain valid.\n   - Internal references and links stay accurate.\n5. **Render in Canvas:**\n\n   - If editing an existing file: open in Canvas and **replace the full contents** with the updated version.\n   - If creating a new file: create it in Canvas and display the **entire file**.\n6. **Variants (optional or on request):** Generate `GEMINI.md` and/or `CLAUDE.md` from the updated `AGENTS.md` using only the Platform Substitution Rules. Render each variant\u2019s **entire file** in Canvas (one file per Canvas operation).\n7. **Size-limit fallback:** If a size cap prevents full-file rendering in Canvas, output the **entire file in chat**, then append:\n\n   - \u201c*Note: Full content was output in chat due to a size limit preventing Canvas rendering.*\u201d\n\n## Output format\n\n- Table: &lt;symptom/item&gt; \u2192 &lt;likely causes&gt; \u2192 &lt;next checks&gt; \u2192 &lt;candidate fix&gt; \u2192 &lt;owner/ETA&gt;.\n\n## Example rows\n\n- \"&lt;example symptom or error&gt;\" \u2192 &lt;cause A, cause B&gt; \u2192 &lt;check 1, check 2&gt; \u2192 &lt;fix sketch&gt; \u2192 &lt;owner/ETA&gt;.\n</code></pre>"},{"location":"temp-prompts-refactored/3-step-process-b4-refactoring/","title":"3-step process (pre-refactor)","text":"<pre><code>&lt;!-- $1 = task description (e.g., \"Refactor email configuration\") --&gt;\n&lt;!-- $2 = list of files to modify (e.g., [\"src/config/email.ts\"]) --&gt;\n&lt;!-- $3 = sample refactor file path (e.g., \"src/config/email.ts\") --&gt;\n\n**Refactoring Pre-Refactor Process**\n\n# 3-step-process-b4-refactoring\n\n## describe the task and call the plan tool\n1. $1. Draft a plan (don't code)\n\n## identify target files for modification\n2. Conduct code analysis to determine files requiring modification: $2\n\n## provide sample refactor implementation\n3. Provide a sample refactor for $3\n</code></pre>"},{"location":"temp-prompts-refactored/Prompt-Optimizer/","title":"Prompt Optimizer","text":"<pre><code>&lt;!-- $1=User's raw prompt, $2=Role name (optional), $3=Number of variants (1-4) --&gt;\n\n**Prompt Optimization Template**\n\nYou are **$2** \u2014 Prompt Optimization Specialist. Transform any raw user prompt into up to **4 concise, high-leverage variants** that preserve intent while improving clarity, constraints, and outcome specificity.\n\n**Your job**\n\n- Keep the user\u2019s original goal intact. Remove fluff, tighten verbs, and make deliverables and success criteria explicit.\n- Resolve ambiguity with **neutral defaults** or **clearly marked placeholders** like `{context}`, `{inputs}`, `{constraints}`, `{acceptance_criteria}`, `{format}`, `{deadline}`.\n- Add structure (steps, bullets, numbered requirements) only when it improves execution.\n- Match or gently improve the **tone** implied by the user (directive/spec-like, polite, collaborative). Never over-polish into marketing-speak.\n- Do **not** introduce tools, external data, or scope changes unless the user asked for them.\n- Prefer active voice, testable requirements, and measurable outputs.\n\n**Output rules**\n\n- Return **only** the variants, each in its **own fenced code block**. No commentary, no preamble, no trailing notes.\n- Produce **1\u20134 variants** (default 3). Stop at 4 unless the user explicitly requests more.\n- For each block, begin with a short bracketed style tag (e.g., `[Directive]`, `[Spec]`, `[Polite]`, `[QA-Ready]`) on the first line, then the optimized prompt on subsequent lines.\n\n**Optimization checklist (apply silently)**\n\n- Clarify objective and end artifact\n- Specify audience/user/environment if implied\n- Pin input sources and constraints\n- Define acceptance criteria and non-goals\n- State format/structure and length limits\n- Include edge cases or examples if hinted\n- Keep placeholders where user must decide\n- **Common pitfalls**: Ambiguous constraints, vague success metrics, over-engineering\n- **Expected output quality**: Clear deliverables, testable criteria, minimal fluff\n\n**Now optimize the next input.**\nUser prompt: $1\n</code></pre>"},{"location":"temp-prompts-refactored/action-diagram/","title":"Action diagram","text":"<pre><code># Action Diagram\n\n## Nodes\n\n- $1\n- $2\n\n## Edges\n\n- $3 -&gt; $4\n\n&lt;!--\nPlaceholder mapping:\n- $1 = node 1\n- $2 = node 2\n- $3 = edge start node\n- $4 = edge end node\n--&gt;\n</code></pre>"},{"location":"temp-prompts-refactored/adr-new/","title":"ADR \u2013 new","text":"<pre><code>&lt;!-- $1=project context source file, $2=example file path, $3=ADR title argument, $4=workflow triggers, $5=failing jobs, $6=proposed fixes, $7=evidence details --&gt;\n\n**Architecture Decision Record Drafting Prompt**\n\nYou are a CLI assistant to draft an Architecture Decision Record with pros/cons using the following inputs:\n\n1. Analyze project context from $1.\n2. Generate a concise ADR with Context, Decision, Status, Consequences. Title: $3.\n3. Synthesize insights into the output format with clear priorities and next steps.\n\n**Output Requirements**:\n- Provide a summary restating the goal.\n- Highlight $4, $5, and $6.\n- Document $7 to ensure maintainability.\n\n**Example Input**: $2\n\n**Expected Output**: Actionable summary aligned with output requirements.\n</code></pre>"},{"location":"temp-prompts-refactored/adr-new.refactor/","title":"ADR \u2013 new (refactor)","text":"<pre><code>**{$2 or Inferred Name}**\n\nYou are a CLI assistant to draft an Architecture Decision Record with pros/cons using the following inputs:\n\n1. Analyze project context from $1.\n2. Generate a concise ADR with Context, Decision, Status, Consequences. Title: $3.\n3. Synthesize insights into the output format with clear priorities and next steps.\n\n**Output Requirements**:\n- Provide a summary restating the goal.\n- Highlight $4, $5, and $6.\n- Document $7 to ensure maintainability.\n\n**Example Input**: $2\n\n**Expected Output**: Actionable summary aligned with output requirements.\n</code></pre>"},{"location":"temp-prompts-refactored/api-contract/","title":"API contract","text":"<pre><code>&lt;!-- $1 = trigger phrase (e.g., \"/api-contract 'accounts &amp; auth'\") --&gt;\n&lt;!-- $2 = domain (e.g., \"auth\") --&gt;\n&lt;!-- $3 = contract type (e.g., \"OpenAPI 3.1\", \"GraphQL\") --&gt;\n&lt;!-- $4 = contract file extension (e.g., \".yaml\", \".graphql\") --&gt;\n&lt;!-- $5 = output file path (e.g., \"apis/$2/$4\") --&gt;\n&lt;!-- $6 = changelog entry path (e.g., \"docs/api/CHANGELOG.md\") --&gt;\n&lt;!-- $7 = style convention (e.g., \"JSON:API\") --&gt;\n\n# API Contract Generator\n\nTrigger: $1\n\nPurpose: Author an initial $3 contract from requirements.\n\n**Steps:**\n\n1. Parse inputs and existing docs. If REST, prefer $3; if GraphQL, produce $3.\n2. Define resources, operations, request/response schemas, error model, auth, and rate limit headers.\n3. Add examples for each endpoint or type. Include pagination and filtering conventions.\n4. Save to $5.\n5. Emit changelog entry $6 with rationale and breaking-change flags.\n\n**Affected files:**\n- $5\n- $6\n\n**Output format:**\n- `Contract Path`: $4\n- `Design Notes`: $7\n- Fenced code block with spec body\n\n**Examples:**\n- `$1` \u2192 $5\n\n**Notes:**\n- Follow $7 style for REST unless specified.\n</code></pre>"},{"location":"temp-prompts-refactored/api-docs-local/","title":"API docs (local)","text":"<pre><code># API Docs Local\n\nTrigger: $1\n\nPurpose: $2\n\n## Steps\n\n$3\n\n## Output format\n\n$4\n\n\n---\n\n### Affected files\n\n- $5\n\n### Root cause\n\n- $6\n\n### Proposed fix\n\n- $7\n\n### Tests\n\n- $8\n\n### Docs gaps\n\n- $9\n\n### Open questions\n\n- $10\n</code></pre>"},{"location":"temp-prompts-refactored/api-usage/","title":"API usage","text":"<pre><code>&lt;!-- Placeholder mapping for api-usage.md:\n$1 = Example input symbol (e.g., 'HttpClient')\n$2 = API usage pattern (e.g., 'Key usages')\n$3 = Evidence type (e.g., 'File paths')\n$4 = Definition source (e.g., 'src/network/httpClient.ts')\n --&gt;\n\n**How to show internal API usage**\n\n1. Gather context by running `rg -n $1 . || grep -RIn $1 .`.\n2. Summarize common usage patterns and potential misuses for the symbol.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\n**Output format**\n\n- Begin with a concise summary that restates the goal: Show how an internal API is used across the codebase.\n- Organize details under clear subheadings so contributors can scan quickly.\n- Document the evidence you used so maintainers can trust the conclusion.\n\n**Example**\n\n- Input: $2\n- Expected output: \n  - Definition: $3\n  - Key usages: $4\n</code></pre>"},{"location":"temp-prompts-refactored/audit/","title":"Audit","text":"<pre><code># Audit\n\nTrigger: $1\n\nPurpose: $2\n\n## Steps\n\n1. Gather context by running `ls -la` for the top-level listing. Inspect $3, $4, $5, $6, $7, and $8 if present to understand shared conventions.\n2. Assess repository hygiene across documentation, testing, CI, linting, and security. Highlight gaps and existing automation.\n3. Synthesize the findings into a prioritized checklist with recommended next steps.\n\n## Output format\n\n- Begin with a concise summary that restates the goal: Audit repository hygiene and suggest improvements.\n- Offer prioritized, actionable recommendations with rationale.\n- Call out test coverage gaps and validation steps.\n- Highlight workflow triggers, failing jobs, and proposed fixes.\n\n## Missing sections\n\n* Affected files: $9\n* Root cause: $10\n* Proposed fix: $11\n* Tests: $12\n* Docs gaps: $13\n* Open questions: $14\n\n&lt;!--\n$1 = Trigger\n$2 = Purpose\n$3 = .editorconfig\n$4 = .gitignore\n$5 = .geminiignore\n$6 = .eslintrc.cjs\n$7 = .eslintrc.js\n$8 = tsconfig.json\n$9 = Affected files\n$10 = Root cause\n$11 = Proposed fix\n$12 = Tests\n$13 = Docs gaps\n$14 = Open questions\n--&gt;\n</code></pre>"},{"location":"temp-prompts-refactored/auth-scaffold/","title":"Auth scaffold","text":"<pre><code>&lt;!-- $1 = Template name (e.g., \"Auth Scaffold\") | $2 = Trigger command (e.g., \"/auth-scaffold &lt;oauth|email|oidc&gt;\") | $3 = Purpose statement (e.g., \"Scaffold auth flows, routes, storage, and a basic threat model\") | $4 = Steps list (e.g., \"1. Select provider...\") | $5 = Output format description (e.g., \"route list, config keys, and mitigations table\") | $6 = Example command (e.g., \"/auth-scaffold oauth\") | $7 = Security notes (e.g., \"Never print real secrets. Use placeholders in `.env.example`\") --&gt;\n\n# $1\n\nTrigger: $2\n\nPurpose: $3\n\n**Steps:**\n\n$4\n\n**Output format:** $5\n\n**Examples:** $6\n\n**Notes:** $7\n</code></pre>"},{"location":"temp-prompts-refactored/blame-summary/","title":"Blame summary","text":"<pre><code>&lt;!-- Placeholder mapping:\n$1 = git blame command with arguments\n$2 = example input file path\n$3 = expected output format description\n$4 = proposed refactor example snippet\n--&gt;\n**How-to: Summarize authorship hotspots**\n\n1. Gather context by running `git blame -w --line-porcelain $1 | sed -n 's/^author //p' | sort | uniq -c | sort -nr | sed -n '1,25p'` for the blame authors (top contributors first).\n2. Given the blame summary below, identify ownership hotspots and potential reviewers.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n- Begin with a concise summary that restates the goal: Summarize authorship hotspots for a file using git blame.\n- Organize details under clear subheadings so contributors can scan quickly.\n- Reference evidence from CODEOWNERS or git history for each owner suggestion.\n\nExample Input:\n$2\n\nExpected Output:\n$3\n\nProposed Fix Examples:\n$4\n</code></pre>"},{"location":"temp-prompts-refactored/changed-files/","title":"Changed files","text":"<pre><code>&lt;!-- Placeholders:  \n$1 = Task goal statement  \n$2 = Git command  \n$3 = File categories (added/modified/renamed/deleted)  \n$4 = Risky changes indicator  \n$5 = Output format requirements  \n$6 = Example input description  \n$7 = Expected output structure  \n--&gt;\n\nCLI Summary Prompt\n\n1. Gather context by running `$2`.\n2. List and categorize changed files: `$3`. Call out risky changes: `$4`.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: `$1`.\n- Document the evidence used: `$5`.\n\nExample Input:\n`$6`\n\nExpected Output:\n`$7`\n</code></pre>"},{"location":"temp-prompts-refactored/changelog-from-commits/","title":"Changelog from commits","text":"<pre><code>&lt;!-- $1=command syntax (e.g., \"since=v2.0.0 until=HEAD\"), $2=commit range (e.g., \"v2.0.0..HEAD\"), $3=change type category (e.g., \"Added\"), $4=change description (e.g., \"Import data from XLSX\"), $5=PR reference (e.g., \"#612\") --&gt;\n**Draft CHANGELOG From Commits**\n\nPurpose: Produce a first-draft six-section CHANGELOG block from commit messages and PR titles between $1.\n\nSteps:\n\n1. Inputs: `since=&lt;ref or tag&gt;` optional, `until=&lt;ref&gt;` default HEAD, `include_prs=true|false` default true.\n2. Gather data with:\n   - `git log --pretty=%H%x09%s%x09%b &lt;since&gt;.. &lt;until&gt;`\n   - If available, `gh pr view` for merged PR titles by commit SHA; else rely on merge commit subjects.\n3. Heuristics:\n   - Map types: `feat|add`\u2192$3, `fix|bug`\u2192$3, `perf|refactor|opt`\u2192$3, `deprecate`\u2192$3, `remove|drop`\u2192$3, `sec|cve|security`\u2192$3.\n   - Shorten to 12\u201380 chars. Strip scope parentheses.\n4. Emit Markdown with only non-empty sections and a short preface noting the range.\n\nExpected output:\n- Range preface line: `Range: $2`\n- Six-section Markdown block (each section starts with $3, followed by bullet points of $4 and $5)\n\nNotes:\n- This is a draft; run `/update-changelog` to finalize and create links.\n- Keep bullets user-facing; avoid internal refactor noise.\n</code></pre>"},{"location":"temp-prompts-refactored/changelog-verify/","title":"Changelog verify","text":"<p><pre><code>&lt;!-- $1 = target command (e.g., /changelog-verify) --&gt;\n&lt;!-- $2 = validation status (PASS|FAIL) --&gt;\n&lt;!-- $3 = line number in CHANGELOG --&gt;\n&lt;!-- $4 = reason for failure (e.g., \"Section order incorrect\") --&gt;\n&lt;!-- $5 = suggested normalized Markdown block --&gt;\n&lt;!-- $6 = unified diff to apply --&gt;\n\n# Verify CHANGELOG Completeness\n\nTrigger: $1\n\nPurpose: Check that the latest merge introduced a CHANGELOG entry with the six-section policy and that sections are concise and non-empty where applicable.\n\nSteps:\n\n1. Parse $1 and locate `## [Unreleased]` or the latest version heading.\n2. Validate presence and order of sections: Added, Changed, Deprecated, Removed, Fixed, Security.\n3. Flag anti-patterns: paragraphs longer than 2 lines, trailing periods, internal-only jargon, file paths, or empty sections left in place.\n4. Cross-check against commits since last tag to detect missing items.\n5. Emit a diagnostic report and a suggested patch to fix ordering and brevity issues.\n\nOutput format:\n\n- `$2`\n- Table of findings with line numbers ($3) and reasons ($4)\n- Suggested normalized Markdown block ($5)\n- Unified diff to apply ($6)\n\nExamples:\nInput \u2192 $1\nOutput \u2192\n</code></pre> $2 - $3: $4 - Missing section stub</p> <p>$5 <pre><code>Constraints:\n- Static analysis only; no network calls.\n- Treat any section with 0 bullets as removable unless policy requires stubs.\n</code></pre></p>"},{"location":"temp-prompts-refactored/check/","title":"Check","text":"<pre><code>**Editorconfig Adherence Check**\n\n&lt;!-- $1 = task description (e.g., \"Check adherence to .editorconfig across the repo\") --&gt;\n&lt;!-- $2 = command to run (e.g., \"git ls-files | sed -n '1,400p'\") --&gt;\n&lt;!-- $3 = output format requirements (e.g., \"prioritized recommendations with rationale\") --&gt;\n\nYou are a CLI assistant focused on helping contributors with the task: $1.\n\n1. Gather context by inspecting `$1`; running `$2`.\n2. From the listing and config, point out inconsistencies and propose fixes.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n- Begin with a concise summary that restates the goal: $1.\n- Offer prioritized, actionable recommendations with rationale: $3.\n- Highlight workflow triggers, failing jobs, and proposed fixes.\n\nCommon pitfalls to watch for:\n- Missing `.editorconfig` files in the repo\n- Inconsistent indentation settings across files\n- Ignoring OS-specific config overrides\n</code></pre>"},{"location":"temp-prompts-refactored/cleanup-branches/","title":"Cleanup branches","text":"<pre><code>&lt;!-- \n$1 = Specific trigger command (e.g., \"/cleanup-branches\")\n$2 = Purpose statement (e.g., \"Recommend which local branches are safe to delete and which to keep\")\n$3 = Context gathering commands (e.g., \"git branch --merged\", \"git branch --no-merged\", \"git for-each-ref...\")\n$4 = Branch suggestion instructions (e.g., \"Using the lists below, suggest local branches safe to delete and which to keep. Include commands to remove them if desired\")\n$5 = Synthesis instructions (e.g., \"Synthesize the insights into the requested format with clear priorities and next steps\")\n$6 = Output format requirements (e.g., \"Begin with a concise summary that restates the goal: Suggest safe local branch cleanup (merged/stale). Document the evidence you used so maintainers can trust the conclusion.\")\n$7 = Example input/output (e.g., \"Example Input: (none \u2013 command runs without arguments)\\nExpected Output: - Structured report following the specified sections.\")\n--&gt;\n\n**Cleanup Branches**\n\nTrigger: $1\n\nPurpose: $2\n\nYou are a CLI assistant focused on helping contributors with the task: $3.\n\n1. $4\n2. $5\n3. $6\n\nAffected files: Local branches\n\nOutput format:\n- $7\n</code></pre>"},{"location":"temp-prompts-refactored/commit-msg/","title":"Commit msg","text":"<pre><code>/*\nPlaceholder mapping:\n- $1 = Input description\n- $2 = Template name (default: 'commit-message')\n- $3 = Max placeholders (default: 7)\n*/\n\n**commit-message**\n\nInput description: $1\n\nOutput format:\n{\n  \"title\": \"\",\n  \"body\": \"\"\n}\n\nEnsure the output is a valid JSON object with the title and body fields.\n</code></pre>"},{"location":"temp-prompts-refactored/commit/","title":"Commit","text":"<pre><code># From Placeholders in prompts.md\n\nCommit title: $1\n\nCommit body:\n\n- Scope: $1\n- Summary: $2\n\nSuggested checklist:\n- run tests\n- run linters\n\n\n## Expected output format\n\n```json\n{\n  \"reasoning\": \"\",\n  \"template_markdown\": \"\"\n}\n</code></pre> <p>Note: Replace $1 with commit title, $2 with summary text. ```</p>"},{"location":"temp-prompts-refactored/compare-outputs/","title":"Compare outputs","text":"<pre><code>&lt;!-- $1=Trigger, $2=Purpose, $3=Steps, $4=Output format, $5=Recommendation --&gt;\n\n**Compare Outputs**\n\n- $1\n- $2\n- $3\n- $4\n\n**Recommended output format**\n\n- $1\n\n*Note: This template includes the following sections that were inferred to be relevant based on the context: Affected files, Root cause, Proposed fix, Tests, Docs gaps, Open questions.*\n</code></pre>"},{"location":"temp-prompts-refactored/content-generation/","title":"Content generation","text":"<pre><code># Content Generation\n\nTrigger: $1\n\nPurpose: $2\n\n## Steps\n\n$3\n\n## Output format\n\n$4\n\n&lt;!-- Placeholder mapping --&gt;\n\n$1 = Title of the content (e.g., 'Content Generation')\n$2 = Purpose statement (e.g., 'Draft docs, blog posts, or marketing copy aligned with the codebase')\n$3 = List of steps with numbers (e.g., '1. Read repo README and recent CHANGELOG or commits.\\n2. Propose outlines for docs and posts.\\n3. Generate content with code snippets and usage examples.')\n$4 = Description of output format (e.g., 'Markdown files with frontmatter and section headings.')\n</code></pre>"},{"location":"temp-prompts-refactored/coverage-guide/","title":"Coverage guide","text":"<pre><code># Coverage Guide\n\nTrigger: $1\n\nPurpose: $2\n\nYou are a CLI assistant focused on helping contributors with the task: $3\n\n1. Gather context by running `find . -name 'coverage*' -type f -maxdepth 3 -print -exec head -n 40 {} \\; 2&gt;/dev/null` for the coverage hints; running `git ls-files | sed -n '1,400p'` for the repo map.\n2. Using coverage artifacts (if available) and repository map, propose the highest\u2011ROI tests to add.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: $4\n- Offer prioritized, actionable recommendations with rationale.\n- Call out test coverage gaps and validation steps.\n\nExample Input:\n$5\n\nExpected Output:\n$6\n</code></pre>"},{"location":"temp-prompts-refactored/cross-check/","title":"Cross-check","text":"<pre><code># Conflict Resolver\n\nTrigger: $1\n\nPurpose: $2\n\nSteps:\n\n1. $3\n2. $4\n3. $5\n\nOutput format:\n</code></pre>"},{"location":"temp-prompts-refactored/cross-check/#6","title":"$6","text":"<ul> <li>$7 <pre><code>Examples:\n\n- $8\n\nNotes:\n\n- $9\n</code></pre></li> </ul>"},{"location":"temp-prompts-refactored/db-bootstrap/","title":"DB bootstrap","text":"<pre><code># DB Bootstrap\n\nTrigger: $1\n\nPurpose: $2\n\n**Steps:**\n\n1. Create $3 for local dev (skip for sqlite).\n2. Choose ORM/driver ($4) for SQL. Add migration config.\n3. Create $5 with baseline tables (users, sessions, audit_log).\n4. Add $6, $7, $8 scripts. Write seed data for local admin user.\n5. Update $9 with `DATABASE_URL` and test connection script.\n\n**Output format:** Migration plan list and generated file paths.\n\n**Examples:** $10 \u2192 $11\n\n**Notes:** Avoid destructive defaults; provide `--preview-feature` warnings if relevant.\n\n---\n\n### Affected files\n\n- $12: db/compose.yaml\n- $13: $5\n- $14: $6\n- $15: $7\n- $16: $8\n- $17: .env.example\n</code></pre>"},{"location":"temp-prompts-refactored/dead-code-scan/","title":"Dead code scan","text":"<pre><code># Dead Code Scan Template\n\n&lt;!-- $1 = command string (e.g., `rg -n \"export |module.exports|...`) --&gt;\n&lt;!-- $2 = goal statement (e.g., \"List likely dead or unused files and exports (static signals)\") --&gt;\n&lt;!-- $3 = purpose statement (e.g., \"Identify likely dead or unused files and exports using static signals\") --&gt;\n\n# Dead Code Scan\n\nTrigger: `/dead-code-scan`\n\nPurpose: $3\n\nYou are a CLI assistant focused on helping contributors with the task: $2.\n\n1. Gather context by running $1 for the file reference graph (best\u2011effort).\n2. From the search results, hypothesize dead code candidates and how to safely remove them.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: $2.\n- Document the evidence you used so maintainers can trust the conclusion.\n</code></pre>"},{"location":"temp-prompts-refactored/design-assets/","title":"Design assets","text":"<pre><code># Design Assets\n\nTrigger: $1\n\nPurpose: $2\n\n## Steps\n\n1. $3\n2. $4\n3. $5\n\n## Output format\n\n- $6\n</code></pre>"},{"location":"temp-prompts-refactored/devops-automation/","title":"DevOps automation","text":"<pre><code>&lt;!-- Placeholder mapping: \n$1 = Trigger (e.g., \"/devops-automation\")\n$2 = Purpose (e.g., \"Configure servers, DNS, SSL, CI/CD at a pragmatic level\")\n$3 = Step 1 (e.g., \"Inspect repo for IaC or deploy scripts\")\n$4 = Step 2 (e.g., \"Generate Terraform or Docker Compose templates if missing\")\n$5 = Step 3 (e.g., \"Propose CI workflows for tests, builds, and deploys\")\n$6 = Step 4 (e.g., \"Provide runbooks for rollback\")\n$7 = Output format description (e.g., \"Infra plan with checkpoints and secrets placeholders\")\n$8 = Affected files (optional)\n$9 = Root cause (optional) --&gt;\n\n**Automation Prompt Template**\n\n# DevOps Automation\n\n$1\n\n$2\n\n## Steps\n\n1. $3\n2. $4\n3. $5\n4. $6\n\n## Output format\n- $7\n\n### Affected files\n- $8\n\n### Root cause\n- $9\n\n### Proposed fix\n- $10\n\n### Tests\n- $11\n\n### Docs gaps\n- $12\n\n### Open questions\n- $13\n</code></pre>"},{"location":"temp-prompts-refactored/docs-fulfilled-100/","title":"Docs fulfilled 100","text":"<pre><code>&lt;!--\n$1 = Source file path (e.g., /home/user/.codex/prompts/temp-prompts/docs-fulfilled-100.md)\n$2 = User's question\n$3 = Status of documentation fulfillment (e.g., 100%)\n$4 = Required additional information\n$5 = List of missing documentation items\n$6 = Proposed actions to fulfill docs\n$7 = Expected output format\n--&gt;\n\n**Docs fulfilled $3**\n\nTo fulfill the plan $3, what docs are missing now? Do you need more information from $1 or $2 to solve this task $3 correctly? Just tell me.\n\n---\n\nAffected files:\n- $1\n\nRoot cause:\n- $4\n\nProposed fix:\n- $5\n\nTests:\n- $6\n\nDocs gaps:\n- $7\n</code></pre>"},{"location":"temp-prompts-refactored/e2e-runner-setup/","title":"E2E runner setup","text":"<pre><code>/*\nPlaceholder mapping:\n$1 = Trigger\n$2 = Purpose\n$3 = Steps\n$4 = Output format\n$5 = Examples\n$6 = Notes\n$7 = Affected files\n$8 = Root cause\n$9 = Proposed fix\n$10 = Tests\n$11 = Docs gaps\n$12 = Open questions\n*/\n\n# $1\n\n**$2**\n\n**$3**:\n\n1. $4\n2. $5\n3. $6\n\n**$7**:\n\n```markdown\n$8\n</code></pre> <p>Examples:</p> <p><code>$9</code></p> <p>Notes:</p> <p>$10 ```</p>"},{"location":"temp-prompts-refactored/env-setup/","title":"Env setup","text":"<pre><code>&lt;!-- $1=trigger command, $2=purpose description, $3=step list, $4=output format, $5=example command, $6=security notes --&gt;\n\n**Env Setup**\n\nTrigger: $1\n\nPurpose: $2\n\n**Steps:**\n\n$3\n\n**Output format:** $4\n\n**Examples:** $5\n\n**Notes:** $6\n</code></pre>"},{"location":"temp-prompts-refactored/error-analysis/","title":"Error analysis","text":"<pre><code># Error Analysis\n\nTrigger: $1\n\nPurpose: $2\n\n## Steps\n\n1. $3\n2. $4\n3. $5\n4. $6\n\n## Output format\n\n- Table: $7 \u2192 $8 \u2192 $9 \u2192 $10\n\n## Examples\n\n- $11\n</code></pre>"},{"location":"temp-prompts-refactored/eslint-review/","title":"ESLint review","text":"<pre><code>/*\n* Placeholders:\n* $1 = task description (e.g., 'Review ESLint config and suggest rule tweaks')\n* $2 = context sources (e.g., '.eslintrc.cjs', '.eslintrc.js', 'package.json')\n* $3 = key rules (e.g., 'no-unused-vars')\n* $4 = missing plugins (e.g., 'eslint-plugin-react')\n* $5 = performance considerations (e.g., 'avoid expensive rules')\n* $6 = expected output format (e.g., 'structured report')\n* $7 = next steps (e.g., 'document evidence')\n*/\n\n**How-to: ESLint Review**\n\n1. Gather context by inspecting $1; inspecting $2; inspecting $3.\n2. Explain key rules, $4, and $5.\n3. Synthesize insights into $6 with clear priorities and $7.\n\n---\n\n### Affected files\n- $1\n\n### Root cause\n- Missing $4\n\n### Proposed fix\n- Add $4 to configuration\n\n### Tests\n- Verify $4 with example code\n\n### Docs gaps\n- Document $5 in contribution guidelines\n\n### Open questions\n- How to optimize $5 for large projects?\n</code></pre>"},{"location":"temp-prompts-refactored/evidence-capture/","title":"Evidence capture","text":"<pre><code>&lt;!-- Placeholder mapping (from input fields):\n$1 = Claim text\n$2 = Source URL\n$3 = Source Title\n$4 = Publisher\n$5 = Publication Date\n$6 = Access Date\n$7 = Quote (\u226425 words) --&gt;\n\n# Evidence Logger\n\nTrigger: /evidence-capture\n\nPurpose: Capture sources for a specified claim with dates, \u226425-word quotes, findings, relevance, and confidence.\n\nSteps:\n\n1. Read the claim text and optional URLs provided.\n2. For each source, record metadata and a \u226425-word quote.\n3. Add a brief Finding, Relevance (H/M/L), and Confidence (0.0\u20131.0).\n\nOutput format:\n</code></pre>"},{"location":"temp-prompts-refactored/evidence-capture/#evidence-log","title":"Evidence Log","text":"SourceID Title Publisher URL PubDate Accessed Quote (\u226425w) Finding Rel Conf <pre><code>Examples:\n\n- Input: `/evidence-capture $1` with $2\n- Output: Evidence table entries with dates.\n\nNotes:\n\n- Mark missing PubDate as n/a. Prefer official documentation.\n</code></pre>"},{"location":"temp-prompts-refactored/explain-code/","title":"Explain code","text":"<pre><code>&lt;!-- $1=Title, $2=Trigger command, $3=Purpose description, $4=Step 1, $5=Step 2, $6=Step 3, $7=Output format description --&gt;\n\n**Code Explanation Template**\n\n# $1\n\nTrigger: $2\n\nPurpose: $3\n\n## Steps\n\n1. $4\n\n2. $5\n\n3. $6\n\n## Output format\n\n$7\n</code></pre>"},{"location":"temp-prompts-refactored/explain-failures/","title":"Explain failures","text":"<pre><code>&lt;!-- $1=Task description; $2=Root cause analysis; $3=Proposed fixes; $4=Affected files; $5=Test coverage impact; $6=Open questions; $7=Example input context --&gt;\n**Test Failure Analysis Template**\n\n1. **Task Context**: Analyze recent test failures and propose fixes for $1.\n2. **Root Cause Analysis**: Identify root causes from $2.\n3. **Proposed Fixes**: Provide concrete fixes for $3.\n4. **Affected Files**: List files impacted by $4.\n5. **Test Coverage Impact**: Note how fixes affect test coverage ($5).\n6. **Open Questions**: Document unresolved issues ($6).\n\n**Output Format**:\n- Begin with a concise summary restating $1.\n- Prioritized recommendations with rationale for $2 and $3.\n- Evidence used to maintain trust ($4).\n\n**Example Context**:\n$7\n</code></pre>"},{"location":"temp-prompts-refactored/explain-symbol/","title":"Explain symbol","text":"<pre><code>**Symbol Explanation Analysis**\n\n&lt;!-- $1 = Symbol to explain (e.g., \"HttpClient\") --&gt;\n&lt;!-- $2 = Definition location (e.g., \"src/network/httpClient.ts line 42\") --&gt;\n&lt;!-- $3 = Key usages (e.g., \"services/userService.ts, hooks/useRequest.ts\") --&gt;\n\nOutput:\n- Begin with a concise summary reiterating the goal: Explain where and how $1 is defined and used.\n- Structure findings under clear subheadings for quick scanning.\n- Document evidence: $2 (definition) and $3 (key usages).\n- Note documentation gaps: [specify any missing documentation or context]\n</code></pre>"},{"location":"temp-prompts-refactored/feature-flags/","title":"Feature flags","text":"<pre><code>&lt;!-- $1=Title, $2=Trigger command pattern, $3=Purpose statement, $4=Step-by-step implementation steps, $5=Expected output format description, $6=Example command, $7=Critical implementation notes --&gt;\n\n**How-to**\n\n$1\n\n**Trigger:** $2\n\n**Purpose:** $3\n\n**Steps:** $4\n\n**Output format:** $5\n\n**Examples:** $6\n\n**Notes:** $7\n</code></pre>"},{"location":"temp-prompts-refactored/file-modularity/","title":"File modularity","text":"<pre><code>&lt;!-- Placeholder mapping:\n$1 = file paths\n$2 = threshold values (e.g., &gt;500 lines)\n$3 = extraction targets (components, hooks, utilities, schemas)\n$4 = before/after examples\n$5 = import updates\n$6 = refactor plan\n$7 = patch details --&gt;\n\n**File Modularity**\n\nTrigger: $1\n\nPurpose: Enforce smaller files and propose safe splits for giant files.\n\n## Steps\n\n1. Find files over thresholds ($2).\n2. Suggest extraction targets: $3.\n3. Provide before/after examples and $5.\n\n## Output format\n\n- $6\n\n---\n\n### Affected files\n\n- $1\n\n### Root cause\n\n- Files exceeding size thresholds\n\n### Proposed fix\n\n- $4\n- $5\n\n### Tests\n\n- Unit tests for extracted components\n\n### Docs gaps\n\n- Documentation for new file structure\n\n### Open questions\n\n- How to handle circular dependencies\n- Should we include type definitions in the extraction?\n</code></pre>"},{"location":"temp-prompts-refactored/fix/","title":"Fix","text":"<p><pre><code># Fix\n\nTrigger: $1\n\nPurpose: $2\n\nYou are a CLI assistant focused on helping contributors with the task: $3\n\n1. Gather context by running `git log --pretty='- %h %s' -n 20` for the recent commits; running `git ls-files | sed -n '1,400p'` for the repo map (first 400 files).\n2. $4: $5\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: $6\n- Provide unified diff-style patches when recommending code changes.\n- Offer prioritized, actionable recommendations with rationale.\n\nExample Input:\n$7\n\nExpected Output:\n</code></pre> $8 <pre><code>Regression test: $9\n</code></pre></p>"},{"location":"temp-prompts-refactored/gemini-map/","title":"Gemini map","text":"<pre><code>&lt;!-- $1=source TOML command name, $2=CLI command, $3=tags, $4=conversion scope, $5=translation steps, $6=example TOML input, $7=expected output structure --&gt;\n\n**Gemini\u2192Codex Mapper**\n\nYou are a translator that converts a $1 TOML command into a Codex prompt file.\n\nSteps:\n\n1) Read TOML with `description` and `prompt`.\n2) Extract the task, inputs, and outputs implied by the TOML.\n3) Write a Codex prompt file \u2264 300 words:\n\n    - Role line `You are ...`\n    - Numbered steps\n    - Output section\n    - Example input and expected output\n    - `Usage: /$2` line\n    - YAML-like metadata at top\n\n4) Choose a short, hyphenated filename \u2264 32 chars.\n5) Emit a ready-to-run bash snippet:\n`cat &gt; ~/.codex/prompts/&lt;filename&gt;.md &lt;&lt; 'EOF'` \u2026 `EOF`.\n6) Do not include destructive commands or secrets.\n\nExample input:\n\n```toml\n$6\n</code></pre> <p>Expected output:</p> <p>A $7 file with the structure above and a bash cat &gt; block.</p> <p>Usage: /$2</p> <p>Output format</p> <p>The output must be a Codex prompt file containing: - Role line: \"You are a translator that converts a $1 TOML command into a Codex prompt file.\" - Numbered steps (1-6) matching $5 - Output section specifying the format - Example input and expected output - <code>Usage: /$2</code> line - YAML metadata: <code>name: $1</code>, <code>command: $2</code>, <code>tags: $3</code>, <code>scope: $4</code></p> <p>ensure - \u22647 placeholders - no verbatim sentences from input - literal <code>$</code> tokens remain ```</p>"},{"location":"temp-prompts-refactored/generate-readme/","title":"Generate README","text":"<pre><code># $1\n\n$2\n\n## Features\n- $3\n\n## Setup\n```bash\n$4\n</code></pre>"},{"location":"temp-prompts-refactored/generate-readme/#usage","title":"Usage","text":"<pre><code>$5\n</code></pre>"},{"location":"temp-prompts-refactored/generate-readme/#contributing","title":"Contributing","text":"<p>$6</p>"},{"location":"temp-prompts-refactored/generate-readme/#license","title":"License","text":"<p>$7</p>"},{"location":"temp-prompts-refactored/generate-readme/#additional-info","title":"Additional Info","text":"<ul> <li>Version: $8</li> <li>Author: $9</li> <li>Last Updated: $10 ```</li> </ul>"},{"location":"temp-prompts-refactored/generate/","title":"Generate","text":"<pre><code>&lt;!-- Placeholder mapping:\n- $1 = Trigger command (e.g., \"/generate &lt;source-file&gt;\")\n- $2 = Purpose statement (e.g., \"Generate unit tests for a given source file\")\n- $3 = Step 1 description\n- $4 = Step 2 description\n- $5 = Step 3 description\n- $6 = Step 4 description\n- $7 = Output summary requirement\n- $8 = Output test file list\n- $9 = Output test case description\n- $10 = Output validation command\n- $11 = Output evidence description --&gt;\n\n**Generate Unit Tests**\n\nTrigger: $1\n\nPurpose: $2\n\nYou are a CLI assistant focused on helping contributors with the task: $2.\n\n## Steps\n\n1. $3\n2. $4\n3. $5\n4. $6\n\n## Output\n\n- $7\n- $8\n- $9\n- $10\n- $11\n</code></pre>"},{"location":"temp-prompts-refactored/grep/","title":"Grep","text":"<pre><code>&lt;!-- $1=Search term (e.g., \"HttpClient\"), $2=Example input, $3=Expected output format --&gt;\n**CLI Search Guide**\n\nYou are a CLI assistant focused on helping contributors with the task: Recursive text search with ripgrep/grep injection.\n\n1. Gather context by running `rg -n $1 . || grep -RIn $1 .`.\n2. Show matched lines with file paths and line numbers.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Recursive text search with ripgrep/grep injection.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\n$2\n\nExpected Output:\n$3\n</code></pre>"},{"location":"temp-prompts-refactored/iac-bootstrap/","title":"IaC bootstrap","text":"<pre><code>&lt;!-- $1=Template name (e.g., \"IaC Bootstrap\"), $2=Platform (aws/gcp/azure/fly/render), $3=Purpose statement, $4=Step-by-step implementation steps, $5=Required output formats, $6=Example command syntax, $7=Implementation notes and common pitfalls --&gt;\n**$1**\n\n**Trigger:** `/iac-bootstrap $2`\n\n**Purpose:** $3\n\n**Steps:** \n1. $4\n2. $4\n3. $4\n4. $4\n\n**Output format:** $5\n\n**Examples:** $6\n\n**Notes:** $7\n</code></pre>"},{"location":"temp-prompts-refactored/instruction-file/","title":"Instruction file","text":"<pre><code>&lt;!-- Placeholder mapping:\n$1 = Trigger\n$2 = Purpose\n$3 = Step 1 description\n$4 = Step 2 description\n$5 = Step 3 description\n$6 = Step 4 description\n$7 = Output format description --&gt;\n\n**How-to: Create Instruction File**\n\n# Instruction File\n\nTrigger: $1\n\nPurpose: $2\n\n## Steps\n\n1. $3\n2. $4\n3. $5\n4. $6\n\n## Output format\n\n- $7\n\n---\n\n### Affected files\n- `cursor.rules`\n- `windsurf.rules`\n- `claude.md`\n\n### Root cause\n- *No specific root cause identified in this context*\n\n### Proposed fix\n- *Not applicable; this is a template for creating new instructions*\n\n### Tests\n- *Not applicable; this is a template for creating new instructions*\n\n### Docs gaps\n- *Not applicable; this is a template for creating new instructions*\n\n### Open questions\n- *Not applicable; this is a template for creating new instructions*\n</code></pre>"},{"location":"temp-prompts-refactored/integration-test/","title":"Integration test","text":"<pre><code>&lt;!-- $1=trigger command, $2=purpose statement, $3=output format --&gt;\n\n**E2E Test Generation Prompt**\n\n# Integration Test\n\nTrigger: $1\n\nPurpose: $2\n\n## Steps\n\n1. Detect framework from `package.json` or repo (Playwright/Cypress/Vitest).\n2. Identify critical path scenarios from `PLAN.md`.\n3. Produce test files under `e2e/` with arrange/act/assert and selectors resilient to DOM changes.\n4. Include login helpers and data setup. Add CI commands.\n\n## Output format\n\n- $3\n\n## Examples\n\n- Login, navigate to dashboard, create record, assert toast.\n\n## Notes\n\n- Prefer data-test-id attributes. Avoid brittle CSS selectors.\n</code></pre>"},{"location":"temp-prompts-refactored/license-report/","title":"License report","text":"<pre><code>&lt;!-- $1=Task description, $2=Command to run, $3=License inventory line format (e.g., \"MIT (12)\"), $4=Risk level (e.g., \"low risk\"), $5=Remediation note (e.g., \"requires legal review\") --&gt;\n\nYou are a CLI assistant focused on helping contributors with the task: $1.\n\n1. Gather context by running $2 for license tools if present.\n2. Create a license inventory with notices of copyleft/unknown licenses.\n3. Synthesize insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary that restates the goal: $1.\n- Organize details under clear subheadings so contributors can scan quickly.\n- Flag copyleft or unknown licenses and suggest remediation timelines.\n\nExample Input:\n(none \u2013 command runs without arguments)\n\nExpected Output:\n\n- $3 \u2014 $4\n- $3 \u2014 $5\n</code></pre>"},{"location":"temp-prompts-refactored/logging-strategy/","title":"Logging strategy","text":"<pre><code>&lt;!-- $1 = Title (e.g., \"Logging Strategy\") --&gt;\n&lt;!-- $2 = Trigger path (e.g., \"/logging-strategy\") --&gt;\n&lt;!-- $3 = Purpose statement (e.g., \"Add or remove diagnostic logging cleanly with levels and privacy in mind\") --&gt;\n&lt;!-- $4 = Step 1 description (e.g., \"Identify hotspots from recent failures\") --&gt;\n&lt;!-- $5 = Step 2 description (e.g., \"Insert structured logs with contexts and correlation IDs\") --&gt;\n&lt;!-- $6 = Step 3 description (e.g., \"Remove noisy or PII-leaking logs\") --&gt;\n&lt;!-- $7 = Step 4 description (e.g., \"Document log levels and sampling in `OBSERVABILITY.md`\") --&gt;\n\n# $1\n\nTrigger: $2\n\nPurpose: $3\n\n## Steps\n\n$4\n\n$5\n\n$6\n\n$7\n\n## Output format\n\n- Diff hunks and a short guideline section.\n</code></pre>"},{"location":"temp-prompts-refactored/migration-plan/","title":"Migration plan","text":"<pre><code>&lt;!-- \n$1 = trigger phrase (e.g., \"/migration-plan\")\n$2 = change summary (e.g., \"orders add status enum\")\n$3 = current vs target schema description\n$4 = migration steps details\n$5 = online migration strategies for large tables\n$6 = SQL snippets\n$7 = PR checklist items\n$8 = rollback capability flag (can_rollback: true|false)\n--&gt;\n\n**Migration Plan Template**\n\nTrigger: $1\n\nPurpose: Produce safe up/down migration steps with checks and rollback notes.\n\n**Steps:**\n\n1. $3\n2. $4\n\n**Output format:** `Plan`, `SQL`, `Rollback`, `Checks` sections.\n\n**Examples:** $2.\n\n**Notes:** $5\n\n**Additional requirements:** $6 and $7 with $8 flag.\n</code></pre>"},{"location":"temp-prompts-refactored/missing-docs/","title":"Missing docs","text":"<pre><code>/*\n  $1 = Original prompt text\n  $2 = 'Missing Docs' (inferred genre)\n  $3 = Max placeholders (default=7)\n*/\n\n**Missing Docs**\n\n(See the source markdown for the full context)\n\nThe following sections are required to complete this analysis:\n\n- **Affected files**: $1\n- **Root cause**: $2\n- **Proposed fix**: $3\n- **Tests**: $4\n- **Docs gaps**: $5\n- **Open questions**: $6\n- **Additional context**: $7\n</code></pre>"},{"location":"temp-prompts-refactored/model-evaluation/","title":"Model evaluation","text":"<pre><code>/*\nPlaceholder mapping:\n$1 = Trigger phrase\n$2 = Purpose statement\n$3 = Step 1 (define benchmark)\n$4 = Step 2 (run candidates)\n$5 = Step 3 (analyze failures)\n$6 = Output format description\n$7 = Expected metrics (optional)\n*/\n\n# Model Evaluation\n\n$1\n\nPurpose: $2\n\n## Steps\n\n1. $3\n2. $4\n3. $5\n\n## Output format\n\n$6\n\n---\n\n**Expected sections** (add if missing):\n- Expected metrics\n- Failure analysis\n- Adoption recommendations\n</code></pre>"},{"location":"temp-prompts-refactored/model-strengths/","title":"Model strengths","text":"<pre><code>&lt;!-- Placeholders: $1=Title, $2=Trigger, $3=Purpose, $4=Steps, $5=Output format --&gt;\n\n**Model Strengths**\n\n(Trigger: $1)\n\n(Purpose: $2)\n\n($3)\n\n($4)\n\n(Recommended output format: $5)\n</code></pre>"},{"location":"temp-prompts-refactored/modular-architecture/","title":"Modular architecture","text":"<pre><code># Modular Architecture\n\nTrigger: $1\n\nPurpose: $2\n\n## Steps\n\n$3\n\n## Output format\n\n$4\n\n---\n\n### Affected files\n\n*To be filled*\n\n### Root cause\n\n*To be filled*\n\n### Proposed fix\n\n*To be filled*\n\n### Tests\n\n*To be filled*\n\n### Docs gaps\n\n*To be filled*\n\n### Open questions\n\n*To be filled*\n</code></pre>"},{"location":"temp-prompts-refactored/monitoring-setup/","title":"Monitoring setup","text":"<pre><code># Monitoring Setup\n\nTrigger: $1\n\nPurpose: $2\n\n**Steps:**\n\n1. $3\n2. $4\n3. $5\n\n**Output format:** $6\n\n**Examples:** $7\n\n**Notes:** $8\n\n---\n\n# Affected files\n\n# Root cause\n\n# Proposed fix\n\n# Tests\n\n# Docs gaps\n\n# Open questions\n</code></pre>"},{"location":"temp-prompts-refactored/openapi-generate/","title":"OpenAPI generate","text":"<pre><code># OpenAPI Generate\n\nTrigger: $1\n\nPurpose: $2\n\n**Steps:**\n\n1. $3\n2. $4\n3. $5\n4. $6\n5. $7\n\n**Output format:** $8\n\n**Examples:** $9\n\n**Notes:** $10\n\n---\n\n## Affected files\n\n## Root cause\n\n## Proposed fix\n\n## Tests\n\n## Docs gaps\n\n## Open questions\n</code></pre>"},{"location":"temp-prompts-refactored/owners/","title":"Owners","text":"<pre><code>&lt;!-- $1=Path argument, $2=Task goal, $3=Codeowners file path, $4=Git log command, $5=Example path, $6=Output format structure, $7=Owner names --&gt;\n\n**Owners Suggestion Prompt**\n\nYou are a CLI assistant focused on helping contributors with the task: $2.\n\n1. Gather context by inspecting $3 for codeowners (if present); running $4 for recent authors of the path.\n2. Based on codeowners and git history, suggest owners.\n3. Synthesize the insights into the requested format with clear priorities.\n\nOutput:\n- Begin with a concise summary restating the goal: $2\n- Reference evidence from $3 or git history for each owner suggestion.\n- Document the evidence used to maintain trust.\n\nExample input: $5\n\nExpected output:\n- Likely reviewers: $6 ($7)\n</code></pre>"},{"location":"temp-prompts-refactored/plan-delta/","title":"Plan delta","text":"<pre><code>&lt;!-- $1=command, $2=purpose, $3=tasks file path pattern, $4=latest plan doc pattern, $5=artifacts directory, $6=date format string, $7=mode selection rules --&gt;\n\n**How-to: $2**\n\nTrigger: $1\n\nPurpose: $2\n\nSteps:\n\n1. Discover repository context:\n   1. Detect tasks file path: prefer $3; else search `**/$3`.\n   2. Detect latest plan doc: prefer $4; else `**/*(prd|spec|plan)*.md`.\n2. Snapshot:\n   1. Create $5 if missing.\n   2. Copy current tasks file to `$5/tasks-$(date +%$6).json` using: `cp -f &lt;tasks.json&gt; $5/tasks-$(date +%$6).json`.\n3. Input collection:\n   1. Read new objectives, constraints, and findings from user input.\n   2. Parse selection rules to choose mode: **$7**.\n4. Delta Doc generation:\n   1. Create `$5/delta-$(date +%$6).md` containing sections:\n      - Objectives (new)\n      - Constraints (new)\n      - Impacts\n      - Decisions\n      - Evidence log (sources, dates, links)\n5. Task graph update:\n   1. Never alter historical states (`done`/`in_progress`/`blocked`) of existing tasks.\n   2. Do not reuse IDs. For replaced tasks, set `superseded_by` on old tasks and include ID in new task's `supersedes[]`.\n   3. Add `source_doc`, `lineage[]` on new/changed tasks.\n   4. Create new tasks only for new/changed work. Link predecessors via `dependencies` or `relations`.\n   5. Keep deprecated tasks with `status: \"deprecated\"` and `reason`.\n6. **Tests**:\n   1. Recompute dependency order and validate acyclicity.\n   2. Flag contradictions as `blocked` with machine-readable `blocked_reason`.\n   3. Verify critical-path tasks are correctly prioritized.\n7. **Affected files**:\n   - $5/tasks-$(date +%$6).json\n   - $5/delta-$(date +%$6).md\n8. Readiness and selection:\n   1. Implement `ready/next()` to select tasks with all dependencies `done` and not `blocked`.\n   2. Produce readiness report grouped by `ready | blocked | deprecated`.\n9. Outputs:\n   1. Write updated tasks file in-place.\n   2. Persist Delta Doc under $5.\n   3. Emit decision hooks: one line per change stating what it enables.\n\n**Output format**:\n- Produce three artifacts:\n  1. **Updated tasks file**: Valid JSON. Preserve existing fields. Append new/changed tasks and relations.\n  2. **Delta document**: Markdown with sections `# Delta`, `## Objectives`, `## Constraints`, `## Impacts`, `## Decisions`, `## Evidence`.\n  3. **Readiness report**: Plain text with sections `READY`, `BLOCKED`, `DEPRECATED`. Format: `- &lt;id&gt; &lt;title&gt;` (blocked items add `[reason=&lt;code&gt;]`).\n- Print **Decision hooks** as lines starting with `HOOK: &lt;id&gt; enables &lt;capability&gt;`.\n\n**Open questions**:\n- What evidence is missing to resolve inputs?\n- How to handle partial scope changes (&lt;20%)?\n- Should deprecated tasks be automatically archived?\n</code></pre>"},{"location":"temp-prompts-refactored/planning-process/","title":"Planning process","text":"<pre><code>**Planning Process Prompt**\n\n&lt;!-- $1 = Feature description (e.g., \"Add OAuth login\") --&gt;\n&lt;!-- $2 = Plan file name (e.g., \"PLAN.md\") --&gt;\n&lt;!-- $3 = Max checklist line length (e.g., \"100 chars\") --&gt;\n\n# Planning Process\n\nTrigger: $2\n\nPurpose: Draft, refine, and execute a feature plan with strict scope control and progress tracking.\n\n## Steps\n\n1. If no plan file exists, create $2. If it exists, load it.\n2. Draft sections: **Goal**, **User Story**, **Milestones**, **Tasks**, **Won't do**, **Ideas for later**, **Validation**, **Risks**.\n3. Trim bloat. Convert vague bullets into testable tasks with acceptance criteria.\n4. Tag each task with an owner and estimate. Link to files or paths that will change.\n5. Maintain two backlogs: **Won't do** (explicit non-goals) and **Ideas for later** (deferrable work).\n6. Mark tasks done after tests pass. Append commit SHAs next to completed items.\n7. After each milestone: run tests, update **Validation**, then commit $2.\n\n## Output format\n\n- Update or create $2 with the sections above.\n- Include a checklist for **Tasks**. Keep lines under $3 chars.\n\n## Examples\n**Input**: $1\n\n**Output**:\n\n- Goal: Let users sign in with Google.\n- Tasks: [ ] add Google client, [ ] callback route, [ ] session, [ ] E2E test.\n- Won't do: org SSO.\n- Ideas for later: Apple login.\n\n## Notes\n\n- Planning only. No code edits.\n- Assume a Git repo with test runner available.\n</code></pre>"},{"location":"temp-prompts-refactored/pr-desc/","title":"PR desc","text":"<pre><code>&lt;!-- \n$1 = Input context path (e.g., \"src/example.ts\")\n$2 = Base branch (e.g., \"origin/main\")\n$3 = User context (e.g., \"&lt;args&gt;\")\n$4 = High-level diff stats (e.g., \"2 files changed, 10 insertions\")\n$5 = List of changed files (e.g., \"src/example.ts\")\n$6 = Desired output structure (e.g., \"Summary, Context, Changes, Screenshots, Risk, Test Plan, Rollback, Release Notes\")\n$7 = Example output (e.g., \"Actionable summary...\")\n--&gt;\n\n**PR Description Template**\n\nTrigger: /pr-desc $1\n\nPurpose: Draft a PR description from the branch diff.\n\n1. Gather context by running `git diff --name-status $5` for the changed files; `git diff --shortstat $4` for high-level stats.\n2. Create a crisp PR description following this structure: $6\n   - Base branch: $2\n   - User context: $3\n3. Synthesize insights into the requested format.\n\nOutput requirements:\n- Begin with a concise summary: $7\n- Prioritized recommendations with rationale\n- Test coverage gaps and validation steps\n- Workflow triggers, failing jobs, and proposed fixes\n\nAffected Files: $5\nRoot Cause: [Optional]\nProposed Fix: [Optional]\nTest Plan: [Optional]\nRisk: [Optional]\nRollback Plan: [Optional]\nRelease Notes: [Optional]\n</code></pre>"},{"location":"temp-prompts-refactored/prd-generator/","title":"PRD generator","text":"<pre><code>&lt;!-- $1=project plan text (visible link text), $2=product name, $3=problem statement, $4=key constraints --&gt;\n**PRD Generator Template**\n\nOutput a plain-text file named `prd.txt` containing **only** these sections in this order (separated by one blank line):\n# Overview\n# Core Features\n# User Experience\n# Technical Architecture\n# Development Roadmap\n# Logical Dependency Chain\n# Risks and Mitigations\n# Appendix\n\n**Output Format**\n\n- `# Overview`: $3\n- `# Core Features`: Each includes *What*, *Why*, *High-level How*, and BDD criteria:\n  `Given ...`\n  `When ...`\n  `Then ...`\n- `# User Experience`: Personas, key flows, UI/UX, accessibility\n- `# Technical Architecture`: Components, data models, APIs/integrations, infrastructure, NFRs\n- `# Development Roadmap`: MVP and Future Enhancements with acceptance criteria (no dates)\n- `# Logical Dependency Chain`: Work ordering for foundations, earliest front end, extensible units\n- `# Risks and Mitigations`: Each includes *Description*, *Likelihood*, *Impact*, *Mitigation*\n- `# Appendix`:\n  \u2022 Assumptions (bulleted)\n  \u2022 Research findings from $1\n  \u2022 Context notes (`- &lt;visible text&gt; \u2014 inferred topic`)\n  \u2022 Technical specs\n\n**Validation Checks**\n\n- Headers present and ordered\n- All BDD criteria included for features/fallbacks\n- Risks include likelihood and impact\n- No URLs/secrets; exactly one blank line between sections\n- $1 contains **only** visible link text (no external browsing)\n</code></pre>"},{"location":"temp-prompts-refactored/prettier-adopt_Migration_report/","title":"Prettier migration report","text":"<pre><code>&lt;!--\n$1=Task description\n$2=Template name (inferred as 'Prettier Migration Guide')\n$3=Summary of the report\n$4=Prioritized recommendations\n$5=Rationale for recommendations\n$6=Evidence used\n$7=Example input (none)\n$8=Expected output structure\n--&gt;\n\n**$2**\n\n1. $1\n\n2. $3\n\n3. $4\n\n4. $5\n\n5. $6\n\n6. $7\n\n7. $8\n\n\n---\n\n### Affected files\n\n- $1 (to be populated with file paths)\n\n### Root cause\n\n- $1 (to be populated with migration challenges)\n\n### Proposed fix\n\n- $1 (to be populated with specific steps)\n\n### Tests\n\n- $1 (to be populated with test cases)\n\n### Docs gaps\n\n- $1 (to be populated with missing documentation)\n\n### Open questions\n\n- $1 (to be populated with unresolved issues)\n</code></pre>"},{"location":"temp-prompts-refactored/problem-analyzer/","title":"Problem analyzer","text":"<pre><code>&lt;!-- Placeholder mapping:\n$1 = Affected files\n$2 = Root cause\n$3 = Proposed fix\n$4 = Tests\n$5 = Documentation gaps\n$6 = Open questions/assumptions --&gt;\n\n# problem-analyzer\n\n&lt;problem&gt;\n$1\n&lt;/problem&gt;\n\n**Tasks:**\n1. Locate all files/modules affected by the issue. List paths and why each is implicated.\n2. Explain the root cause(s): what changed, how it propagates to the failure, and any environmental factors.\n3. Propose the minimal, safe fix. Include code-level steps, side effects, and tests to add/update.\n4. Flag any missing or outdated documentation/configs/schemas that should be updated or added (especially if code appears outdated vs. current behavior).\n\n**Output format:**\n- **Affected files:**\n  - `$1`: `&lt;reason&gt;`\n- **Root cause:**\n  - `$2`: `&lt;concise explanation&gt;`\n- **Proposed fix:**\n  - `$3`: `&lt;steps/patch outline&gt;`\n  - **Tests:**\n- **Documentation gaps:**\n  - `$4`: `&lt;doc_section_what_to_update_add&gt;`\n- **Open questions/assumptions:**\n  - `$5`: `&lt;items&gt;`\n\n**DON'T CODE YET.**\n</code></pre>"},{"location":"temp-prompts-refactored/prompt-sequence-generator/","title":"Prompt sequence generator","text":"<pre><code># Prompt: Generate Prompt Execution Sequence\n\n**Purpose:** Given a high-level goal and a set of available prompts, generate the logical execution sequence required to accomplish that goal by chaining the prompts together.\n\n---\n\n### **Inputs**\n\n*   **High-Level Goal:** {{high_level_goal}}\n    *   *A clear, one-sentence description of the final outcome the user wants to achieve.*\n    *   *Example: \"Create and document a pull request for the currently staged changes.\"*\n\n*   **Available Prompts:**\n    ```\n    {{available_prompts}}\n    ```\n    *   *A list of candidate prompt names (e.g., from the output of `rank-root-prompts`).*\n    *   *Example: ['pr-desc.md', 'commit-msg.md', 'changed-files.md', 'review.md', 'release-notes.md']*\n\n*   **Context (Optional):** {{context}}\n    *   *Any additional context, such as the current state of the git repository or specific files of interest.*\n    *   *Example: \"The user has already staged files using `git add`.\"*\n\n---\n\n### **Instructions for the AI**\n\n1.  **Analyze the Goal:** Deconstruct the `{{high_level_goal}}` into a series of logical steps required to get from the starting state to the final outcome.\n\n2.  **Map Prompts to Steps:** For each logical step, identify the most suitable prompt from the `{{available_prompts}}` list that can perform that step.\n    *   Consider the inputs and outputs of each prompt to determine dependencies. A prompt's input is often the output of a previous one.\n\n3.  **Establish Order:** Arrange the selected prompts into a numbered sequence based on their dependencies. The sequence should represent a complete and logical workflow.\n\n4.  **Identify Gaps:** If any necessary step in the workflow cannot be fulfilled by one of the available prompts, explicitly state what action or prompt is missing.\n\n---\n\n### **Required Output Format**\n\n**Execution Sequence:**\n\n1.  **`[prompt_name_1.md]`**: [Brief justification for why this prompt is first and what it accomplishes.]\n2.  **`[prompt_name_2.md]`**: [Brief justification for why this prompt is second, and how it uses the output of the previous step.]\n3.  ...\n\n**Identified Gaps (if any):**\n\n*   [Description of a missing step or prompt needed to complete the workflow.]\n</code></pre>"},{"location":"temp-prompts-refactored/prototype-feature/","title":"Prototype feature","text":"<pre><code># Prototype Feature\n\nTrigger: $1\n\nPurpose: $2\n\n## Steps\n\n$3\n\n## Output format\n\n- $4\n</code></pre>"},{"location":"temp-prompts-refactored/query-set/","title":"Query set","text":"<pre><code>&lt;!-- Placeholder mapping:\n$1 = Goal statement\n$2 = Number of queries (4-8)\n$3 = Time window (e.g., 'past year')\n$4 = Input entities (e.g., 'OpenAI Responses API streaming server-sent events')\n$5 = Query types (e.g., 'define, compare, integrate') --&gt;\n\n**High-Yield Query Generator**\n\nTrigger: /query-set\n\nPurpose: Generate {1} targeted web search queries with operators, entity variants, and recency filters for a given objective.\n\nSteps:\n1. Restate the goal with entities and time window.\n2. Produce queries using operators: site:, filetype:, inurl:, quotes, OR, date filters.\n3. Include synonyms and common misspellings.\n4. Mix intents: {2}\n\nOutput format:\n</code></pre>"},{"location":"temp-prompts-refactored/query-set/#goal","title":"Goal","text":"<p>{3}</p>"},{"location":"temp-prompts-refactored/query-set/#query-set","title":"Query Set","text":"<ul> <li>{4}</li> <li>{5} ... up to 8 <pre><code>Examples:\n- Input: `/query-set {6} {7}`\n- Output: Goal + {8} queries with operators.\n\nNotes:\n- No evidence logging here. Use /research-item to execute.\n</code></pre></li> </ul>"},{"location":"temp-prompts-refactored/rank-root-prompts/","title":"Rank root prompts","text":"<pre><code>&lt;!--\n$1 = command name/identifier\n$2 = example user question\n$3 = project root path to scan (defaults to \"~/.codex/prompts\" when omitted/blank)\n$4 = minimum relevance threshold (0\u20131)\n--&gt;\n\n# {Prompt Ranking Command}\n\n```md\n# Command: $1\n\n# Usage: $1 \"$2\" \"$3\" \"$4\"\n\n# Args:\n\n# - {{query}}: $2\n# - {{path}}: $3\n# - {{threshold}}: $4\n\nprompt = \"\"\"\nTask:\nGiven a user inquiry {{query}}, review prompt-definition files located at {{path}} and identify the most relevant ones.\n\nDefaults:\n* If {{path}} is missing or blank, use \"~/.codex/prompts\".\n\nDo the following:\n1) List files in {{path}} without descending into subfolders. Treat common doc/config extensions as candidates.\n2) Read each candidate\u2019s text and summarize its purpose + domain in one sentence.\n3) Compute a relevance score in [0,1] between that summary and {{query}}.\n4) Order all candidates by score (highest first).\n5) Emit a compact table with exactly these columns: filename | description | match_score (rounded to 2 decimals).\n\nRules:\n* The description must be 1\u20132 sentences capturing purpose and domain.\n* Only include rows with match_score \u2265 {{threshold}}.\n* If none satisfy {{threshold}}, output a single line: \"No prompt exceeds threshold {{threshold}} \u2014 recommend creating a new prompt.\"\n\nAcceptance:\n* When \u22651 match meets {{threshold}}, a table sorted by descending match_score is present.\n* Otherwise, the single-line note is produced.\n\n!{echo \"Using path: ${PATH_ARG:-~/.codex/prompts}\"}\n\"\"\"\n</code></pre>"},{"location":"temp-prompts-refactored/rank-root-prompts/#output-format","title":"Output format","text":"<ul> <li>Preferred: a markdown table with columns <code>filename | description | match_score</code> sorted by <code>match_score</code> (desc) and filtered by <code>{{threshold}}</code>.</li> <li> </li> </ul>"},{"location":"temp-prompts-refactored/rank-root-prompts/#fallback-the-exact-one-line-message-when-no-entries-meet-threshold","title":"Fallback: the exact one-line message when no entries meet <code>{{threshold}}</code>.","text":"```"},{"location":"temp-prompts-refactored/refactor-file/","title":"Refactor file","text":"<pre><code># Refactor Analysis\n\n&lt;!-- Placeholder mapping:  \n$1 = File path (e.g., src/components/Button.tsx)\n$2 = Before/after snippet (code diff)\n$3 = Evidence used (e.g., lines 1-400 of file)\n$4 = Refactor goal (e.g., extract shared styling hook)\n$5 = Summary (concise restatement of goal)\n$6 = Complexity reduction justification (why refactoring improves readability)\n$7 = Next steps (actionable items for maintainers) --&gt;\n\n**Refactor Analysis**\n\n1. Gather context by running `sed -n '1,400p' $1` for the first 400 lines of the file.\n2. Suggest refactors that reduce complexity and improve readability without changing behavior. Provide $2 with commentary.\n3. Synthesize insights into $5 with clear priorities and $7.\n\n**Output Format**\n\n- Begin with a concise summary: $5\n- Include $2 with commentary\n- Document evidence: $3\n\n*Note: $4 is implied by the refactoring goal but can be explicitly stated for clarity*\n</code></pre>"},{"location":"temp-prompts-refactored/refactor-suggestions/","title":"Refactor suggestions","text":"<pre><code># Refactor Suggestions\n\nTrigger: $1\n\nPurpose: $2\n\n## Steps\n\n$3\n\n## Output format\n\n$4\n\n\n### Affected files\n\n\n### Root cause\n\n\n### Proposed fix\n\n\n### Tests\n\n\n### Docs gaps\n\n\n### Open questions\n\n\n---\n\n&lt;!-- Placeholder mapping --&gt;\n\n- $1 = Trigger (e.g., /refactor-suggestions)\n- $2 = Purpose (e.g., Propose repo-wide refactoring opportunities after tests exist)\n- $3 = Steps (e.g., Map directory structure and large files. \\n2. Identify duplication, data clumps, and god objects. \\n3. Suggest phased refactors with safety checks and tests.)\n- $4 = Output format (e.g., Ranked list with owners and effort estimates.)\n</code></pre>"},{"location":"temp-prompts-refactored/reference-implementation/","title":"Reference implementation","text":"<pre><code>&lt;!-- $1=Template title, $2=Trigger command, $3=Purpose statement, $4=Step 1 description, $5=Step 2 description, $6=Step 3 description, $7=Output format description --&gt;\n\n**How-to**\n\n# $1\n\nTrigger: $2\n\nPurpose: $3\n\n## Steps\n\n1. $4\n2. $5\n3. $6\n\n## Output format\n\n- $7\n</code></pre>"},{"location":"temp-prompts-refactored/regression-guard/","title":"Regression guard","text":"<pre><code>&lt;!-- Placeholder mapping: \n$1 = Title\n$2 = Purpose\n$3 = Step 1\n$4 = Step 2\n$5 = Step 3\n$6 = Output format\n$7 = Notes --&gt;\n\n**Regression Guard**\n\nTrigger: $1\n\nPurpose: $2\n\n## Steps\n\n$3\n$4\n$5\n\n## Output format\n\n$6\n\n## Notes\n\n$7\n\n\n### Affected files\n\n### Root cause\n\n### Proposed fix\n\n### Tests\n\n### Docs gaps\n\n### Open questions\n</code></pre>"},{"location":"temp-prompts-refactored/release-notes-prepare/","title":"Release notes prepare","text":"<pre><code># Prepare Release Notes From CHANGELOG\n\nTrigger: `/release-notes-prepare`\n\nPurpose: Convert the latest CHANGELOG section into release notes suitable for GitHub Releases with the six-section layout.\n\nSteps:\n\n1. Detect latest version heading and extract its section.\n2. Normalize bullets to sentence fragments without trailing periods.\n3. Add short highlights at top (3 bullets max) derived from Added/Changed.\n4. Emit a \"copy-ready\" Markdown body.\n\nOutput format:\n\n- Title line: `Release ${1} \u2014 ${2}`\n- Highlights list\n- Six sections with bullets\n\n&lt;!-- Placeholder mapping --&gt;\n${1}=Version (e.g., 1.6.0)\n${2}=Release date (e.g., 2025-09-22)\n${3}=Highlight 1 (e.g., Custom roles and permissions)\n${4}=Highlight 2 (e.g., Faster cold starts)\n${5}=Highlight 3 (optional)\n${6}=Added section content\n${7}=Changed section content\n\n**Note**: This template follows the six-section layout (Added, Changed, Removed, Fixed, Improved, Deprecated). Missing sections like Removed, Fixed, Improved, Deprecated are implied by the context and will be populated with the appropriate content from CHANGELOG.\n</code></pre>"},{"location":"temp-prompts-refactored/release-notes/","title":"Release notes","text":"<pre><code>&lt;!-- $1=git-range argument, $2=commit log output, $3=change categories (e.g., Features, Fixes), $4=input file path, $5=specific change entry, $6=summary text, $7=evidence description --&gt;\n\n## How to Generate Release Notes\n\nTrigger: /release-notes $1\n\nPurpose: Generate human-readable release notes from recent commits.\n\nYou are a CLI assistant focused on helping contributors with the task: Generate human\u2011readable release notes from recent commits.\n\n1. Gather context by running `git log --pretty='* %s (%h) \u2014 %an' --no-merges $2` for the commit log (no merges).\n2. Produce release notes grouped by type $3. Include a Highlights section and a full changelog list.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n\n- Begin with a concise summary: $6\n- Document the evidence: $7\n\nExample Input:\n$4\n\nExpected Output:\n## $3\n\n- $5\n</code></pre>"},{"location":"temp-prompts-refactored/research-batch/","title":"Research batch","text":"<pre><code>**Conversation-Aware Research \u2014 Batch WBRO**\n\nTrigger: $1\n\nPurpose: Process a numbered work-breakdown list of objectives with carry-forward context across items and produce a roll-up summary.\n\nSteps:\n\n1. Parse numbered WBRO items from the input after the trigger.\n2. Before Item 1: list \u22645 bullets of starting context.\n3. For each item i: execute the per-item workflow and include a Conversation State Update.\n4. If blocked by prior gaps, emit **Dependency Blocked** with a minimal micro-query.\n5. After all items: emit a Roll-up Summary with per-item status, enabled decisions, unresolved risks, and a domain-type count of sources.\n\nOutput format:\n\n- Repeat the single-item format per item.\n- End with:\n</code></pre>"},{"location":"temp-prompts-refactored/research-batch/#roll-up-summary","title":"Roll-up Summary","text":"<ul> <li>Item $2: $3 \u2014 decision enabled: $4; risks: $5</li> <li>Sources by domain type: $6, $7 <pre><code>Examples:\n- Input: `/research-batch $1`\n- Output: Per-item sections plus roll-up.\n\nNotes:\n- Keep quotes \u226425 words. Prefer primary docs.\n\n&lt;!-- Placeholder mapping --&gt;\n- $1: Input WBRO items (e.g., \"1) Validate Next.js 15 stability. 2) Compare Bun vs Node for CI. 3) Licensing risks for MIT vs Apache-2.0.\")\n- $2: Item number (e.g., \"1\")\n- $3: Status (e.g., \"Completed\")\n- $4: Enabled decisions (e.g., \"Validate Next.js 15\")\n- $5: Unresolved risks (e.g., \"Licensing conflicts\")\n- $6: Domain type count (e.g., \"3\")\n- $7: Domain types (e.g., \"gov, org, docs, blog, news\") --&gt;\n</code></pre></li> </ul>"},{"location":"temp-prompts-refactored/research-item/","title":"Research item","text":"<pre><code>&lt;!-- Placeholders: $1=short title, $2=goal sentence, $3=assumption bullet, $4=first query, $5=second query, $6=third query, $7=fourth query to eighth query (range) --&gt;\n\n**Conversation-Aware Research**\n\n# Conversation-Aware Research \u2014 Single Item\n\nTrigger: /research-item\n\nPurpose: Run the full per-item research workflow for one objective and return queries, evidence, synthesis, contradictions, gaps, decision hook, plus a conversation state update.\n\nSteps:\n1. Read the objective text following the trigger.\n2. Capture starting context if provided.\n3. Apply the Process (per item): Goal, Assumptions, Query Set (4\u20138), Search Plan, Run &amp; Capture, Cross-check, Synthesis, Gaps &amp; Next, Decision Hook.\n4. Track PubDate and Accessed (ISO) for every source; prefer primary docs.\n5. Enforce quotes \u226425 words; mark inferences as \"Inference\".\n\nOutput format:\n</code></pre>"},{"location":"temp-prompts-refactored/research-item/#item-1-1","title":"Item 1: $1","text":""},{"location":"temp-prompts-refactored/research-item/#goal","title":"Goal","text":"<p>$2</p>"},{"location":"temp-prompts-refactored/research-item/#assumptions","title":"Assumptions","text":"<ul> <li>$3</li> </ul>"},{"location":"temp-prompts-refactored/research-item/#query-set","title":"Query Set","text":"<ul> <li>$4</li> <li>$5</li> <li>$6</li> <li>$7</li> </ul>"},{"location":"temp-prompts-refactored/research-item/#evidence-log","title":"Evidence Log","text":"SourceID Title Publisher URL PubDate Accessed Quote (\u226425w) Finding Rel Conf"},{"location":"temp-prompts-refactored/research-item/#synthesis","title":"Synthesis","text":"<ul> <li>$8</li> <li>$9</li> <li>$10</li> </ul>"},{"location":"temp-prompts-refactored/research-item/#contradictions","title":"Contradictions","text":"<ul> <li>$11 \u2192 $12</li> </ul>"},{"location":"temp-prompts-refactored/research-item/#gaps-next","title":"Gaps &amp; Next","text":"<ul> <li>$13</li> </ul>"},{"location":"temp-prompts-refactored/research-item/#decision-hook","title":"Decision Hook","text":"<p>$14</p>"},{"location":"temp-prompts-refactored/research-item/#conversation-state-update","title":"Conversation State Update","text":"<ul> <li>New facts: $15</li> <li>Constraints learned: $16</li> <li>Entities normalized: $17 <pre><code>Examples:\n- Input: `/research-item Compare OpenAPI 3.1 tooling for Python clients in 2024; budget $0; prefer official docs.`\n- Output: As per format with SourceIDs and dates.\n\nNotes:\n- Safety: No personal data. Do not fabricate sources.\n- Provenance: Cite reputable sources; record n/a for missing PubDate.\n</code></pre></li> </ul>"},{"location":"temp-prompts-refactored/reset-strategy/","title":"Reset strategy","text":"<pre><code># Reset Strategy\n\nTrigger: $1\n\nPurpose: $2\n\n## Steps\n\n$3\n$4\n$5\n$6\n\n## Output format\n\n- A short decision note and exact commands. Never execute resets automatically.\n\n## Examples\n\n- Recommend reset after repeated failing refactors touching $7\n\n## Notes\n\n- Warn about destructive nature. Require user confirmation.\n\n---\n\n### Missing Sections (Inferred for Analysis Context)\n\n- **Affected files**: $8\n- **Root cause**: $9\n- **Proposed fix**: $10\n- **Tests**: $11\n- **Docs gaps**: $12\n- **Open questions**: $13\n</code></pre>"},{"location":"temp-prompts-refactored/review-branch/","title":"Review branch","text":"<pre><code>/*\n\nPlaceholder mapping:\n$1 = Trigger\n$2 = Purpose\n$3 = Step 1 description\n$4 = Step 2 description\n$5 = Step 3 description\n$6 = Output requirements\n$7 = Example input (if applicable)\n*/\n\n# {template_name or Inferred Name}\n\n{Trigger}\n\n{Purpose}\n\n1. {Step 1}\n2. {Step 2}\n3. {Step 3}\n\n{Output Requirements}\n\n{Example Input}\n\n---\n\n### Analysis\n\n- **Affected files**: {Affected files}\n- **Root cause**: {Root cause}\n- **Proposed fix**: {Proposed fix}\n- **Tests**: {Tests}\n- **Docs gaps**: {Docs gaps}\n- **Open questions**: {Open questions}\n\n---\n\n### Output format\n\n- {Output format requirement}\n\n---\n\n*Note: Placeholders marked with `$1..$7` are to be filled with context-specific content from the input.*\n</code></pre>"},{"location":"temp-prompts-refactored/review/","title":"Review","text":"<pre><code># Review\n\nTrigger: $1\n\nPurpose: Review code matching $1 and deliver actionable feedback.\n\nYou are a CLI assistant focused on helping contributors with the task: Review code matching $1 and give actionable feedback.\n\n1. Gather context by running `rg -n $2 . || grep -RIn $2 .` for the search results for $2 (filename or regex).\n2. Perform a thorough code review. Focus on correctness, complexity, readability, security, and performance. Provide concrete patch suggestions.\n\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n- Begin with a concise summary that restates the goal: Review code matching $1 and give actionable feedback.\n- Provide unified diff-style patches when recommending code changes.\n- Organize details under clear subheadings so contributors can scan quickly.\n\nExample Input:\n$3\n\nExpected Output:\n- Usage cluster in src/network/* with note on inconsistent error handling.\n\n&lt;!-- Placeholders:\n- $1 = trigger pattern (e.g., `HttpClient`)\n- $2 = search pattern for code context (e.g., `HttpClient`)\n- $3 = example input pattern (e.g., `HttpClient`)\n --&gt;\n</code></pre>"},{"location":"temp-prompts-refactored/roll-up/","title":"Roll-up","text":"<pre><code>&lt;!-- $1 = trigger phrase (e.g., \"/roll-up\") --&gt;\n&lt;!-- $2 = purpose statement (e.g., \"Summarize per-item statuses, enabled decisions, unresolved risks, and count sources by domain type\") --&gt;\n&lt;!-- $3 = step 1 description (e.g., \"Aggregate Conversation State Updates from prior items\") --&gt;\n&lt;!-- $4 = step 2 description (e.g., \"Produce per-item status lines and decisions\") --&gt;\n&lt;!-- $5 = step 3 description (e.g., \"Tally sources by domain type: gov, org, docs, blog, news, academic\") --&gt;\n&lt;!-- $6 = output format template (e.g., the code block below) --&gt;\n&lt;!-- $7 = example input (e.g., \"/roll-up from items 1\u20133\") --&gt;\n\n# Research Roll-up Summary\n\nTrigger: $1\n\nPurpose: $2\n\nSteps:\n1. $3\n2. $4\n3. $5\n\nOutput format:\n</code></pre>"},{"location":"temp-prompts-refactored/roll-up/#roll-up-summary","title":"Roll-up Summary","text":"<ul> <li>Item {n}: {status} \u2014 decision enabled: {\u2026}; risks: {\u2026}</li> <li>Sources by domain type: {gov:X, org:Y, docs:Z, blog:A, news:B, academic:C} <pre><code>Examples:\n- Input: $7\n- Output: [see above]\n\nNotes:\n- Domain Count Analysis: $6 (explain why counts vary across domains)\n- Evidence Log Reference: Use counts derived from the Evidence Logs\n</code></pre></li> </ul>"},{"location":"temp-prompts-refactored/scaffold-fullstack/","title":"Scaffold (full-stack)","text":"<pre><code># Scaffold Full\u2011Stack App\n\nTrigger: $1\n\nPurpose: $2\n\n**Steps:**\n\n1. Read repository context: `git rev-parse --is-inside-work-tree`.\n2. If repo is empty, initialize: `git init -b main` and create `.editorconfig`, `.gitignore`, `README.md`.\n3. For $3 derive presets (examples):\n   - `$4`: Next.js app, Express API, Prisma + PostgreSQL, Playwright, pnpm workspaces.\n   - `$5`: Vite + React app, Fastify API, Drizzle + SQLite.\n4. Create workspace layout:\n   - root: `package.json` with `pnpm` workspaces, `tsconfig.base.json`, `eslint`, `prettier`.\n   - apps/web, apps/api, packages/ui, packages/config.\n5. Add scripts:\n   - root: `dev`, `build`, `lint`, `typecheck`, `test`, `e2e`, `format`.\n   - web: Next/Vite scripts. api: dev with ts-node or tsx.\n6. Seed CI files: `.github/workflows/ci.yml` with jobs [lint, typecheck, test, build, e2e] and artifact uploads.\n7. Add example routes:\n   - web: `/health` page. api: `GET /health` returning `{ ok: true }`.\n8. Write docs to `README.md`: how to run dev, test, build, and env variables.\n9. Stage files, but do not commit. Output a tree and next commands.\n\n**Output format:**\n- Title line: `Scaffold created: $6`\n- Sections: `Repo Tree`, `Next Steps`, `CI Seeds`.\n- Include a fenced code block of the `tree` and sample scripts.\n\n**Examples:**\n- **Input:** `$7`\n  **Output:** Summary + tree with `apps/web`, `apps/api`, `packages/ui`.\n- **Input:** `$8`\n  **Output:** Summary + tree + Drizzle config.\n\n**Notes:**\n- Assume pnpm and Node 20+. Do not run package installs automatically; propose commands instead.\n- Respect existing files; avoid overwriting without explicit confirmation.\n\n&lt;!-- Placeholder mapping: --&gt;\n- $1 = trigger command\n- $2 = purpose statement\n- $3 = stack preset name\n- $4 = example preset description\n- $5 = alternative example preset description\n- $6 = output title suffix\n- $7 = example input command\n- $8 = alternative example input command --&gt;\n</code></pre>"},{"location":"temp-prompts-refactored/scope-control/","title":"Scope control","text":"<pre><code>/* Placeholder mapping:\n$1 = Trigger\n$2 = Purpose\n$3 = Steps\n$4 = Output format\n$5 = Example input\n$6 = Example output\n$7 = Notes */\n\n**Scope Control**\n\n$1\n\n**Purpose**: $2\n\n**Steps**:\n1. $3\n2. $4\n3. $5\n4. $6\n\n**Output format**: $7\n\n### Examples\n- Input: $1\n- Output: $2\n\n### Notes\n- $3\n</code></pre>"},{"location":"temp-prompts-refactored/secrets-manager-setup/","title":"Secrets manager setup","text":"<pre><code>&lt;!--\n$1=Trigger phrase (e.g., \"/secrets-manager-setup &lt;provider&gt;\")\n$2=Purpose statement (e.g., \"Provision a secrets store and map application variables to it.\")\n$3=List of steps (e.g., \"1. Choose provider: 1Password, Doppler, AWS Secrets Manager, GCP Secret Manager, Vault.\")\n$4=Output format specification (e.g., \"mapping table `ENV_VAR \u2192 provider path` and bootstrap steps\")\n$5=Example command (e.g., \"/secrets-manager-setup doppler\")\n$6=Notes section (e.g., \"Never echo secret values. Include rotation policy.\")\n$7=Additional context (e.g., \"Applicable providers: 1Password, Doppler, AWS Secrets Manager, GCP Secret Manager, Vault.\")\n--&gt;\n\n**$2**\n\nTrigger: $1\n\nPurpose: $2\n\n**Steps:**\n\n$3\n\n**Output format:** $4\n\n**Examples:** $5\n\n**Notes:** $6\n\n**Affected files:** (to be filled)\n**Root cause:** (to be filled)\n**Proposed fix:** (to be filled)\n**Tests:** (to be filled)\n**Docs gaps:** (to be filled)\n**Open questions:** (to be filled)\n</code></pre>"},{"location":"temp-prompts-refactored/secrets-scan/","title":"Secrets scan","text":"<pre><code>&lt;!-- \n$1 = Core task description (e.g., \"Review secret scan output and highlight real leaks\")\n$2 = Command to run (e.g., \"gitleaks detect --no-banner --redact 2&gt;/dev/null\")\n$3 = Interpretation method (e.g., \"de-dupe false positives and propose rotations\")\n$4 = Output format requirement (e.g., \"structured report with prioritized recommendations\")\n$5 = Example input format (e.g., \"none \u2013 command runs without arguments\")\n$6 = Expected output structure (e.g., \"concise summary, prioritized recommendations, evidence documentation\")\n$7 = Specific evidence type (e.g., \"scanner results from gitleaks\")\n--&gt;\n**Secrets Scan Analysis**\n\n1. Gather context by running `$2` for the if `$2` is available, output will appear below.\n2. Interpret the scanner results using `$3` to de\u2011dupe false positives and propose rotations/remediation.\n3. Synthesize the insights into `$4` with clear priorities and next steps.\n\nOutput:\n- Begin with a concise summary restating `$1`\n- Offer prioritized, actionable recommendations with rationale\n- Document the evidence used for maintainers' trust\n\nExample Input:\n$5\n\nExpected Output:\n$6\n\nAffected files: \nRoot cause: \nProposed fix: \nTests: \nDocs gaps: \nOpen questions:\n</code></pre>"},{"location":"temp-prompts-refactored/slo-setup/","title":"SLO setup","text":"<pre><code>&lt;!-- Placeholders mapping:\n$1 = Template title (e.g., \"SLO Setup\")\n$2 = Command trigger (e.g., \"/slo-setup\")\n$3 = Purpose statement (e.g., \"Define Service Level Objectives, burn alerts, and runbooks.\")\n$4 = Implementation steps (e.g., \"1. Choose SLI/metrics per user journey... 2. Create burn alerts... 3. Add `SLO.md`...\")\n$5 = Output format specification (e.g., \"SLO table and alert rules snippet\")\n$6 = Example usage (e.g., \"/slo-setup\")\n$7 = Implementation notes (e.g., \"Tie SLOs to deploy gates and incident severity\")\n--&gt;\n\n**$1**\n\nTrigger: $2\n\nPurpose: $3\n\n**Steps:**\n\n$4\n\n**Output format:** $5\n\n**Examples:** $6\n\n**Notes:** $7\n</code></pre>"},{"location":"temp-prompts-refactored/stack-evaluation/","title":"Stack evaluation","text":"<pre><code>&lt;!-- $1=Template title (e.g., \"Stack Evaluation\"), $2=Trigger command, $3=Purpose statement, $4=First step description, $5=Second step description, $6=Third step description, $7=Output format description --&gt;\n**$1**\n\nTrigger: $2\n\nPurpose: $3\n\n## Steps\n\n1. $4\n2. $5\n3. $6\n\n## Output format\n\n- $7\n</code></pre>"},{"location":"temp-prompts-refactored/stop-guessing/","title":"Stop guessing","text":"<pre><code># stop guessing\n\n$1\n\nRespond with a JSON object in the following order of fields: `reasoning`, then `template_markdown`.\n</code></pre>"},{"location":"temp-prompts-refactored/summary-1/","title":"Summary 1","text":"<pre><code># Inferred Analysis Template\n\nYou are a CLI assistant helping contributors with the task: **$1**.\n\n1. **Context sweep.** Derive a repository map by running **$2** (first N entries are sufficient). Review **$3** for primary documentation.\n2. **Draft the summary.** Organize findings under **$4, $5, $6, $7**.\n3. **Synthesize.** Present a prioritized, action-oriented report with immediate next steps.\n\n## Report Structure\n\n### $4\n* \u2026\n\n### $5\n* \u2026\n\n### $6\n* \u2026\n\n### $7\n1. \u2026\n2. \u2026\n3. \u2026\n\n### Evidence Consulted\n* Repo map derived via: **$2**\n* Docs reviewed: **$3**\n* Noteworthy gaps or uncertainties: \u2026\n\n### Next Steps (Prioritized)\n1. \u2026\n2. \u2026\n3. \u2026\n\n### Open Questions\n* \u2026\n* \u2026\n\n---\n\n## Output format (for automation and reviews)\n* **Audience:** contributors and maintainers\n* **Tone:** concise, decision-ready\n* **Must include:** goal recap (**$1**), sections (**$4\u2013$7**), evidence, priorities, open questions\n* **Nice to have:** links to code paths, brief risk notes\n\n**Validation checklist**\n* [ ] All required sections present\n* [ ] Evidence lists commands/files used (**$2**, **$3**)\n* [ ] Priorities and next steps are explicit\n* [ ] Open questions are called out clearly\n\n&lt;!-- $1=task, $2=command, $3=docs, $4=primary section, $5=secondary section, $6=tertiary section, $7=quaternary section --&gt;\n</code></pre>"},{"location":"temp-prompts-refactored/summary-2/","title":"Summary 2","text":"<pre><code>&lt;!-- $1 = task description (e.g., \"summarize the project\") --&gt;\n&lt;!-- $2 = CLI command (e.g., \"git ls-tree\") --&gt;\n&lt;!-- $3 = file paths to inspect (e.g., \"docs/README.md\") --&gt;\n\n# $1\n\nYou are a CLI helper guiding contributors to accomplish: **$1**.\n\n## Scope &amp; Role\n\n* Operate in a repository working tree.\n* Run lightweight, read-only commands to gather context.\n* Synthesize findings into a concise, maintainer-friendly report.\n\n## Procedure\n\n1. **Map the repo (quick scan)** \u2014 run **$2** to capture a top-slice of the file tree for orientation.\n2. **Locate key docs** \u2014 check the paths in **$3** (if present) for project-level guidance.\n3. **Summarize the project** \u2014 draft a high-level overview covering:\n   * **Purpose** (what it is)\n   * **Motivation** (why it exists)\n   * **Architecture/Workflow** (how it works at a glance)\n   * **Getting Started** (how to begin using/developing)\n4. **Prioritize next steps** \u2014 identify immediate follow-ups for readers (e.g., areas to explore, gaps to fill).\n5. **Record evidence** \u2014 note exactly what you inspected so maintainers can verify.\n\n## Output\n\nBegin with a one-sentence restatement of **$1**, then provide the sections below in order:\n\n* **Project Summary** \u2014 purpose, motivation, architecture/workflow, getting started.\n* **Repo Snapshot** \u2014 brief map excerpt from **$2** (top of tree only).\n* **Evidence Log** \u2014 list the commands run and files/paths reviewed, including **$3**.\n* **Priorities &amp; Next Steps** \u2014 the most important actions to take next (short list).\n\n## Example Input\n\n(no arguments; run from the repo root)\n\n## Expected Result\n\nA structured report following the **Output** section above, optimized for README-level clarity and trustworthiness.\n\n## Output format (strict)\n\nProvide sections exactly in this order: Project Summary \u2192 Repo Snapshot \u2192 Evidence Log \u2192 Priorities &amp; Next Steps. Keep each section concise and actionable.\n</code></pre>"},{"location":"temp-prompts-refactored/summary/","title":"Summary","text":"<pre><code>&lt;!-- $1 = specific command to run for file listing --&gt;\n&lt;!-- $2 = target repo summary goal --&gt;\n&lt;!-- $3 = high-level summary sections (What, Why, How, Getting Started) --&gt;\n&lt;!-- $4 = requirement for documenting evidence --&gt;\n&lt;!-- $5 = output format specification --&gt;\n\n**Repository Summary Generator**\n\n1. Gather context by running `$1` for the repo map.\n2. Generate a high-level summary covering `$3`.\n3. Document evidence used to maintain trust in conclusions per `$4`.\n4. Output a structured report following `$5`.\n</code></pre>"},{"location":"temp-prompts-refactored/switch-model/","title":"Switch model","text":"<pre><code>&lt;!-- Placeholders: $1=Task type, $2=Model selection criteria, $3=Input suite, $4=Metrics, $5=Recommended model, $6=Rationale, $7=Output format --&gt;\n\n**Switch Model**\n\nTrigger: $1\n\nPurpose: Decide when to try a different AI backend and how to compare.\n\n## Steps\n\n1. Define task type: $2\n2. Select candidate models and temperature/tooling options.\n3. Run a fixed input suite: $3 and measure $4.\n4. Recommend a model per task: $5 with $6.\n\n## Output format\n\n- Table: task \u2192 model \u2192 settings \u2192 $7.\n</code></pre>"},{"location":"temp-prompts-refactored/system-level-instruction-editor/","title":"System-level instruction editor","text":"<pre><code>&lt;!-- Placeholder mapping:\n$1 = Title (System-level instruction)\n$2 = Purpose\n$3 = Inputs\n$4 = Steps\n$5 = Deconstruct request\n$6 = Locate insertion points\n$7 = Apply minimal change and invariants --&gt;\n\n**System-Level Instruction Editor**\n\nTrigger: $1\n\nPurpose: $2\n\n## Inputs\n\n- $3\n\n## Steps\n\n1. $4\n2. $5\n3. $6\n\n1. **Deconstruct the request:** $7\n\n2. **Locate insertion points:** Use semantic matching on headings and content to find the best-fit sections for the user\u2019s request. If no clear section exists, create a new minimal section with a logically consistent title.\n\n3. **Apply minimal change:** Insert or modify content to satisfy the request while preserving tone, structure, and cross-references. Keep unrelated sections unchanged.\n\n4. **Run invariants:**\n\n   - The entire file must be present (no placeholders, no truncation).\n   - Markdown structure and formatting must remain valid.\n   - Internal references and links stay accurate.\n\n5. **Render in Canvas:**\n\n   - If editing an existing file: open in Canvas and **replace the full contents** with the updated version.\n   - If creating a new file: create it in Canvas and display the **entire file**.\n\n6. **Variants (optional):** Generate $1.md and/or $2.md from the updated $3.md using only the Platform Substitution Rules. Render each variant\u2019s **entire file** in Canvas (one file per Canvas operation).\n\n7. **Size-limit fallback:** If a size cap prevents full-file rendering in Canvas, output the **entire file in chat**, then append:\n\n   - \"*Note: Full content was output in chat due to a size limit preventing Canvas rendering.*\"\n\n## Output format\n\n- Table: $1 \u2192 $2 \u2192 $3 \u2192 $4 \u2192 $5\n\n## Example rows\n\n- \"&lt;example symptom or error&gt;\" \u2192 $6 \u2192 $7 \u2192 $1 \u2192 $2\n</code></pre>"},{"location":"temp-prompts-refactored/tm-advance/","title":"TM \u00b7 advance","text":"<pre><code>&lt;!-- $1 = input task IDs (e.g., TM-42, TM-43) --&gt;\n&lt;!-- $2 = task title from tasks.json --&gt;\n&lt;!-- $3 = step-by-step plan description --&gt;\n&lt;!-- $4 = list of file touch-points --&gt;\n&lt;!-- $5 = test hooks for the task --&gt;\n&lt;!-- $6 = measurable acceptance criteria --&gt;\n&lt;!-- $7 = Conventional Commits message (e.g., `feat(parser): implement rule X`) --&gt;\n\n**Advance Task Plan Generator**\n\nTrigger: For given $1, produce a concrete work plan, acceptance criteria, tests, and a Conventional Commits message to move status toward done.\n\nPurpose: For given task id(s), produce a concrete work plan, acceptance criteria, tests, and a Conventional Commits message to move status toward done.\n\nSteps:\n\n1. Read tasks.json; resolve each provided $1. If none provided, pick the top item from /tm-next.\n2. For each task: restate $2, goals, and related dependencies.\n3. Draft a step-by-step plan with $4 and $5.\n4. Provide a minimal commit plan and a Conventional Commits message ($7).\n5. List measurable acceptance criteria ($6).\n\nOutput format:\n\n- One section per task: \"## $1 \u2014 $2\"\n- Subsections: Plan, Files, Tests, Acceptance, Commit Message ($7), Risks.\n\nNotes:\n- Do not mutate tasks.json. Emit proposed changes only.\n</code></pre>"},{"location":"temp-prompts-refactored/tm-blockers/","title":"TM \u00b7 blockers","text":"<pre><code>&lt;!-- Placeholders: $1=Trigger, $2=Purpose, $3=Steps, $4=Output format, $5=Examples, $6=Notes, $7=Input/Output examples --&gt;\n\n**Blocker Diagnosis Template**\n\n$1\n\n$2\n\n$3\n\n$4\n\n$5\n\n$6\n\n\n# Blocker Report: $7\n\nTables: blockers (type | item | evidence), actions (step | owner | effort | success_criteria).\n</code></pre>"},{"location":"temp-prompts-refactored/tm-ci/","title":"TM \u00b7 CI","text":"<pre><code>&lt;!-- $1 = task path (e.g., \"/tm-ci\") --&gt;\n&lt;!-- $2 = purpose statement --&gt;\n&lt;!-- $3 = ready tasks path (e.g., \"/tm-next\") --&gt;\n&lt;!-- $4 = grouping method (e.g., \"by component/tag\") --&gt;\n&lt;!-- $5 = CI job details (name | trigger | commands | est_time) --&gt;\n&lt;!-- $6 = test matrix (scope | command | expected_artifacts) --&gt;\n&lt;!-- $7 = risk areas --&gt;\n\n# CI/Test Checklist Template\n\n## Analysis\n\n- [ ] Affected files\n- [ ] Root cause\n- [ ] Proposed fix\n- [ ] Tests\n- [ ] Docs gaps\n- [ ] Open questions\n\n## How-to Steps\n\n1. Compute ready tasks (see $3) and collect testStrategy fields.\n2. Group by $4; otherwise by path keywords in titles.\n3. Propose CI jobs and test commands with approximate runtimes and gating rules ($5).\n4. Include a smoke-test matrix ($6) and minimal code coverage targets if relevant.\n\nOutput format:\n\n- \"# CI Plan\"\n- Tables: jobs ($5) and tests ($6)\n- \"## Risk Areas\" ($7)\n\nExamples:\n\n- Input: $1\n- Output: one CI plan with 3\u20138 jobs and a test table.\n\nNotes:\n\n- Non-binding guidance. Adapt to the repo\u2019s actual CI system.\n</code></pre>"},{"location":"temp-prompts-refactored/tm-delta/","title":"TM \u00b7 delta","text":"<pre><code># $1 \u2192 Tasks Delta\n\nTrigger: $2\n\nPurpose: Compare $1 against tasks.json and propose add/update/remove operations.\n\nSteps:\n\n$3. Extract $4, $5, $6, and $7 from $1.\n$4. Map them to existing tasks by fuzzy match on title and keywords; detect gaps.\n\nPropose: new tasks, updates to titles/descriptions/priority, and deprecations.\n\nOutput format:\n\n- \"# Delta Summary\"\n- Tables: adds | updates | removals.\n- \"## JSON Patch\" with an ordered list of operations: add/replace/remove.\n- \"## Assumptions\" and \"## Open Questions\".\n\nExamples:\n\n- Input: $2\n- Output: tables with a small JSON Patch block.\n\nNotes:\n\n- Keep patches minimal and reversible. Flag any destructive changes explicitly.\n</code></pre>"},{"location":"temp-prompts-refactored/tm-docs/","title":"TM \u00b7 docs","text":"<pre><code>&lt;!-- Placeholder mapping:\n- $1 = Trigger\n- $2 = Purpose\n- $3 = Steps count\n- $4 = Output format\n- $5 = Examples\n- $6 = Notes\n--&gt;\n\n**Project Status Docs**\n\n# Generate Status Docs\n\nTrigger: $1\n\nPurpose: $2\n\nSteps:\n1. $3\n2. $4\n3. $5\n4. $6\n\nOutput format:\n- $7\n\nExamples:\n- $8\n\nNotes:\n- $9\n\n\n**Analysis**\n- [ ] Affected files: [list]\n- [ ] Root cause: [reason]\n- [ ] Proposed fix: [solution]\n- [ ] Tests: [test cases]\n- [ ] Docs gaps: [missing sections]\n- [ ] Open questions: [questions]\n\n**Root cause**\n- [ ] Identifying factors: [list]\n\n**Proposed fix**\n- [ ] Action items: [list]\n\n**Tests**\n- [ ] Test cases: [list]\n\n**Docs gaps**\n- [ ] Missing sections: [list]\n\n**Open questions**\n- [ ] Unresolved issues: [list]\n</code></pre>"},{"location":"temp-prompts-refactored/tm-next/","title":"TM \u00b7 next","text":"<pre><code># Next Ready Tasks\n\nTrigger: $1\n\nPurpose: $2\n\nSteps:\n\n1. $3\n2. $4\n3. $5\n4. $6\n\nOutput format:\n\n- \"$7\"\n- Table: id | title | priority | why_ready | prereqs\n- \"## Notes\" for tie-break rules and data gaps.\n\nExamples:\n\n- Input: $8\n- Output: $9\n\nNotes:\n\n- Treat missing or null priority as $10. If custom scales exist, describe them in Notes.\n\n&lt;!-- Placeholder mapping --&gt;\n$1: Trigger (e.g., \"/tm-next\")\n$2: Purpose (brief description)\n$3: Step 1 (algorithmic step)\n$4: Step 2 (algorithmic step)\n$5: Step 3 (algorithmic step)\n$6: Step 4 (algorithmic step)\n$7: Output format description\n$8: Example input format\n$9: Example output format\n$10: Default priority value\n</code></pre>"},{"location":"temp-prompts-refactored/tm-overview/","title":"TM \u00b7 overview","text":"<pre><code># TaskMaster Overview\n\nTrigger: $1\n\nPurpose: $2\n\nSteps:\n1. Locate the active tasks.json at repo root or the path supplied in the user message. Do not modify it.\n2. Parse fields: id, title, description, status, priority, dependencies, subtasks.\n3. Compute counts per status and a table of top pending items by priority.\n4. Detect dependency issues: cycles, missing ids, orphans (no deps and not depended on).\n5. Approximate a critical path: longest dependency chain among pending\u2192in_progress tasks.\n\nOutput format: $3\n\nExamples:\n- Input: $4\n- Output: $5\n\nNotes:\n- $6: Read-only. Assume statuses: pending | in_progress | blocked | done.\n- If tasks.json is missing or invalid, output an \"## Errors\" section with a concise diagnosis.\n\n&lt;!-- Placeholder mapping --&gt;\n$1 = Task description\n$2 = Purpose statement\n$3 = Output format specification\n$4 = Example input format\n$5 = Expected output structure\n$6 = Critical path details (optional) --&gt;\n</code></pre>"},{"location":"temp-prompts-refactored/tm-refine/","title":"TM \u00b7 refine","text":"<pre><code>&lt;!-- $1=task ID (e.g., \"TM-09\"), $2=subtasks table content, $3=JSON patch array --&gt;\n\n**Refine Task into Subtasks**\n\nTrigger: /tm-refine\n\nPurpose: Expand a vague or large task into actionable subtasks with clear acceptance criteria.\n\nSteps:\n\n1. Load the task by $1 and analyze description for ambiguity and scope.\n2. Propose 3\u20138 subtasks with titles, brief descriptions, and dependencies between them.\n3. Define acceptance criteria per subtask using Given/When/Then or bullet checks.\n4. Suggest test coverage and doc updates triggered by completion.\n\nOutput format:\n\n- \"# Refinement: $1\"\n- Subtasks as a Markdown table: $2\n- \"## JSON Patch\" fenced code of suggested additions suitable for tasks.json editing: $3\n\nExamples:\n\n- Input: /tm-refine $1\n- Output: $2 plus a minimal JSON Patch array.\n\nConstraints:\n- Do not assume authority to change files; provide patches the user can apply.\n</code></pre>"},{"location":"temp-prompts-refactored/todo-report/","title":"TODO report","text":"<pre><code>&lt;!-- $1=Task goal statement, $2=Command to run, $3=Grouping criteria, $4=Triage plan description, $5=Summary restatement, $6=Prioritized recommendations, $7=Output subheading structure --&gt;\n\n**CLI Assistant Prompt for TODO Triage**\n\nYou are a CLI assistant focused on helping contributors with the task: $1.\n\n1. Gather context by running $2.\n2. Aggregate and group TODO/FIXME/XXX by $3.\n3. Propose a triage plan: $4.\n\nOutput:\n- Begin with a concise summary that restates the goal: $5.\n- Offer prioritized, actionable recommendations with rationale: $6.\n- Organize details under clear subheadings: $7.\n</code></pre>"},{"location":"temp-prompts-refactored/todos/","title":"TODOs","text":"<pre><code>&lt;!--\n$1 = command to run for evidence gathering\n$2 = task title\n$3 = synthesis instructions\n$4 = example output\n$5 = example input (n/a)\n--&gt;\n\n**How-to: Find and group TODO/FIXME annotations**\n\n1. Gather context by running `$1`.\n2. Find and group TODO/FIXME annotations.\n3. $3\n\nOutput:\n\n- Begin with a concise summary that restates the goal: Find and group TODO/FIXME annotations.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\n$5\n\nExpected Output:\n$4\n</code></pre>"},{"location":"temp-prompts-refactored/tsconfig-review/","title":"TSConfig review","text":"<pre><code>&lt;!-- Placeholder mapping:\n$1 = Title (e.g., \"Review tsconfig for correctness and DX\")\n$2 = Summary (e.g., \"You are a CLI assistant focused on helping contributors with the task...\")\n$3 = Recommendations (e.g., \"Prioritized, actionable recommendations with rationale\")\n$4 = Evidence (e.g., \"Documentation of the evidence used\")\n$5 = Example Inputs (e.g., \"(none \u2013 command runs without arguments)\")\n$6 = Expected Output (e.g., \"Structured report following the specified sections\") --&gt;\n\n**CLI Assistant Task: Review tsconfig**\n\nYou are a CLI assistant focused on helping contributors with the task: $1\n\n1. Gather context by inspecting $2.\n2. Provide recommendations for module/target, strictness, paths, incremental builds.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\n**Output**\n\n- Begin with a concise summary that restates the goal: $1\n- Offer prioritized, actionable recommendations with rationale: $3\n- Document the evidence you used so maintainers can trust the conclusion: $4\n\n**Example**\n- Input: $5\n- Expected Output: $6\n\n---\n\n### Optional sections (for analysis tasks)\n- [ ] Affected files\n- [ ] Root cause\n- [ ] Proposed fix\n- [ ] Tests\n- [ ] Docs gaps\n- [ ] Open questions\n</code></pre>"},{"location":"temp-prompts-refactored/ui-screenshots/","title":"UI screenshots","text":"<pre><code>&lt;!-- $1=Title, $2=Trigger, $3=Purpose, $4=Step 1, $5=Step 2, $6=Step 3, $7=Output format --&gt;\n**UI Screenshots Analysis**\n\nTrigger: $2\n\nPurpose: $3\n\n## Steps\n\n1. $4\n2. $5\n3. $6\n\n## Output format\n\n$7\n\n## Affected files (optional)\n\n- List components/files needing changes\n\n## Root cause (optional)\n\n- Specific UI issues identified\n\n## Proposed fix (optional)\n\n- Concrete implementation changes\n\n## Test cases (optional)\n\n- Validation criteria for fixes\n\n## Open questions (optional)\n\n- Unclear requirements or edge cases\n</code></pre>"},{"location":"temp-prompts-refactored/update-changelog/","title":"Update changelog","text":"<p><pre><code>&lt;!-- Placeholder mapping --&gt;\n$1 = Trigger command (e.g., \"/update-changelog\")\n$2 = Purpose statement (e.g., \"Generate a user-facing CHANGELOG entry...\")\n$3 = Step 1 description (e.g., \"Inspect repo state:\")\n$4 = Step 2 description (e.g., \"Collect changes:\")\n$5 = Step 3 description (e.g., \"De-dupe and rewrite:\")\n$6 = Step 4 description (e.g., \"Emit Markdown snippet...\")\n$7 = Step 5 description (e.g., \"Decide placement:\")\n\n**How-to: Update CHANGELOG**\n\n$1\n\nPurpose: $2\n\nSteps:\n\n$3\n\n$4\n\n$5\n\n$6\n\n$7\n\nOutput format:\n\n- Heading line with target section (Unreleased or version)\n- Six-section block in Markdown with only non-empty sections in order: Added, Changed, Deprecated, Removed, Fixed, Security\n- A short \"Link references\" block suggestion for `[Unreleased]` and new version comparison links\n- A unified diff (context 3) for `CHANGELOG.md`\n\nExamples:\n\nInput \u2192\n</code></pre> $8 <pre><code>Output \u2192\n</code></pre> $9 <pre><code>Notes:\n\n- Assumes git repository is available and tags follow SemVer.\n- Keep content end-user focused. Avoid internal file names and refactor notes.\n- If no Conventional Commits, infer section from message heuristics.\n- Do not include secrets or internal ticket links.\n</code></pre></p>"},{"location":"temp-prompts-refactored/version-control-guide/","title":"Version control guide","text":"<pre><code># Version Control Guide\n\nTrigger: $1\n\nPurpose: Enforce clean incremental commits and clean-room re-implementation when finalizing.\n\n## Steps\n\n$2\n\n## Output format\n\n$3\n\n## Examples\n\n$4\n\n## Notes\n\n$5\n</code></pre>"},{"location":"temp-prompts-refactored/version-proposal/","title":"Version proposal","text":"<pre><code># Version Proposal\n\nTrigger: $1\n\nPurpose: $2\n\nYou are a CLI assistant focused on helping contributors with the task: $3\n\n1. Gather context by running `git describe --tags --abbrev=0` for the last tag; running `git log --pretty='%s' --no-merges $(git describe --tags --abbrev=0)..HEAD` for the commits since last tag (no merges).\n2. Given the Conventional Commit history since the last tag, propose the next SemVer and justify why.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\nOutput:\n- Begin with a concise summary that restates the goal: $4\n- Offer prioritized, actionable recommendations with rationale.\n- Document the evidence you used so maintainers can trust the conclusion.\n\nExample Input:\n$5\n\nExpected Output:\n- Structured report following the specified sections.\n\n&lt;!-- Placeholders:\n$1 = Trigger (e.g., \"/version-proposal\")\n$2 = Purpose (e.g., \"Propose the next semantic version based on commit history\")\n$3 = Task description (e.g., \"Propose next version (major/minor/patch) from commit history\")\n$4 = Output summary goal (e.g., \"Propose next version (major/minor/patch) from commit history\")\n$5 = Example input format (e.g., \"(none \u2013 command runs without arguments)\") --&gt;\n</code></pre>"},{"location":"temp-prompts-refactored/voice-input/","title":"Voice input","text":"<pre><code>&lt;!-- $1 = Template title (e.g., \"Voice Input\") --&gt;\n&lt;!-- $2 = Trigger command (e.g., \"/voice-input\") --&gt;\n&lt;!-- $3 = Purpose statement (e.g., \"Support interaction from voice capture and convert to structured prompts\") --&gt;\n&lt;!-- $4 = Step description (e.g., \"Accept transcript text\") --&gt;\n&lt;!-- $5 = Output format description (e.g., \"Cleaned command list ready to execute\") --&gt;\n\n**Voice Input Template**\n\nTrigger: $2\n\nPurpose: $3\n\n## Steps\n1. $4\n2. Normalize to tasks or commands for other prompts.\n3. Preserve speaker intents and important entities.\n\n## Key entities\n*(e.g., speaker intent, command type, entities)*\n\n## Expected output\n$5\n</code></pre>"}]}