{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Prompt Docs","text":"<p>A structured playbook for ideation \u2192 scaffold \u2192 implementation \u2192 refactor \u2192 testing \u2192 docs \u2192 release. Use the sidebar to explore, or jump straight into a workflow below.</p> <p>Get Started</p> <p>Browse Sections</p> <p>Contribute</p>"},{"location":"#quick-start","title":"Quick start","text":"<p>New Workflow!</p> <ul> <li>QA-ready_refactor-plan</li> <li>ops_apply</li> <li>ops_quality</li> </ul> Try these out first <ul> <li>Need to refactor? Run first QA-ready_refactor-plan</li> <li>Then, Run second ops_apply</li> <li>If needed, run ops_quality</li> </ul> <p>First time here?</p> <ul> <li>Skim the 3 lanes below (Plan / Build / Ship).</li> <li>Use the search in the top-right.</li> <li>Every page is Markdown\u2014click Edit this page to propose improvements.</li> </ul> PlanBuildShip <ul> <li>Write a quick PRD \u2192 PRD generator</li> <li>Pick an architecture approach \u2192 ADR \u2013 new \u2022 Modular architecture</li> <li>Define logging &amp; SLOs \u2192 Logging strategy \u2022 SLO setup</li> </ul> <ul> <li>Bootstrap env &amp; CI \u2192 Env setup \u2022 DevOps automation</li> <li>Start coding prompts \u2192 Generate \u2022 Feature flags</li> <li>Review &amp; tighten \u2192 PR description \u2022 Audit</li> </ul> <ul> <li>Test coverage \u2192 Coverage guide</li> <li>Prepare release notes \u2192 Release notes (prepare)</li> <li>Versioning \u2192 Version proposal</li> </ul>"},{"location":"#whats-inside","title":"What\u2019s inside","text":"<ul> <li>Temp Prompts (organized) \u2014 curated, step-by-step:</li> <li>00 \u00b7 Ideation \u2192 Architecture, Design, Requirements</li> <li>10 \u00b7 Scaffold \u2192 CI setup, Conventions, Scaffold</li> <li>20 \u00b7 Implementation \u2192 Impl, Review, Spec-oriented</li> <li>30 \u00b7 Refactor \u2192 Refactor file, Perf eval</li> <li>40 \u00b7 Testing \u2192 Integration test, Flake fixes</li> <li>50 \u00b7 Docs \u2192 API docs (local)</li> <li> <p>60 \u00b7 Release \u2192 Changelog from commits, Post-release checks</p> </li> <li> <p>Temp Prompts (refactored) \u2014 same ideas, reworked as single-file flows:</p> </li> <li>Jump in: Action diagram, Prompt Optimizer, Scaffold (full-stack)</li> <li> <p>Docs helpers: Generate README, Docs 100%</p> </li> <li> <p>Shared &amp; Templates</p> </li> <li><code>_Shared</code> \u2192 TM overview, Reset strategy</li> <li><code>_Templates</code> \u2192 Instruction file, Prompt sequence generator</li> </ul>"},{"location":"#common-tasks","title":"Common tasks","text":"Plan a change (ADR + PRD checklist) <ol> <li>Start an ADR \u2192 ADR \u2013 new</li> <li>Draft PRD \u2192 PRD generator</li> <li>Stakeholder review \u2192 Planning process</li> </ol> Spin up a project scaffold <ul> <li>CI &amp; secrets \u2192 Secrets manager</li> <li>Monitoring &amp; SLOs \u2192 Monitoring setup \u2022 SLO setup</li> </ul> Run a crisp PR review <p>Use the trio: - PR description helper - Cross-check - Evidence capture</p>"},{"location":"#search-like-a-pro","title":"Search like a pro","text":"<ul> <li>Use filters in the search box (e.g. <code>flag lang:impl</code>), or just keywords like \u201crelease notes prepare\u201d.</li> <li>Prefer relative links when you add content (keeps GitHub Pages happy under <code>/prompt-docs/</code>).</li> <li>Add a short front-matter description on new pages to improve search snippets.</li> </ul> <p>Helpful deep links</p> <ul> <li>Spec-oriented helpers: Explain code \u2022 Changed files \u2022 Grep</li> <li>Testing: Integration test \u2022 Regression guard</li> </ul>"},{"location":"#contributing","title":"Contributing","text":"<ol> <li>Create a branch, add or edit Markdown under the appropriate section.</li> <li>Keep file names consistent with the existing pattern (e.g., <code>*.impl.md</code>, <code>*.review.md</code>).</li> <li>Submit a PR\u2014use the PR description helper.</li> <li>After merge, the site auto-deploys (using <code>mkdocs build</code> + Pages).</li> </ol> <p>Open a new issue Propose a change</p>"},{"location":"#release-versioning","title":"Release &amp; versioning","text":"<ul> <li>Draft notes \u2192 Release notes (prepare)</li> <li>Generate from commits \u2192 Changelog from commits</li> <li>Sanity pass \u2192 Verify</li> </ul>"},{"location":"#credits","title":"Credits","text":"<p>Built with MkDocs Material and maintained in the prompt-docs repo.</p>"},{"location":"temp-prompts-organized/temp-prompts-organized_filetree/","title":"Temp prompts organized filetree","text":"<p>Project Structure: \u251c\u2500\u2500 00-ideation \u2502   \u251c\u2500\u2500 architecture \u2502   \u2502   \u251c\u2500\u2500 adr-new.architecture.md \u2502   \u2502   \u251c\u2500\u2500 logging-strategy.architecture.md \u2502   \u2502   \u251c\u2500\u2500 modular-architecture.architecture.md \u2502   \u2502   \u2514\u2500\u2500 stack-evaluation.architecture.md \u2502   \u251c\u2500\u2500 design \u2502   \u2502   \u251c\u2500\u2500 action-diagram.design.md \u2502   \u2502   \u251c\u2500\u2500 api-contract.design.md \u2502   \u2502   \u251c\u2500\u2500 design-assets.design.md \u2502   \u2502   \u2514\u2500\u2500 ui-screenshots.design.md \u2502   \u2514\u2500\u2500 requirements \u2502       \u251c\u2500\u2500 plan-delta.requirements.md \u2502       \u251c\u2500\u2500 planning-process.requirements.md \u2502       \u251c\u2500\u2500 prd-generator.requirements.md \u2502       \u2514\u2500\u2500 scope-control.requirements.md \u251c\u2500\u2500 10-scaffold \u2502   \u251c\u2500\u2500 ci-setup \u2502   \u2502   \u251c\u2500\u2500 devops-automation.ci-setup.md \u2502   \u2502   \u251c\u2500\u2500 env-setup.ci-setup.md \u2502   \u2502   \u251c\u2500\u2500 monitoring-setup.ci-setup.md \u2502   \u2502   \u251c\u2500\u2500 secrets-manager-setup.ci-setup.md \u2502   \u2502   \u2514\u2500\u2500 slo-setup.ci-setup.md \u2502   \u251c\u2500\u2500 conventions \u2502   \u2502   \u2514\u2500\u2500 version-control-guide.conventions.md \u2502   \u2514\u2500\u2500 scaffold \u2502       \u251c\u2500\u2500 auth.scaffold.md \u2502       \u251c\u2500\u2500 db-bootstrap.scaffold.md \u2502       \u251c\u2500\u2500 fullstack.scaffold.md \u2502       \u2514\u2500\u2500 iac-bootstrap.scaffold.md \u251c\u2500\u2500 20-implementation \u2502   \u251c\u2500\u2500 impl \u2502   \u2502   \u251c\u2500\u2500 commit.impl.md \u2502   \u2502   \u251c\u2500\u2500 content-generation.impl.md \u2502   \u2502   \u251c\u2500\u2500 feature-flags.impl.md \u2502   \u2502   \u251c\u2500\u2500 fix.impl.md \u2502   \u2502   \u251c\u2500\u2500 generate.impl.md \u2502   \u2502   \u251c\u2500\u2500 prototype-feature.impl.md \u2502   \u2502   \u251c\u2500\u2500 todos.impl.md \u2502   \u2502   \u2514\u2500\u2500 voice-input.impl.md \u2502   \u251c\u2500\u2500 review \u2502   \u2502   \u251c\u2500\u2500 audit.review.md \u2502   \u2502   \u251c\u2500\u2500 cross-check.review.md \u2502   \u2502   \u251c\u2500\u2500 evidence-capture.review.md \u2502   \u2502   \u251c\u2500\u2500 pr-desc.review.md \u2502   \u2502   \u251c\u2500\u2500 review-branch.review.md \u2502   \u2502   \u251c\u2500\u2500 review.review.md \u2502   \u2502   \u251c\u2500\u2500 todo-report.review.md \u2502   \u2502   \u2514\u2500\u2500 tsconfig-review.review.md \u2502   \u2514\u2500\u2500 spec-orient \u2502       \u251c\u2500\u2500 blame-summary.spec-orient.md \u2502       \u251c\u2500\u2500 changed-files.spec-orient.md \u2502       \u251c\u2500\u2500 explain-code.spec-orient.md \u2502       \u251c\u2500\u2500 explain-symbol.spec-orient.md \u2502       \u251c\u2500\u2500 grep.spec-orient.md \u2502       \u251c\u2500\u2500 research-batch.spec-orient.md \u2502       \u2514\u2500\u2500 research-item.spec-orient.md \u251c\u2500\u2500 30-refactor \u2502   \u251c\u2500\u2500 perf \u2502   \u2502   \u251c\u2500\u2500 compare-outputs.perf.md \u2502   \u2502   \u251c\u2500\u2500 model-evaluation.perf.md \u2502   \u2502   \u2514\u2500\u2500 model-strengths.perf.md \u2502   \u251c\u2500\u2500 refactor \u2502   \u2502   \u251c\u2500\u2500 adr-new.refactor.md \u2502   \u2502   \u251c\u2500\u2500 file-modularity.refactor.md \u2502   \u2502   \u251c\u2500\u2500 prettier-adopt-migration-report.refactor.md \u2502   \u2502   \u2514\u2500\u2500 refactor-file.refactor.md \u2502   \u2514\u2500\u2500 refactor-candidates \u2502       \u251c\u2500\u2500 dead-code-scan.refactor-candidates.md \u2502       \u251c\u2500\u2500 migration-plan.refactor-candidates.md \u2502       \u2514\u2500\u2500 refactor-suggestions.refactor-candidates.md \u251c\u2500\u2500 40-testing \u2502   \u251c\u2500\u2500 coverage \u2502   \u2502   \u251c\u2500\u2500 guide.coverage.md \u2502   \u2502   \u2514\u2500\u2500 regression-guard.coverage.md \u2502   \u251c\u2500\u2500 fix-flakes \u2502   \u2502   \u251c\u2500\u2500 error-analysis.fix-flakes.md \u2502   \u2502   \u2514\u2500\u2500 explain-failures.fix-flakes.md \u2502   \u251c\u2500\u2500 gen-tests \u2502   \u2502   \u251c\u2500\u2500 check.gen-tests.md \u2502   \u2502   \u2514\u2500\u2500 integration-test.gen-tests.md \u2502   \u2514\u2500\u2500 test-plan \u2502       \u251c\u2500\u2500 e2e-runner-setup.test-plan.md \u2502       \u251c\u2500\u2500 query-set.test-plan.md \u2502       \u2514\u2500\u2500 secrets-scan.test-plan.md \u251c\u2500\u2500 50-docs \u2502   \u251c\u2500\u2500 api-docs \u2502   \u2502   \u251c\u2500\u2500 api-docs-local.api-docs.md \u2502   \u2502   \u2514\u2500\u2500 openapi-generate.api-docs.md \u2502   \u251c\u2500\u2500 doc-plan \u2502   \u2502   \u251c\u2500\u2500 gemini-map.doc-plan.md \u2502   \u2502   \u2514\u2500\u2500 owners.doc-plan.md \u2502   \u251c\u2500\u2500 examples \u2502   \u2502   \u251c\u2500\u2500 api-usage.examples.md \u2502   \u2502   \u2514\u2500\u2500 reference-implementation.examples.md \u2502   \u2514\u2500\u2500 site-sync \u251c\u2500\u2500 60-release \u2502   \u251c\u2500\u2500 changelog \u2502   \u2502   \u251c\u2500\u2500 from-commits.changelog.md \u2502   \u2502   \u251c\u2500\u2500 project.changelog.md \u2502   \u2502   \u251c\u2500\u2500 release-notes-prepare.changelog.md \u2502   \u2502   \u251c\u2500\u2500 release-notes.changelog.md \u2502   \u2502   \u251c\u2500\u2500 update.changelog.md \u2502   \u2502   \u2514\u2500\u2500 verify.changelog.md \u2502   \u251c\u2500\u2500 pack-publish \u2502   \u251c\u2500\u2500 post-release-checks \u2502   \u2502   \u251c\u2500\u2500 cleanup-branches.post-release-checks.md \u2502   \u2502   \u2514\u2500\u2500 license-report.post-release-checks.md \u2502   \u2514\u2500\u2500 versioning \u2502       \u2514\u2500\u2500 version-proposal.versioning.md \u251c\u2500\u2500 _archive \u251c\u2500\u2500 _experimental \u251c\u2500\u2500 _shared \u2502   \u251c\u2500\u2500 rank-root-prompts.shared.md \u2502   \u251c\u2500\u2500 reset-strategy.shared.md \u2502   \u251c\u2500\u2500 roll-up.shared.md \u2502   \u251c\u2500\u2500 summary.shared.md \u2502   \u251c\u2500\u2500 switch-model.shared.md \u2502   \u2514\u2500\u2500 tm \u2502       \u251c\u2500\u2500 advance.tm.md \u2502       \u251c\u2500\u2500 blockers.tm.md \u2502       \u251c\u2500\u2500 ci.tm.md \u2502       \u251c\u2500\u2500 delta.tm.md \u2502       \u251c\u2500\u2500 docs.tm.md \u2502       \u251c\u2500\u2500 next.tm.md \u2502       \u251c\u2500\u2500 overview.tm.md \u2502       \u2514\u2500\u2500 refine.tm.md \u2514\u2500\u2500 _templates     \u251c\u2500\u2500 instruction-file.templates.md     \u251c\u2500\u2500 prompt-sequence-generator.templates.md     \u2514\u2500\u2500 system-level-instruction-editor.templates.md</p> <p>_shared/rank-root-prompts.shared.md <pre><code>1 | &lt;!--\n2 | $1 = command name/identifier\n3 | $2 = example user question\n4 | $3 = project CWD path to scan for context (defaults to current directory)\n5 | $4 = prompt directory path (defaults to \"~/.codex/prompts\")\n6 | $5 = minimum relevance threshold (0\u20131)\n7 | --&gt;\n8 | \n9 | # {Context-Aware Prompt Ranking Command}\n10 | \n11 | ```md\n12 | # Command: $1\n13 | \n14 | # Usage: $1 \"$2\" \"$3\" \"$4\" \"$5\"\n15 | \n16 | # Args:\n17 | \n18 | # - {{query}}: $2\n19 | # - {{project_path}}: $3\n20 | # - {{prompt_path}}: $4\n21 | # - {{threshold}}: $5\n22 | \n23 | prompt = \"\"\"\n24 | Task:\n25 | Given a user inquiry ({{query}}) and the context of a software project located at {{project_path}}, your goal is to identify the most relevant prompt-definition file from the directory {{prompt_path}}.\n26 | \n27 | Defaults:\n28 | * If {{project_path}} is missing or blank, use the current working directory.\n29 | * If {{prompt_path}} is missing or blank, use \"~/.codex/prompts\".\n30 | \n31 | Do the following:\n32 | 1) **Analyze Project Context**: Recursively scan {{project_path}} to understand its structure, languages, and purpose. Create a concise summary of the project context.\n33 | 2) **Scan Prompts**: List all candidate prompt files in {{prompt_path}} (non-recursively).\n34 | 3) **Evaluate Prompts**: For each candidate prompt file:\n35 |     a) Read its content.\n36 |     b) Create a one-sentence summary of its purpose and domain.\n37 |     c) Compute a relevance score from 0 to 1. This score must measure how well the prompt's purpose aligns with the user's {{query}}, considering the project context summary. A higher score means the prompt is a better fit for solving the query within the given project.\n38 | 4) **Rank and Filter**: Order the prompts by their relevance score in descending order.\n39 | 5) **Generate Output**: Emit a compact markdown table with the columns: `filename | description | match_score` (rounded to 2 decimals).\n40 | \n41 | Rules:\n42 | * The description must be 1\u20132 sentences capturing the prompt's purpose and domain.\n43 | * Only include prompts in the table where `match_score` is greater than or equal to {{threshold}}.\n44 | * If no prompts meet the threshold, output a single line: \"No prompt exceeds threshold {{threshold}} \u2014 recommend creating a new prompt.\"\n45 | \n46 | Acceptance:\n47 | * If one or more matches meet the {{threshold}}, a markdown table sorted by descending `match_score` is produced.\n48 | * Otherwise, the single-line fallback message is produced.\n49 | \n50 | !{echo \"Scanning project: ${PROJECT_PATH_ARG:-.}\"}\n51 | !{echo \"Searching for prompts in: ${PROMPT_PATH_ARG:-~/.codex/prompts}\"}\n52 | \"\"\"\n53 | ```\n54 | \n55 | ## Output format\n56 | \n57 | * **Preferred**: a markdown table with columns `filename | description | match_score` sorted by `match_score` (desc) and filtered by `{{threshold}}`.\n58 | * **Fallback**: the exact one-line message when no entries meet `{{threshold}}`.\n</code></pre></p> <p>_shared/reset-strategy.shared.md <pre><code>1 | ---\n2 | phase: \"Reset Playbook\"\n3 | gate: \"Clean restart\"\n4 | status: \"triggered when gate criteria stall for &gt;60 minutes.\"\n5 | previous:\n6 |   - \"Any blocked stage\"\n7 | next:\n8 |   - \"Restart with /planning-process then follow the gated flow\"\n9 | ---\n10 | \n11 | # Reset Strategy\n12 | \n13 | Trigger: /reset-strategy\n14 | \n15 | Purpose: Decide when to hard reset and start clean to avoid layered bad diffs.\n16 | \n17 | ## Steps\n18 | \n19 | 1. Run: `git status -sb` and `git diff --stat` to assess churn.\n20 | 2. If many unrelated edits or failing builds, propose: `git reset --hard HEAD` to discard working tree.\n21 | 3. Save any valuable snippets to `scratch/` before reset.\n22 | 4. Re-implement the minimal correct fix from a clean state.\n23 | \n24 | ## Output format\n25 | \n26 | - A short decision note and exact commands. Never execute resets automatically.\n27 | \n28 | ## Examples\n29 | \n30 | - Recommend reset after repeated failing refactors touching 15+ files.\n31 | \n32 | ## Notes\n33 | \n34 | - Warn about destructive nature. Require user confirmation.\n35 | \n</code></pre></p> <p>_shared/roll-up.shared.md <pre><code>1 | # Research Roll-up Summary\n2 | \n3 | Trigger: /roll-up\n4 | \n5 | Purpose: Summarize per-item statuses, enabled decisions, unresolved risks, and count sources by domain type.\n6 | \n7 | Steps:\n8 | \n9 | 1. Aggregate Conversation State Updates from prior items.\n10 | 2. Produce per-item status lines and decisions.\n11 | 3. Tally sources by domain type: gov, org, docs, blog, news, academic.\n12 | \n13 | Output format:\n14 | \n15 | ```\n16 | ## Roll-up Summary\n17 | - Item {n}: {status} \u2014 decision enabled: {\u2026}; risks: {\u2026}\n18 | - Sources by domain type: {gov:X, org:Y, docs:Z, blog:A, news:B, academic:C}\n19 | ```\n20 | \n21 | Examples:\n22 | \n23 | - Input: `/roll-up from items 1\u20133`\n24 | - Output: Summary block as above.\n25 | \n26 | Notes:\n27 | \n28 | - Use counts derived from the Evidence Logs.\n</code></pre></p> <p>_shared/summary.shared.md <pre><code>1 | You are a CLI assistant focused on helping contributors with the task: Produce a README\u2011level summary of the repo.\n2 | \n3 | 1. Gather context by running `git ls-files | sed -n '1,400p'` for the repo map (first 400 files); inspecting `README.md` for the key docs if present; inspecting `docs` for the key docs if present.\n4 | 2. Generate a high\u2011level summary (What, Why, How, Getting Started).\n5 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n6 | \n7 | Output:\n8 | \n9 | - Begin with a concise summary that restates the goal: Produce a README\u2011level summary of the repo.\n10 | - Document the evidence you used so maintainers can trust the conclusion.\n11 | \n12 | Example Input:\n13 | (none \u2013 command runs without arguments)\n14 | \n15 | Expected Output:\n16 | \n17 | - Structured report following the specified sections.\n</code></pre></p> <p>_shared/switch-model.shared.md <pre><code>1 | ---\n2 | phase: \"P9 Model Tactics\"\n3 | gate: \"Model uplift\"\n4 | status: \"document rollback/guardrails before flipping defaults.\"\n5 | previous:\n6 |   - \"/compare-outputs\"\n7 | next:\n8 |   - \"Return to the blocked stage (e.g., /integration-test) to apply learnings\"\n9 | ---\n10 | \n11 | # Switch Model\n12 | \n13 | Trigger: /switch-model\n14 | \n15 | Purpose: Decide when to try a different AI backend and how to compare.\n16 | \n17 | ## Steps\n18 | \n19 | 1. Define task type: frontend codegen, backend reasoning, test writing, refactor.\n20 | 2. Select candidate models and temperature/tooling options.\n21 | 3. Run a fixed input suite and measure latency, compile success, and edits needed.\n22 | 4. Recommend a model per task with rationale.\n23 | \n24 | ## Output format\n25 | \n26 | - Table: task \u2192 model \u2192 settings \u2192 win reason.\n27 | \n</code></pre></p> <p>_templates/instruction-file.templates.md <pre><code>1 | ---\n2 | phase: \"P0 Preflight Docs\"\n3 | gate: \"DocFetchReport\"\n4 | status: \"capture approved instructions before proceeding.\"\n5 | previous:\n6 |   - \"Preflight discovery (AGENTS baseline)\"\n7 | next:\n8 |   - \"/planning-process\"\n9 |   - \"/scope-control\"\n10 | ---\n11 | \n12 | # Instruction File\n13 | \n14 | Trigger: /instruction-file\n15 | \n16 | Purpose: Generate or update `cursor.rules`, `windsurf.rules`, or `claude.md` with project-specific instructions.\n17 | \n18 | ## Steps\n19 | \n20 | 1. Scan repo for existing instruction files.\n21 | 2. Compose sections: Context, Coding Standards, Review Rituals, Testing, Security, Limits.\n22 | 3. Include \"Reset and re-implement cleanly\" guidance and scope control.\n23 | 4. Write to chosen file and propose a commit message.\n24 | \n25 | ## Output format\n26 | \n27 | - Markdown instruction file with stable headings.\n28 | \n</code></pre></p> <p>_templates/prompt-sequence-generator.templates.md <pre><code>1 | # Prompt: Generate Prompt Execution Sequence\n2 | \n3 | **Purpose:** Given a high-level goal and a set of available prompts, generate the logical execution sequence required to accomplish that goal by chaining the prompts together.\n4 | \n5 | ---\n6 | \n7 | ### **Inputs**\n8 | \n9 | *   **High-Level Goal:** {{high_level_goal}}\n10 |     *   *A clear, one-sentence description of the final outcome the user wants to achieve.*\n11 |     *   *Example: \"Create and document a pull request for the currently staged changes.\"*\n12 | \n13 | *   **Available Prompts:**\n14 |     ```\n15 |     {{available_prompts}}\n16 |     ```\n17 |     *   *A list of candidate prompt names (e.g., from the output of `rank-root-prompts`).*\n18 |     *   *Example: ['pr-desc.md', 'commit-msg.md', 'changed-files.md', 'review.md', 'release-notes.md']*\n19 | \n20 | *   **Context (Optional):** {{context}}\n21 |     *   *Any additional context, such as the current state of the git repository or specific files of interest.*\n22 |     *   *Example: \"The user has already staged files using `git add`.\"*\n23 | \n24 | ---\n25 | \n26 | ### **Instructions for the AI**\n27 | \n28 | 1.  **Analyze the Goal:** Deconstruct the `{{high_level_goal}}` into a series of logical steps required to get from the starting state to the final outcome.\n29 | \n30 | 2.  **Map Prompts to Steps:** For each logical step, identify the most suitable prompt from the `{{available_prompts}}` list that can perform that step.\n31 |     *   Consider the inputs and outputs of each prompt to determine dependencies. A prompt's input is often the output of a previous one.\n32 | \n33 | 3.  **Establish Order:** Arrange the selected prompts into a numbered sequence based on their dependencies. The sequence should represent a complete and logical workflow.\n34 | \n35 | 4.  **Identify Gaps:** If any necessary step in the workflow cannot be fulfilled by one of the available prompts, explicitly state what action or prompt is missing.\n36 | \n37 | ---\n38 | \n39 | ### **Required Output Format**\n40 | \n41 | **Execution Sequence:**\n42 | \n43 | 1.  **`[prompt_name_1.md]`**: [Brief justification for why this prompt is first and what it accomplishes.]\n44 | 2.  **`[prompt_name_2.md]`**: [Brief justification for why this prompt is second, and how it uses the output of the previous step.]\n45 | 3.  ...\n46 | \n47 | **Identified Gaps (if any):**\n48 | \n49 | *   [Description of a missing step or prompt needed to complete the workflow.]\n</code></pre></p> <p>_templates/system-level-instruction-editor.templates.md <pre><code>1 | phase: \"P0 Preflight Docs\"\n2 | gate: \"Scope Gate\"\n3 | status: \"draft\"\n4 | owner: \"Prompt Ops\"\n5 | date: \"2025-09-20\"\n6 | previous:\n7 |   - \"/instruction-file.md\"\n8 |   - \"/planning-process.md\"\n9 | next:\n10 |   - \"/AGENTS.md\"\n11 |   - \"/GEMINI.md\"\n12 | tags:\n13 |   - \"instructions\"\n14 |   - \"editor\"\n15 | ---\n16 | \n17 | # System Instruction: Canonical Instruction File Editor\n18 | \n19 | Trigger: /&lt;slash-command&gt;\n20 | \n21 | Purpose: &lt;1\u20132 lines describing the objective and outcome criteria.&gt;\n22 | \n23 | ## Inputs\n24 | \n25 | - &lt;logs/artifacts to collect&gt;\n26 | - &lt;affected services/modules&gt;\n27 | - &lt;build/version/commit&gt;\n28 | - &lt;time window/region/tenant&gt;\n29 | - &lt;SLO/SLA impacted&gt;\n30 | \n31 | ## Steps\n32 | \n33 | 1. Collect relevant data (&lt;test logs, traces, metrics, dumps, repro steps&gt;).\n34 | 2. Group by symptom/pattern; for each group, list 2\u20133 plausible causes.\n35 | 3. Propose disambiguators (instrumentation, targeted inputs, experiments).\n36 | 4. Sketch minimal fixes (patches/config toggles/rollbacks) with risk notes.\n37 | 5. Validate fixes (tests to run, monitors to watch, acceptance criteria).\n38 | 6. Roll out &amp; verify (staged rollout plan, owners, ETA).\n39 | 7. Capture follow-ups (refactors, docs, guardrails).\n40 | \n41 | 1. **Deconstruct the request:** Identify the user\u2019s intent and the minimal set of sections that should be added or updated.\n42 | 2. **Locate insertion points:** Use semantic matching on headings and content to find the best-fit sections for the user\u2019s request. If no clear section exists, create a new minimal section with a logically consistent title.\n43 | 3. **Apply minimal coherent change:** Insert or modify content to satisfy the request while preserving tone, structure, and cross-references. Keep unrelated sections unchanged.\n44 | 4. **Run invariants:**\n45 | \n46 |    - The entire file must be present (no placeholders, no truncation).\n47 |    - Markdown structure and formatting must remain valid.\n48 |    - Internal references and links stay accurate.\n49 | 5. **Render in Canvas:**\n50 | \n51 |    - If editing an existing file: open in Canvas and **replace the full contents** with the updated version.\n52 |    - If creating a new file: create it in Canvas and display the **entire file**.\n53 | 6. **Variants (optional or on request):** Generate `GEMINI.md` and/or `CLAUDE.md` from the updated `AGENTS.md` using only the Platform Substitution Rules. Render each variant\u2019s **entire file** in Canvas (one file per Canvas operation).\n54 | 7. **Size-limit fallback:** If a size cap prevents full-file rendering in Canvas, output the **entire file in chat**, then append:\n55 | \n56 |    - \u201c*Note: Full content was output in chat due to a size limit preventing Canvas rendering.*\u201d\n57 | \n58 | ## Output format\n59 | \n60 | - Table: &lt;symptom/item&gt; \u2192 &lt;likely causes&gt; \u2192 &lt;next checks&gt; \u2192 &lt;candidate fix&gt; \u2192 &lt;owner/ETA&gt;.\n61 | \n62 | ## Example rows\n63 | \n64 | - \"&lt;example symptom or error&gt;\" \u2192 &lt;cause A, cause B&gt; \u2192 &lt;check 1, check 2&gt; \u2192 &lt;fix sketch&gt; \u2192 &lt;owner/ETA&gt;.\n</code></pre></p> <p>00-ideation/architecture/adr-new.architecture.md <pre><code>1 | You are a CLI assistant focused on helping contributors with the task: Draft an Architecture Decision Record with pros/cons.\n2 | \n3 | 1. Gather context by inspecting `README.md` for the project context.\n4 | 2. Draft a concise ADR including Context, Decision, Status, Consequences. Title: &lt;args&gt;.\n5 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n6 | \n7 | Output:\n8 | \n9 | - Begin with a concise summary that restates the goal: Draft an Architecture Decision Record with pros/cons.\n10 | - Highlight workflow triggers, failing jobs, and proposed fixes.\n11 | - Document the evidence you used so maintainers can trust the conclusion.\n12 | \n13 | Example Input:\n14 | src/example.ts\n15 | \n16 | Expected Output:\n17 | \n18 | - Actionable summary aligned with the output section.\n</code></pre></p> <p>00-ideation/architecture/logging-strategy.architecture.md <pre><code>1 | phase: \"P7 Release &amp; Ops\"\n2 | gate: \"Release Gate\"\n3 | status: \"logging guardrails ready for canary/production checks; coordinate with P4 Frontend UX for client telemetry.\"\n4 | previous:\n5 | \n6 | - \"/monitoring-setup\"\n7 | - \"/slo-setup\"\n8 | next:\n9 | - \"/audit\"\n10 | - \"/error-analysis\"\n11 | \n12 | ---\n13 | \n14 | # Logging Strategy\n15 | \n16 | Trigger: /logging-strategy\n17 | \n18 | Purpose: Add or remove diagnostic logging cleanly with levels and privacy in mind.\n19 | \n20 | ## Steps\n21 | \n22 | 1. Identify hotspots from recent failures.\n23 | 2. Insert structured logs with contexts and correlation IDs.\n24 | 3. Remove noisy or PII-leaking logs.\n25 | 4. Document log levels and sampling in `OBSERVABILITY.md`.\n26 | \n27 | ## Output format\n28 | \n29 | - Diff hunks and a short guideline section.\n30 | \n</code></pre></p> <p>00-ideation/architecture/modular-architecture.architecture.md <pre><code>1 | phase: \"P2 App Scaffold &amp; Contracts\"\n2 | gate: \"Test Gate lite\"\n3 | status: \"boundaries documented and lint/build scripts still pass; revisit during P4 Frontend UX for UI seams.\"\n4 | previous:\n5 | \n6 | - \"/openapi-generate\"\n7 | next:\n8 | - \"/db-bootstrap\"\n9 | - \"/ui-screenshots\"\n10 | - \"/design-assets\"\n11 | \n12 | ---\n13 | \n14 | # Modular Architecture\n15 | \n16 | Trigger: /modular-architecture\n17 | \n18 | Purpose: Enforce modular boundaries and clear external interfaces.\n19 | \n20 | ## Steps\n21 | \n22 | 1. Identify services/modules and their public contracts.\n23 | 2. Flag cross-module imports and circular deps.\n24 | 3. Propose boundaries, facades, and internal folders.\n25 | 4. Add \"contract tests\" for public APIs.\n26 | \n27 | ## Output format\n28 | \n29 | - Diagram-ready list of modules and edges, plus diffs.\n30 | \n</code></pre></p> <p>00-ideation/architecture/stack-evaluation.architecture.md <pre><code>1 | ---\n2 | phase: \"P1 Plan &amp; Scope\"\n3 | gate: \"Scope Gate\"\n4 | status: \"record recommended stack and top risks before building.\"\n5 | previous:\n6 |   - \"/scope-control\"\n7 | next:\n8 |   - \"/scaffold-fullstack\"\n9 |   - \"/api-contract\"\n10 | ---\n11 | \n12 | # Stack Evaluation\n13 | \n14 | Trigger: /stack-evaluation\n15 | \n16 | Purpose: Evaluate language/framework choices relative to AI familiarity and repo goals.\n17 | \n18 | ## Steps\n19 | \n20 | 1. Detect current stack and conventions.\n21 | 2. List tradeoffs: maturity, tooling, available examples, hiring, and AI training coverage.\n22 | 3. Recommend stay-or-switch with migration outline if switching.\n23 | \n24 | ## Output format\n25 | \n26 | - Decision memo with pros/cons and next steps.\n27 | \n</code></pre></p> <p>00-ideation/design/action-diagram.design.md <pre><code>1 | You are a CLI assistant focused on helping contributors with the task: Explain workflow triggers and dependencies as a diagram\u2011ready outline.\n2 | \n3 | 1. Gather context by inspecting `.github/workflows`.\n4 | 2. Explain workflow triggers and dependencies as a diagram\u2011ready outline.\n5 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n6 | \n7 | Output:\n8 | \n9 | - Begin with a concise summary that restates the goal: Explain workflow triggers and dependencies as a diagram\u2011ready outline.\n10 | - Organize details under clear subheadings so contributors can scan quickly.\n11 | - List nodes and edges to make diagram creation straightforward.\n12 | - Highlight workflow triggers, failing jobs, and proposed fixes.\n13 | \n14 | Example Input:\n15 | (none \u2013 command runs without arguments)\n16 | \n17 | Expected Output:\n18 | \n19 | ## Nodes\n20 | \n21 | - build\n22 | - deploy\n23 | \n24 | ## Edges\n25 | \n26 | - push -&gt; build\n27 | - build -&gt; deploy\n</code></pre></p> <p>00-ideation/design/api-contract.design.md <pre><code>1 | ---\n2 | phase: \"P2 App Scaffold &amp; Contracts\"\n3 | gate: \"Test Gate lite\"\n4 | status: \"contract checked into repo with sample generation running cleanly.\"\n5 | previous:\n6 |   - \"/scaffold-fullstack\"\n7 | next:\n8 |   - \"/openapi-generate\"\n9 |   - \"/modular-architecture\"\n10 | ---\n11 | \n12 | # API Contract\n13 | \n14 | Trigger: /api-contract \"&lt;feature or domain&gt;\"\n15 | \n16 | Purpose: Author an initial OpenAPI 3.1 or GraphQL SDL contract from requirements.\n17 | \n18 | **Steps:**\n19 | \n20 | 1. Parse inputs and existing docs. If REST, prefer OpenAPI 3.1 YAML; if GraphQL, produce SDL.\n21 | 2. Define resources, operations, request/response schemas, error model, auth, and rate limit headers.\n22 | 3. Add examples for each endpoint or type. Include pagination and filtering conventions.\n23 | 4. Save to `apis/&lt;domain&gt;/openapi.yaml` or `apis/&lt;domain&gt;/schema.graphql`.\n24 | 5. Emit changelog entry `docs/api/CHANGELOG.md` with rationale and breaking-change flags.\n25 | \n26 | **Output format:**\n27 | \n28 | - `Contract Path`, `Design Notes`, and a fenced code block with the spec body.\n29 | \n30 | **Examples:**\n31 | \n32 | - `/api-contract \"accounts &amp; auth\"` \u2192 `apis/auth/openapi.yaml` with OAuth 2.1 flows.\n33 | \n34 | **Notes:**\n35 | \n36 | - Follow JSON:API style for REST unless caller specifies otherwise. Include `429` and `5xx` models.\n37 | \n</code></pre></p> <p>00-ideation/design/design-assets.design.md <pre><code>1 | ---\n2 | phase: \"P4 Frontend UX\"\n3 | gate: \"Accessibility checks queued\"\n4 | status: \"ensure assets support design review.\"\n5 | previous:\n6 |   - \"/modular-architecture\"\n7 | next:\n8 |   - \"/ui-screenshots\"\n9 |   - \"/logging-strategy\"\n10 | ---\n11 | \n12 | # Design Assets\n13 | \n14 | Trigger: /design-assets\n15 | \n16 | Purpose: Generate favicons and small design snippets from product brand.\n17 | \n18 | ## Steps\n19 | \n20 | 1. Extract brand colors and name from README or config.\n21 | 2. Produce favicon set, social preview, and basic UI tokens.\n22 | 3. Document asset locations and references.\n23 | \n24 | ## Output format\n25 | \n26 | - Asset checklist and generation commands.\n27 | \n</code></pre></p> <p>00-ideation/design/ui-screenshots.design.md <pre><code>1 | ---\n2 | phase: \"P4 Frontend UX\"\n3 | gate: \"Accessibility checks queued\"\n4 | status: \"capture UX issues and backlog fixes.\"\n5 | previous:\n6 |   - \"/design-assets\"\n7 |   - \"/modular-architecture\"\n8 | next:\n9 |   - \"/logging-strategy\"\n10 |   - \"/e2e-runner-setup\"\n11 | ---\n12 | \n13 | # UI Screenshots\n14 | \n15 | Trigger: /ui-screenshots\n16 | \n17 | Purpose: Analyze screenshots for UI bugs or inspiration and propose actionable UI changes.\n18 | \n19 | ## Steps\n20 | \n21 | 1. Accept screenshot paths or links.\n22 | 2. Describe visual hierarchy, spacing, contrast, and alignment issues.\n23 | 3. Output concrete CSS or component changes.\n24 | \n25 | ## Output format\n26 | \n27 | - Issue list and code snippets to fix visuals.\n28 | \n</code></pre></p> <p>00-ideation/requirements/plan-delta.requirements.md <pre><code>1 | # plan-delta\n2 | \n3 | Trigger: /plan-delta\n4 | \n5 | Purpose: Orchestrate mid-project planning deltas on an existing task graph with history preservation, lineage, and readiness recalculation.\n6 | \n7 | Steps:\n8 | \n9 | 1. Discover repository context:\n10 |    1. Detect tasks file path: prefer `tasks.json`; else search `**/tasks.json`.\n11 |    2. Detect latest plan doc: prefer `PRD.md` or `docs/PRD.md`; else `**/*(prd|spec|plan)*.md`.\n12 | 2. Snapshot:\n13 |    1. Create `./artifacts/` if missing.\n14 |    2. Copy the current tasks file to `./artifacts/tasks-$(date +%Y%m%d-%H%M%S).json` using: `cp -f &lt;tasks.json&gt; ./artifacts/tasks-$(date +%Y%m%d-%H%M%S).json`.\n15 | 3. Input collection:\n16 |    1. Read new objectives, constraints, and findings from the user input or provided delta text.\n17 |    2. Parse selection rules to choose mode: **Continue**, **Hybrid Rebaseline**, or **Full Rebaseline**.\n18 | 4. Delta Doc generation:\n19 |    1. Create `./artifacts/delta-$(date +%Y%m%d-%H%M%S).md` containing sections:\n20 |       - Objectives (new)\n21 |       - Constraints (new)\n22 |       - Impacts\n23 |       - Decisions\n24 |       - Evidence log (sources, dates, links)\n25 | 5. Task graph update:\n26 |    1. Never alter historical states `done|in_progress|blocked` of existing tasks.\n27 |    2. Do not reuse IDs. For any replaced task, set `superseded_by` on the old task and include its ID in the new task's `supersedes[]`.\n28 |    3. Add `source_doc`, `lineage[]` on all new or changed tasks.\n29 |    4. Create new tasks only for new or changed work. Link predecessors via `dependencies` or `relations`.\n30 |    5. Keep deprecated tasks in graph with `status: \"deprecated\"` and a `reason`.\n31 | 6. Graph maintenance:\n32 |    1. Recompute dependency order and validate acyclicity.\n33 |    2. Flag contradictions or invalidated edges as `blocked` with a machine-readable `blocked_reason`.\n34 |    3. Bubble critical-path tasks to the active frontier by recomputing earliest-start and slack.\n35 | 7. Readiness and selection:\n36 |    1. Implement `ready/next()` over the graph: select tasks with all dependencies `done` and not `blocked`.\n37 |    2. Produce a short readiness report grouped by `ready | blocked | deprecated`.\n38 | 8. Outputs:\n39 |    1. Write the updated tasks file in-place, preserving formatting where possible.\n40 |    2. Persist the Delta Doc under `./artifacts/`.\n41 |    3. Emit decision hooks: one line per change stating what it enables.\n42 | 9. Termination:\n43 |    - Stop when all deltas are merged and readiness recalculated, or when a prerequisite cannot be resolved with available evidence.\n44 | \n45 | Output format:\n46 | \n47 | - Produce three artifacts:\n48 |   1. **Updated tasks file**: valid JSON. Preserve existing fields. Append only the new or changed tasks and relations. Do not mutate historical statuses.\n49 |   2. **Delta document**: Markdown with the exact headings `# Delta`, `## Objectives`, `## Constraints`, `## Impacts`, `## Decisions`, `## Evidence`.\n50 |   3. **Readiness report**: Plain text with sections `READY`, `BLOCKED`, `DEPRECATED`. Each item as `- &lt;id&gt; &lt;title&gt;`; blocked items add `[reason=&lt;code&gt;]`.\n51 | - Print **Decision hooks** as lines starting with `HOOK: &lt;id&gt; enables &lt;capability&gt;`.\n52 | \n53 | Examples:\n54 | \n55 | - Input \u2192\n56 | \n57 |   ```\n58 |   Mode: Continue\n59 |   New objectives: add offline export for tasks\n60 |   Constraints: no DB migrations\n61 |   Findings: existing export lib supports JSON only\n62 |   ```\n63 | \n64 |   Output \u2192\n65 |   - Updated `tasks.json` with new task `T-342` { title: \"Add CSV export\", dependencies: [\"T-120\"], source_doc: \"delta-20250921.md\", lineage: [\"T-120\"], supersedes: [] }.\n66 |   - `artifacts/delta-20250921-160500.md` populated with objectives, constraints, impacts, decisions, evidence.\n67 |   - Readiness report lists `T-342` under READY if deps done.\n68 | \n69 | - Input \u2192\n70 | \n71 |   ```\n72 |   Mode: Hybrid Rebaseline\n73 |   Changes: ~30% of scope affected by auth provider swap\n74 |   ```\n75 | \n76 |   Output \u2192\n77 |   - Minor-plan version bump recorded in Delta Doc.\n78 |   - New tasks added for provider swap; prior tasks kept with `deprecated` or `blocked` and lineage links.\n79 | \n80 | Notes:\n81 | \n82 | - Never write outside the repo. Keep artifacts in `./artifacts/`.\n83 | - Evidence log entries include `source`, `date`, `summary`, and optional `link`.\n84 | - Selection rules: Continue (&lt;20% change), Hybrid (20\u201340%), Full (&gt;40% or goals/KPIs/architecture pivot).\n85 | - If inputs are insufficient, emit a TERMINATION note with missing evidence keys.\n</code></pre></p> <p>00-ideation/requirements/planning-process.requirements.md <pre><code>1 | ---\n2 | phase: \"P1 Plan &amp; Scope\"\n3 | gate: \"Scope Gate\"\n4 | status: \"confirm problem, users, Done criteria, and stack risks are logged.\"\n5 | previous:\n6 |   - \"Preflight Docs (AGENTS baseline)\"\n7 | next:\n8 |   - \"/scope-control\"\n9 |   - \"/stack-evaluation\"\n10 | ---\n11 | \n12 | # Planning Process\n13 | \n14 | Trigger: /planning-process\n15 | \n16 | Purpose: Draft, refine, and execute a feature plan with strict scope control and progress tracking.\n17 | \n18 | ## Steps\n19 | \n20 | 1. If no plan file exists, create `PLAN.md`. If it exists, load it.\n21 | 2. Draft sections: **Goal**, **User Story**, **Milestones**, **Tasks**, **Won't do**, **Ideas for later**, **Validation**, **Risks**.\n22 | 3. Trim bloat. Convert vague bullets into testable tasks with acceptance criteria.\n23 | 4. Tag each task with an owner and estimate. Link to files or paths that will change.\n24 | 5. Maintain two backlogs: **Won't do** (explicit non-goals) and **Ideas for later** (deferrable work).\n25 | 6. Mark tasks done after tests pass. Append commit SHAs next to completed items.\n26 | 7. After each milestone: run tests, update **Validation**, then commit `PLAN.md`.\n27 | \n28 | ## Output format\n29 | \n30 | - Update or create `PLAN.md` with the sections above.\n31 | - Include a checklist for **Tasks**. Keep lines under 100 chars.\n32 | \n33 | ## Examples\n34 | **Input**: \"Add OAuth login\"\n35 | \n36 | **Output**:\n37 | \n38 | - Goal: Let users sign in with Google.\n39 | - Tasks: [ ] add Google client, [ ] callback route, [ ] session, [ ] E2E test.\n40 | - Won't do: org SSO.\n41 | - Ideas for later: Apple login.\n42 | \n43 | ## Notes\n44 | \n45 | - Planning only. No code edits.\n46 | - Assume a Git repo with test runner available.\n47 | \n</code></pre></p> <p>00-ideation/requirements/prd-generator.requirements.md <pre><code>1 | # PRD Generator\n2 | Trigger: /prd-generate\n3 | Purpose: Produce a complete `prd.txt` in the exact section order, headers, and tone of the inline example PRD using only the repository README and visible link texts.\n4 | Steps:\n5 | \n6 | &lt;&lt;&lt;&lt;&lt;&lt;&lt; Updated upstream\n7 | 1. Read `README.md` at repo root; do not fetch external links.\n8 | 2. Extract: product name, problem, target users, value, scope, constraints, features, flows, integrations, data, non-functional needs, risks.\n9 | 3. If links exist, include their visible text or titles only as contextual hints.\n10 | 4. Fill gaps with conservative assumptions to keep the PRD complete; collect assumptions for the Appendix.\n11 | 5. Enforce strict structure identical to the example PRD\u2019s top-level headers and order.\n12 | 6. For each core feature, include What, Why, High-level How, and Acceptance criteria.\n13 | 7. In Technical Architecture, document optional platform-specific features and required fallbacks; mirror related risks.\n14 | 8. In Development Roadmap, group by phases (MVP and later); include acceptance criteria; exclude timelines.\n15 | 9. In Logical Dependency Chain, order from foundations to visible value; keep items atomic.\n16 | 10. Run an internal consistency check: features appear in roadmap; risks reflect platform and data concerns; all sections non-empty.\n17 | 11. Output only the final `prd.txt` content starting with `# Overview` and ending with `# Appendix`.\n18 | Output format:\n19 | \n20 | - Plain text PRD starting with `# Overview` and ending with `# Appendix`.\n21 | - No preamble, no postscript, no meta commentary.\n22 | Notes:\n23 | - Reject generation if `README.md` is missing.\n24 | - Do not browse external sources.\n25 | - Derived from example_prd.txt, extracted summaries only; secrets redacted.\n26 | =======\n27 | Output a plain-text file named `prd.txt` containing **only** these sections in this order (separated by one blank line):\n28 | # Overview\n29 | # Core Features\n30 | # User Experience\n31 | # Technical Architecture\n32 | # Development Roadmap\n33 | # Logical Dependency Chain\n34 | # Risks and Mitigations\n35 | # Appendix\n36 | \n37 | **Output Format**\n38 | \n39 | - `# Overview`: $3\n40 | - `# Core Features`: Each includes *What*, *Why*, *High-level How*, and BDD criteria:\n41 |   `Given ...`\n42 |   `When ...`\n43 |   `Then ...`\n44 | - `# User Experience`: Personas, key flows, UI/UX, accessibility\n45 | - `# Technical Architecture`: Components, data models, APIs/integrations, infrastructure, NFRs\n46 | - `# Development Roadmap`: MVP and Future Enhancements with acceptance criteria (no dates)\n47 | - `# Logical Dependency Chain`: Work ordering for foundations, earliest front end, extensible units\n48 | - `# Risks and Mitigations`: Each includes *Description*, *Likelihood*, *Impact*, *Mitigation*\n49 | - `# Appendix`:\n50 |   \u2022 Assumptions (bulleted)\n51 |   \u2022 Research findings from $1\n52 |   \u2022 Context notes (`- &lt;visible text&gt; \u2014 inferred topic`)\n53 |   \u2022 Technical specs\n54 | \n55 | **Validation Checks**\n56 | \n57 | - Headers present and ordered\n58 | - All BDD criteria included for features/fallbacks\n59 | - Risks include likelihood and impact\n60 | - No URLs/secrets; exactly one blank line between sections\n61 | - $1 contains **only** visible link text (no external browsing)\n62 | &gt;&gt;&gt;&gt;&gt;&gt;&gt; Stashed changes\n</code></pre></p> <p>00-ideation/requirements/scope-control.requirements.md <pre><code>1 | ---\n2 | phase: \"P1 Plan &amp; Scope\"\n3 | gate: \"Scope Gate\"\n4 | status: \"Done criteria, scope lists, and stack choices are committed.\"\n5 | previous:\n6 |   - \"/planning-process\"\n7 | next:\n8 |   - \"/stack-evaluation\"\n9 |   - \"/scaffold-fullstack\"\n10 | ---\n11 | \n12 | # Scope Control\n13 | \n14 | Trigger: /scope-control\n15 | \n16 | Purpose: Enforce explicit scope boundaries and maintain \"won't do\" and \"ideas for later\" lists.\n17 | \n18 | ## Steps\n19 | \n20 | 1. Parse `PLAN.md` or create it if absent.\n21 | 2. For each open task, confirm linkage to the current milestone.\n22 | 3. Detect off-scope items and move them to **Won't do** or **Ideas for later** with rationale.\n23 | 4. Add a \"Scope Gate\" checklist before merging.\n24 | \n25 | ## Output format\n26 | \n27 | - Patch to `PLAN.md` showing changes in sections and checklists.\n28 | \n29 | ## Examples\n30 | Input: off-scope request \"Add email templates\" during OAuth feature.\n31 | Output: Move to **Ideas for later** with reason \"Not needed for OAuth MVP\".\n32 | \n33 | ## Notes\n34 | \n35 | - Never add new scope without recording tradeoffs.\n36 | \n</code></pre></p> <p>10-scaffold/conventions/version-control-guide.conventions.md <pre><code>1 | ---\n2 | phase: \"P6 CI/CD &amp; Env\"\n3 | gate: \"Review Gate\"\n4 | status: \"clean diff, CI green, and approvals ready.\"\n5 | previous:\n6 |   - \"/regression-guard\"\n7 | next:\n8 |   - \"/devops-automation\"\n9 |   - \"/env-setup\"\n10 | ---\n11 | \n12 | # Version Control Guide\n13 | \n14 | Trigger: /version-control-guide\n15 | \n16 | Purpose: Enforce clean incremental commits and clean-room re-implementation when finalizing.\n17 | \n18 | ## Steps\n19 | \n20 | 1. Start each feature from a clean branch: `git switch -c &lt;feat&gt;`.\n21 | 2. Commit in vertical slices with passing tests: `git add -p &amp;&amp; git commit`.\n22 | 3. When solution is proven, recreate a minimal clean diff: stash or copy results, reset, then apply only the final changes.\n23 | 4. Use `git revert` for bad commits instead of force-pushing shared branches.\n24 | \n25 | ## Output format\n26 | \n27 | - Checklist plus suggested commands for the current repo state.\n28 | \n29 | ## Examples\n30 | \n31 | - Convert messy spike into three commits: setup, feature, tests.\n32 | \n33 | ## Notes\n34 | \n35 | - Never modify remote branches without confirmation.\n36 | \n</code></pre></p> <p>10-scaffold/scaffold/auth.scaffold.md <pre><code>1 | ---\n2 | phase: \"P3 Data &amp; Auth\"\n3 | gate: \"Migration dry-run\"\n4 | status: \"auth flows threat-modeled and test accounts wired.\"\n5 | previous:\n6 |   - \"/migration-plan\"\n7 | next:\n8 |   - \"/modular-architecture\"\n9 |   - \"/ui-screenshots\"\n10 |   - \"/e2e-runner-setup\"\n11 | ---\n12 | \n13 | # Auth Scaffold\n14 | \n15 | Trigger: /auth-scaffold &lt;oauth|email|oidc&gt;\n16 | \n17 | Purpose: Scaffold auth flows, routes, storage, and a basic threat model.\n18 | \n19 | **Steps:**\n20 | \n21 | 1. Select provider (OAuth/OIDC/email) and persistence for sessions.\n22 | 2. Generate routes: login, callback, logout, session refresh.\n23 | 3. Add CSRF, state, PKCE where applicable. Include secure cookie flags.\n24 | 4. Document threat model: replay, fixation, token leakage, SSRF on callbacks.\n25 | 5. Wire to frontend with protected routes and user context.\n26 | \n27 | **Output format:** route list, config keys, and mitigations table.\n28 | \n29 | **Examples:** `/auth-scaffold oauth` \u2192 NextAuth/Passport/Custom adapter plan.\n30 | \n31 | **Notes:** Never print real secrets. Use placeholders in `.env.example`.\n32 | \n</code></pre></p> <p>10-scaffold/scaffold/db-bootstrap.scaffold.md <pre><code>1 | ---\n2 | phase: \"P3 Data &amp; Auth\"\n3 | gate: \"Migration dry-run\"\n4 | status: \"migrations apply/rollback cleanly with seeds populated.\"\n5 | previous:\n6 |   - \"/modular-architecture\"\n7 | next:\n8 |   - \"/migration-plan\"\n9 |   - \"/auth-scaffold\"\n10 | ---\n11 | \n12 | # DB Bootstrap\n13 | \n14 | Trigger: /db-bootstrap &lt;postgres|mysql|sqlite|mongodb&gt;\n15 | \n16 | Purpose: Pick a database, initialize migrations, local compose, and seed scripts.\n17 | \n18 | **Steps:**\n19 | \n20 | 1. Create `db/compose.yaml` for local dev (skip for sqlite).\n21 | 2. Choose ORM/driver (Prisma or Drizzle for SQL). Add migration config.\n22 | 3. Create `prisma/schema.prisma` or `drizzle/*.ts` with baseline tables (users, sessions, audit_log).\n23 | 4. Add `pnpm db:migrate`, `db:reset`, `db:seed` scripts. Write seed data for local admin user.\n24 | 5. Update `.env.example` with `DATABASE_URL` and test connection script.\n25 | \n26 | **Output format:** Migration plan list and generated file paths.\n27 | \n28 | **Examples:** `/db-bootstrap postgres` \u2192 Prisma + Postgres docker-compose.\n29 | \n30 | **Notes:** Avoid destructive defaults; provide `--preview-feature` warnings if relevant.\n31 | \n</code></pre></p> <p>10-scaffold/scaffold/fullstack.scaffold.md <pre><code>1 | ---\n2 | phase: \"P2 App Scaffold &amp; Contracts\"\n3 | gate: \"Test Gate lite\"\n4 | status: \"ensure lint/build scripts execute on the generated scaffold.\"\n5 | previous:\n6 |   - \"/stack-evaluation\"\n7 | next:\n8 |   - \"/api-contract\"\n9 |   - \"/openapi-generate\"\n10 |   - \"/modular-architecture\"\n11 | ---\n12 | \n13 | # Scaffold Full\u2011Stack App\n14 | \n15 | Trigger: /scaffold-fullstack &lt;stack&gt;\n16 | \n17 | Purpose: Create a minimal, production-ready monorepo template with app, API, tests, CI seeds, and infra stubs.\n18 | \n19 | **Steps:**\n20 | \n21 | 1. Read repository context: `git rev-parse --is-inside-work-tree`.\n22 | 2. If repo is empty, initialize: `git init -b main` and create `.editorconfig`, `.gitignore`, `README.md`.\n23 | 3. For `&lt;stack&gt;` derive presets (examples):\n24 |    - `ts-next-express-pg`: Next.js app, Express API, Prisma + PostgreSQL, Playwright, pnpm workspaces.\n25 |    - `ts-vite-fastify-sqlite`: Vite + React app, Fastify API, Drizzle + SQLite.\n26 | 4. Create workspace layout:\n27 |    - root: `package.json` with `pnpm` workspaces, `tsconfig.base.json`, `eslint`, `prettier`.\n28 |    - apps/web, apps/api, packages/ui, packages/config.\n29 | 5. Add scripts:\n30 |    - root: `dev`, `build`, `lint`, `typecheck`, `test`, `e2e`, `format`.\n31 |    - web: Next/Vite scripts. api: dev with ts-node or tsx.\n32 | 6. Seed CI files: `.github/workflows/ci.yml` with jobs [lint, typecheck, test, build, e2e] and artifact uploads.\n33 | 7. Add example routes:\n34 |    - web: `/health` page. api: `GET /health` returning `{ ok: true }`.\n35 | 8. Write docs to `README.md`: how to run dev, test, build, and env variables.\n36 | 9. Stage files, but do not commit. Output a tree and next commands.\n37 | \n38 | **Output format:**\n39 | \n40 | - Title line: `Scaffold created: &lt;stack&gt;`\n41 | - Sections: `Repo Tree`, `Next Steps`, `CI Seeds`.\n42 | - Include a fenced code block of the `tree` and sample scripts.\n43 | \n44 | **Examples:**\n45 | \n46 | - **Input:** `/scaffold-fullstack ts-next-express-pg`\n47 |   **Output:** Summary + tree with `apps/web`, `apps/api`, `packages/ui`.\n48 | - **Input:** `/scaffold-fullstack ts-vite-fastify-sqlite`\n49 |   **Output:** Summary + tree + Drizzle config.\n50 | \n51 | **Notes:**\n52 | \n53 | - Assume pnpm and Node 20+. Do not run package installs automatically; propose commands instead.\n54 | - Respect existing files; avoid overwriting without explicit confirmation.\n55 | \n</code></pre></p> <p>10-scaffold/scaffold/iac-bootstrap.scaffold.md <pre><code>1 | ---\n2 | phase: \"P6 CI/CD &amp; Env\"\n3 | gate: \"Review Gate\"\n4 | status: \"IaC applied in staging with drift detection configured.\"\n5 | previous:\n6 |   - \"/secrets-manager-setup\"\n7 | next:\n8 |   - \"/owners\"\n9 |   - \"/review\"\n10 | ---\n11 | \n12 | # IaC Bootstrap\n13 | \n14 | Trigger: /iac-bootstrap &lt;aws|gcp|azure|fly|render&gt;\n15 | \n16 | Purpose: Create minimal Infrastructure-as-Code for the chosen platform plus CI hooks.\n17 | \n18 | **Steps:**\n19 | \n20 | 1. Select tool (Terraform, Pulumi). Initialize backend and state.\n21 | 2. Define stacks for `preview`, `staging`, `prod`. Add outputs (URLs, connection strings).\n22 | 3. Add CI jobs: plan on PR, apply on main with manual approval.\n23 | 4. Document rollback and drift detection.\n24 | \n25 | **Output format:** stack diagram, file list, CI snippets.\n26 | \n27 | **Examples:** `/iac-bootstrap aws`.\n28 | \n29 | **Notes:** Prefer least privilege IAM and remote state with locking.\n30 | \n</code></pre></p> <p>10-scaffold/ci-setup/devops-automation.ci-setup.md <pre><code>1 | ---\n2 | phase: \"P6 CI/CD &amp; Env\"\n3 | gate: \"Review Gate\"\n4 | status: \"CI pipeline codified, rollback steps rehearsed.\"\n5 | previous:\n6 |   - \"/version-control-guide\"\n7 | next:\n8 |   - \"/env-setup\"\n9 |   - \"/secrets-manager-setup\"\n10 |   - \"/iac-bootstrap\"\n11 | ---\n12 | \n13 | # DevOps Automation\n14 | \n15 | Trigger: /devops-automation\n16 | \n17 | Purpose: Configure servers, DNS, SSL, CI/CD at a pragmatic level.\n18 | \n19 | ## Steps\n20 | \n21 | 1. Inspect repo for IaC or deploy scripts.\n22 | 2. Generate Terraform or Docker Compose templates if missing.\n23 | 3. Propose CI workflows for tests, builds, and deploys.\n24 | 4. Provide runbooks for rollback.\n25 | \n26 | ## Output format\n27 | \n28 | - Infra plan with checkpoints and secrets placeholders.\n29 | \n</code></pre></p> <p>10-scaffold/ci-setup/env-setup.ci-setup.md <pre><code>1 | ---\n2 | phase: \"P6 CI/CD &amp; Env\"\n3 | gate: \"Review Gate\"\n4 | status: \"environment schemas enforced and CI respects strict loading.\"\n5 | previous:\n6 |   - \"/devops-automation\"\n7 | next:\n8 |   - \"/secrets-manager-setup\"\n9 |   - \"/iac-bootstrap\"\n10 | ---\n11 | \n12 | # Env Setup\n13 | \n14 | Trigger: /env-setup\n15 | \n16 | Purpose: Create .env.example, runtime schema validation, and per-env overrides.\n17 | \n18 | **Steps:**\n19 | \n20 | 1. Scan repo for `process.env` usage and collected keys.\n21 | 2. Emit `.env.example` with comments and safe defaults.\n22 | 3. Add runtime validation via `zod` or `envsafe` in `packages/config`.\n23 | 4. Document `development`, `staging`, `production` precedence and loading order.\n24 | \n25 | **Output format:** `.env.example` content block and `config/env.ts` snippet.\n26 | \n27 | **Examples:** `/env-setup`.\n28 | \n29 | **Notes:** Do not include real credentials. Enforce `STRICT_ENV=true` in CI.\n30 | \n</code></pre></p> <p>10-scaffold/ci-setup/monitoring-setup.ci-setup.md <pre><code>1 | ---\n2 | phase: \"P7 Release &amp; Ops\"\n3 | gate: \"Release Gate\"\n4 | status: \"observability baselines ready before rollout.\"\n5 | previous:\n6 |   - \"/version-proposal\"\n7 | next:\n8 |   - \"/slo-setup\"\n9 |   - \"/logging-strategy\"\n10 | ---\n11 | \n12 | # Monitoring Setup\n13 | \n14 | Trigger: /monitoring-setup\n15 | \n16 | Purpose: Bootstrap logs, metrics, and traces with dashboards per domain.\n17 | \n18 | **Steps:**\n19 | \n20 | 1. Choose stack: OpenTelemetry \u2192 Prometheus/Grafana, or vendor.\n21 | 2. Instrument web and api for request latency, error rate, throughput, and core domain metrics.\n22 | 3. Provide default dashboards JSON and alert examples.\n23 | \n24 | **Output format:** instrumentation checklist and dashboard links/paths.\n25 | \n26 | **Examples:** `/monitoring-setup`.\n27 | \n28 | **Notes:** Avoid high\u2011cardinality labels. Sample traces selectively in prod.\n29 | \n</code></pre></p> <p>10-scaffold/ci-setup/slo-setup.ci-setup.md <pre><code>1 | ---\n2 | phase: \"P7 Release &amp; Ops\"\n3 | gate: \"Release Gate\"\n4 | status: \"SLOs and alerts reviewed before production rollout.\"\n5 | previous:\n6 |   - \"/monitoring-setup\"\n7 | next:\n8 |   - \"/logging-strategy\"\n9 |   - \"/audit\"\n10 | ---\n11 | \n12 | # SLO Setup\n13 | \n14 | Trigger: /slo-setup\n15 | \n16 | Purpose: Define Service Level Objectives, burn alerts, and runbooks.\n17 | \n18 | **Steps:**\n19 | \n20 | 1. Choose SLI/metrics per user journey. Define SLO targets and error budgets.\n21 | 2. Create burn alerts (fast/slow) and link to runbooks.\n22 | 3. Add `SLO.md` with rationale and review cadence.\n23 | \n24 | **Output format:** SLO table and alert rules snippet.\n25 | \n26 | **Examples:** `/slo-setup`.\n27 | \n28 | **Notes:** Tie SLOs to deploy gates and incident severity.\n29 | \n</code></pre></p> <p>20-implementation/review/audit.review.md <pre><code>1 | ---\n2 | phase: \"P7 Release &amp; Ops\"\n3 | gate: \"Release Gate\"\n4 | status: \"readiness criteria before shipping.\"\n5 | previous:\n6 |   - \"/logging-strategy\"\n7 | next:\n8 |   - \"/error-analysis\"\n9 |   - \"/fix\"\n10 | ---\n11 | \n12 | # Audit\n13 | \n14 | Trigger: /audit\n15 | \n16 | Purpose: Audit repository hygiene and suggest improvements.\n17 | \n18 | ## Steps\n19 | \n20 | 1. Gather context by running `ls -la` for the top-level listing. Inspect `.editorconfig`, `.gitignore`, `.geminiignore`, `.eslintrc.cjs`, `.eslintrc.js`, `tsconfig.json`, and `pyproject.toml` if present to understand shared conventions.\n21 | 2. Assess repository hygiene across documentation, testing, CI, linting, and security. Highlight gaps and existing automation.\n22 | 3. Synthesize the findings into a prioritized checklist with recommended next steps.\n23 | \n24 | ## Output format\n25 | \n26 | - Begin with a concise summary that restates the goal: Audit repository hygiene and suggest improvements.\n27 | - Offer prioritized, actionable recommendations with rationale.\n28 | - Call out test coverage gaps and validation steps.\n29 | - Highlight workflow triggers, failing jobs, and proposed fixes.\n30 | \n31 | ## Example input\n32 | \n33 | (none \u2013 command runs without arguments)\n34 | \n35 | ## Expected output\n36 | \n37 | - Structured report following the specified sections.\n38 | \n</code></pre></p> <p>20-implementation/review/cross-check.review.md <pre><code>1 | # Conflict Resolver\n2 | \n3 | Trigger: /cross-check\n4 | \n5 | Purpose: Compare conflicting findings and decide which source prevails with rationale.\n6 | \n7 | Steps:\n8 | \n9 | 1. Accept a list of SourceIDs or URLs with short findings.\n10 | 2. Evaluate publisher authority, recency, directness to primary data.\n11 | 3. Select the prevailing source; note contradictions and rationale.\n12 | \n13 | Output format:\n14 | \n15 | ```\n16 | ### Contradictions\n17 | - {S2 vs S5 \u2192 rationale}\n18 | \n19 | ### Prevails\n20 | - {SourceID} because {reason}\n21 | ```\n22 | \n23 | Examples:\n24 | \n25 | - Input: `/cross-check S2: blog vs S5: RFC`\n26 | - Output: RFC prevails due to primary standard.\n27 | \n28 | Notes:\n29 | \n30 | - Always explain why one source prevails.\n</code></pre></p> <p>20-implementation/review/evidence-capture.review.md <pre><code>1 | # Evidence Logger\n2 | \n3 | Trigger: /evidence-capture\n4 | \n5 | Purpose: Capture sources for a specified claim with dates, \u226425-word quotes, findings, relevance, and confidence.\n6 | \n7 | Steps:\n8 | \n9 | 1. Read the claim text and optional URLs provided.\n10 | 2. For each source, record metadata and a \u226425-word quote.\n11 | 3. Add a brief Finding, Relevance (H/M/L), and Confidence (0.0\u20131.0).\n12 | \n13 | Output format:\n14 | \n15 | ```\n16 | ### Evidence Log\n17 | | SourceID | Title | Publisher | URL | PubDate | Accessed | Quote (\u226425w) | Finding | Rel | Conf |\n18 | |---|---|---|---|---|---|---|---|---|---|\n19 | ```\n20 | \n21 | Examples:\n22 | \n23 | - Input: `/evidence-capture \"Next.js 15 requires React 19 RC\"` with official links.\n24 | - Output: Evidence table entries with dates.\n25 | \n26 | Notes:\n27 | \n28 | - Mark missing PubDate as n/a. Prefer official documentation.\n</code></pre></p> <p>20-implementation/review/pr-desc.review.md <pre><code>1 | ---\n2 | phase: \"P7 Release &amp; Ops\"\n3 | gate: \"Review Gate\"\n4 | status: \"PR narrative ready for approvals and release prep.\"\n5 | previous:\n6 |   - \"/review-branch\"\n7 | next:\n8 |   - \"/release-notes\"\n9 |   - \"/version-proposal\"\n10 | ---\n11 | \n12 | # PR Description\n13 | \n14 | Trigger: /pr-desc &lt;context&gt;\n15 | \n16 | Purpose: Draft a PR description from the branch diff.\n17 | \n18 | You are a CLI assistant focused on helping contributors with the task: Draft a PR description from the branch diff.\n19 | \n20 | 1. Gather context by running `git diff --name-status origin/main...HEAD` for the changed files (name + status); running `git diff --shortstat origin/main...HEAD` for the high\u2011level stats.\n21 | 2. Create a crisp PR description following this structure: Summary, Context, Changes, Screenshots (if applicable), Risk, Test Plan, Rollback, Release Notes (if user\u2011facing). Base branch: origin/main User context: &lt;args&gt;.\n22 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n23 | \n24 | Output:\n25 | \n26 | - Begin with a concise summary that restates the goal: Draft a PR description from the branch diff.\n27 | - Offer prioritized, actionable recommendations with rationale.\n28 | - Call out test coverage gaps and validation steps.\n29 | - Highlight workflow triggers, failing jobs, and proposed fixes.\n30 | \n31 | Example Input:\n32 | src/example.ts\n33 | \n34 | Expected Output:\n35 | \n36 | - Actionable summary aligned with the output section.\n37 | \n</code></pre></p> <p>20-implementation/review/review-branch.review.md <pre><code>1 | ---\n2 | phase: \"P7 Release &amp; Ops\"\n3 | gate: \"Review Gate\"\n4 | status: \"branch scope validated before PR submission.\"\n5 | previous:\n6 |   - \"/review\"\n7 | next:\n8 |   - \"/pr-desc\"\n9 |   - \"/release-notes\"\n10 | ---\n11 | \n12 | # Review Branch\n13 | \n14 | Trigger: /review-branch\n15 | \n16 | Purpose: Provide a high-level review of the current branch versus origin/main.\n17 | \n18 | You are a CLI assistant focused on helping contributors with the task: Provide a high\u2011level review of the current branch vs origin/main.\n19 | \n20 | 1. Gather context by running `git diff --stat origin/main...HEAD` for the diff stats; running `git diff origin/main...HEAD | sed -n '1,200p'` for the ```diff.\n21 | 2. Provide a reviewer\u2011friendly overview: goals, scope, risky areas, test impact.\n22 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n23 | \n24 | Output:\n25 | \n26 | - Begin with a concise summary that restates the goal: Provide a high\u2011level review of the current branch vs origin/main.\n27 | - Organize details under clear subheadings so contributors can scan quickly.\n28 | - Call out test coverage gaps and validation steps.\n29 | \n30 | Example Input:\n31 | (none \u2013 command runs without arguments)\n32 | \n33 | Expected Output:\n34 | \n35 | - Structured report following the specified sections.\n36 | \n</code></pre></p> <p>20-implementation/review/review.review.md <pre><code>1 | ---\n2 | phase: \"P7 Release &amp; Ops\"\n3 | gate: \"Review Gate\"\n4 | status: \"peer review coverage met before merging.\"\n5 | previous:\n6 |   - \"/owners\"\n7 | next:\n8 |   - \"/review-branch\"\n9 |   - \"/pr-desc\"\n10 | ---\n11 | \n12 | # Review\n13 | \n14 | Trigger: /review &lt;pattern&gt;\n15 | \n16 | Purpose: Review code matching a pattern and deliver actionable feedback.\n17 | \n18 | You are a CLI assistant focused on helping contributors with the task: Review code matching a pattern and give actionable feedback.\n19 | \n20 | 1. Gather context by running `rg -n {{args}} . || grep -RIn {{args}} .` for the search results for {{args}} (filename or regex).\n21 | 2. Perform a thorough code review. Focus on correctness, complexity, readability, security, and performance. Provide concrete patch suggestions.\n22 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n23 | \n24 | Output:\n25 | \n26 | - Begin with a concise summary that restates the goal: Review code matching a pattern and give actionable feedback.\n27 | - Provide unified diff-style patches when recommending code changes.\n28 | - Organize details under clear subheadings so contributors can scan quickly.\n29 | \n30 | Example Input:\n31 | HttpClient\n32 | \n33 | Expected Output:\n34 | \n35 | - Usage cluster in src/network/* with note on inconsistent error handling.\n36 | \n</code></pre></p> <p>20-implementation/review/todo-report.review.md <pre><code>1 | You are a CLI assistant focused on helping contributors with the task: Summarize TODO/FIXME/XXX annotations across the codebase.\n2 | \n3 | 1. Gather context by running `rg -n \"TODO|FIXME|XXX\" -g '!node_modules' . || grep -RInE 'TODO|FIXME|XXX' .`.\n4 | 2. Aggregate and group TODO/FIXME/XXX by area and priority. Propose a triage plan.\n5 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n6 | \n7 | Output:\n8 | \n9 | - Begin with a concise summary that restates the goal: Summarize TODO/FIXME/XXX annotations across the codebase.\n10 | - Offer prioritized, actionable recommendations with rationale.\n11 | - Organize details under clear subheadings so contributors can scan quickly.\n12 | \n13 | Example Input:\n14 | (none \u2013 command runs without arguments)\n15 | \n16 | Expected Output:\n17 | \n18 | - Group: Platform backlog \u2014 4 TODOs referencing auth migration (owner: @platform).\n</code></pre></p> <p>20-implementation/review/tsconfig-review.review.md <pre><code>1 | You are a CLI assistant focused on helping contributors with the task: Review tsconfig for correctness and DX.\n2 | \n3 | 1. Gather context by inspecting `tsconfig.json`.\n4 | 2. Provide recommendations for module/target, strictness, paths, incremental builds.\n5 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n6 | \n7 | Output:\n8 | \n9 | - Begin with a concise summary that restates the goal: Review tsconfig for correctness and DX.\n10 | - Offer prioritized, actionable recommendations with rationale.\n11 | - Document the evidence you used so maintainers can trust the conclusion.\n12 | \n13 | Example Input:\n14 | (none \u2013 command runs without arguments)\n15 | \n16 | Expected Output:\n17 | \n18 | - Structured report following the specified sections.\n</code></pre></p> <p>20-implementation/spec-orient/blame-summary.spec-orient.md <pre><code>1 | You are a CLI assistant focused on helping contributors with the task: Summarize authorship hotspots for a file using git blame.\n2 | \n3 | 1. Gather context by running `git blame -w --line-porcelain {{args}} | sed -n 's/^author //p' | sort | uniq -c | sort -nr | sed -n '1,25p'` for the blame authors (top contributors first).\n4 | 2. Given the blame summary below, identify ownership hotspots and potential reviewers.\n5 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n6 | \n7 | Output:\n8 | \n9 | - Begin with a concise summary that restates the goal: Summarize authorship hotspots for a file using git blame.\n10 | - Organize details under clear subheadings so contributors can scan quickly.\n11 | - Reference evidence from CODEOWNERS or git history for each owner suggestion.\n12 | \n13 | Example Input:\n14 | src/components/Button.tsx\n15 | \n16 | Expected Output:\n17 | \n18 | - Refactor proposal extracting shared styling hook with before/after snippet.\n</code></pre></p> <p>20-implementation/spec-orient/changed-files.spec-orient.md <pre><code>1 | You are a CLI assistant focused on helping contributors with the task: Summarize changed files between HEAD and origin/main.\n2 | \n3 | 1. Gather context by running `git diff --name-status origin/main...HEAD`.\n4 | 2. List and categorize changed files: added/modified/renamed/deleted. Call out risky changes.\n5 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n6 | \n7 | Output:\n8 | \n9 | - Begin with a concise summary that restates the goal: Summarize changed files between HEAD and origin/main.\n10 | - Document the evidence you used so maintainers can trust the conclusion.\n11 | \n12 | Example Input:\n13 | (none \u2013 command runs without arguments)\n14 | \n15 | Expected Output:\n16 | \n17 | - Structured report following the specified sections.\n</code></pre></p> <p>20-implementation/spec-orient/explain-code.spec-orient.md <pre><code>1 | ---\n2 | phase: \"P7 Release &amp; Ops\"\n3 | gate: \"Review Gate\"\n4 | status: \"Improve reviewer comprehension before approvals.\"\n5 | previous:\n6 |   - \"/owners\"\n7 |   - \"/review\"\n8 | next:\n9 |   - \"/review-branch\"\n10 |   - \"/pr-desc\"\n11 | ---\n12 | \n13 | # Explain Code\n14 | \n15 | Trigger: /explain-code\n16 | \n17 | Purpose: Provide line-by-line explanations for a given file or diff.\n18 | \n19 | ## Steps\n20 | \n21 | 1. Accept a file path or apply to staged diff.\n22 | 2. Explain blocks with comments on purpose, inputs, outputs, and caveats.\n23 | 3. Highlight risky assumptions and complexity hot spots.\n24 | \n25 | ## Output format\n26 | \n27 | - Annotated markdown with code fences and callouts.\n28 | \n</code></pre></p> <p>20-implementation/spec-orient/explain-symbol.spec-orient.md <pre><code>1 | You are a CLI assistant focused on helping contributors with the task: Explain where and how a symbol is defined and used.\n2 | \n3 | 1. Gather context by running `rg -n {{args}} . || grep -RIn {{args}} .` for the results.\n4 | 2. Explain where and how a symbol is defined and used.\n5 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n6 | \n7 | Output:\n8 | \n9 | - Begin with a concise summary that restates the goal: Explain where and how a symbol is defined and used.\n10 | - Organize details under clear subheadings so contributors can scan quickly.\n11 | - Document the evidence you used so maintainers can trust the conclusion.\n12 | \n13 | Example Input:\n14 | HttpClient\n15 | \n16 | Expected Output:\n17 | \n18 | - Definition: src/network/httpClient.ts line 42\n19 | - Key usages: services/userService.ts, hooks/useRequest.ts\n</code></pre></p> <p>20-implementation/spec-orient/grep.spec-orient.md <pre><code>1 | You are a CLI assistant focused on helping contributors with the task: Recursive text search with ripgrep/grep injection.\n2 | \n3 | 1. Gather context by running `rg -n {{args}} . || grep -RIn {{args}} .`.\n4 | 2. Show matched lines with file paths and line numbers.\n5 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n6 | \n7 | Output:\n8 | \n9 | - Begin with a concise summary that restates the goal: Recursive text search with ripgrep/grep injection.\n10 | - Document the evidence you used so maintainers can trust the conclusion.\n11 | \n12 | Example Input:\n13 | HttpClient\n14 | \n15 | Expected Output:\n16 | \n17 | - Usage cluster in src/network/* with note on inconsistent error handling.\n</code></pre></p> <p>20-implementation/spec-orient/research-batch.spec-orient.md <pre><code>1 | # Conversation-Aware Research \u2014 Batch WBRO\n2 | \n3 | Trigger: /research-batch\n4 | \n5 | Purpose: Process a numbered work-breakdown list of objectives with carry-forward context across items and produce a roll-up summary.\n6 | \n7 | Steps:\n8 | \n9 | 1. Parse numbered WBRO items from the input after the trigger.\n10 | 2. Before Item 1: list \u22645 bullets of starting context.\n11 | 3. For each item i: execute the per-item workflow and include a Conversation State Update.\n12 | 4. If blocked by prior gaps, emit **Dependency Blocked** with a minimal micro-query.\n13 | 5. After all items: emit a Roll-up Summary with per-item status, enabled decisions, unresolved risks, and a domain-type count of sources.\n14 | \n15 | Output format:\n16 | \n17 | - Repeat the single-item format per item.\n18 | - End with:\n19 | \n20 | ```\n21 | ## Roll-up Summary\n22 | - Item {n}: {status} \u2014 decision enabled: {\u2026}; risks: {\u2026}\n23 | - Sources by domain type: {gov, org, docs, blog, news}\n24 | ```\n25 | \n26 | Examples:\n27 | \n28 | - Input: `/research-batch 1) Validate Next.js 15 stability. 2) Compare Bun vs Node for CI. 3) Licensing risks for MIT vs Apache-2.0.`\n29 | - Output: Per-item sections plus roll-up.\n30 | \n31 | Notes:\n32 | \n33 | - Keep quotes \u226425 words. Prefer primary docs.\n</code></pre></p> <p>20-implementation/spec-orient/research-item.spec-orient.md <pre><code>1 | # Conversation-Aware Research \u2014 Single Item\n2 | \n3 | Trigger: /research-item\n4 | \n5 | Purpose: Run the full per-item research workflow for one objective and return queries, evidence, synthesis, contradictions, gaps, decision hook, plus a conversation state update.\n6 | \n7 | Steps:\n8 | \n9 | 1. Read the objective text following the trigger.\n10 | 2. Capture starting context if provided.\n11 | 3. Apply the Process (per item): Goal, Assumptions, Query Set (4\u20138), Search Plan, Run &amp; Capture, Cross-check, Synthesis, Gaps &amp; Next, Decision Hook.\n12 | 4. Track PubDate and Accessed (ISO) for every source; prefer primary docs.\n13 | 5. Enforce quotes \u226425 words; mark inferences as \"Inference\".\n14 | \n15 | Output format:\n16 | \n17 | ```\n18 | ## Item 1: {short title}\n19 | \n20 | ### Goal\n21 | {1 sentence}\n22 | \n23 | ### Assumptions\n24 | - {only if needed}\n25 | \n26 | ### Query Set\n27 | - {Q1}\n28 | - {Q2}\n29 | - {Q3}\n30 | - {Q4\u2013Q8}\n31 | \n32 | ### Evidence Log\n33 | | SourceID | Title | Publisher | URL | PubDate | Accessed | Quote (\u226425w) | Finding | Rel | Conf |\n34 | |---|---|---|---|---|---|---|---|---|---|\n35 | \n36 | ### Synthesis\n37 | - {claim with [S1,S3]}\n38 | - {finding with [S2]}\n39 | - {risk/edge with [S4]}\n40 | \n41 | ### Contradictions\n42 | - {S2 vs S5 \u2192 rationale}\n43 | \n44 | ### Gaps &amp; Next\n45 | - {follow-up or test}\n46 | \n47 | ### Decision Hook\n48 | {one line}\n49 | \n50 | ### Conversation State Update\n51 | - New facts: {bullets}\n52 | - Constraints learned: {bullets}\n53 | - Entities normalized: {canonical forms}\n54 | ```\n55 | \n56 | Examples:\n57 | \n58 | - Input: `/research-item Compare OpenAPI 3.1 tooling for Python clients in 2024; budget $0; prefer official docs.`\n59 | - Output: As per format with SourceIDs and dates.\n60 | \n61 | Notes:\n62 | \n63 | - Safety: No personal data. Do not fabricate sources.\n64 | - Provenance: Cite reputable sources; record n/a for missing PubDate.\n</code></pre></p> <p>40-testing/coverage/guide.coverage.md <pre><code>1 | ---\n2 | phase: \"P5 Quality Gates &amp; Tests\"\n3 | gate: \"Test Gate\"\n4 | status: \"coverage targets and regression guard plan recorded.\"\n5 | previous:\n6 |   - \"/integration-test\"\n7 | next:\n8 |   - \"/regression-guard\"\n9 |   - \"/version-control-guide\"\n10 | ---\n11 | \n12 | # Coverage Guide\n13 | \n14 | Trigger: /coverage-guide\n15 | \n16 | Purpose: Propose high-ROI tests to raise coverage using uncovered areas.\n17 | \n18 | You are a CLI assistant focused on helping contributors with the task: Suggest a plan to raise coverage based on uncovered areas.\n19 | \n20 | 1. Gather context by running `find . -name 'coverage*' -type f -maxdepth 3 -print -exec head -n 40 {} \\; 2&gt;/dev/null` for the coverage hints; running `git ls-files | sed -n '1,400p'` for the repo map.\n21 | 2. Using coverage artifacts (if available) and repository map, propose the highest\u2011ROI tests to add.\n22 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n23 | \n24 | Output:\n25 | \n26 | - Begin with a concise summary that restates the goal: Suggest a plan to raise coverage based on uncovered areas.\n27 | - Offer prioritized, actionable recommendations with rationale.\n28 | - Call out test coverage gaps and validation steps.\n29 | \n30 | Example Input:\n31 | (none \u2013 command runs without arguments)\n32 | \n33 | Expected Output:\n34 | \n35 | - Focus on src/auth/login.ts \u2014 0% branch coverage; add error path test.\n36 | \n</code></pre></p> <p>40-testing/coverage/regression-guard.coverage.md <pre><code>1 | ---\n2 | phase: \"P5 Quality Gates &amp; Tests\"\n3 | gate: \"Test Gate\"\n4 | status: \"regression coverage in place before CI hand-off.\"\n5 | previous:\n6 |   - \"/coverage-guide\"\n7 | next:\n8 |   - \"/version-control-guide\"\n9 |   - \"/devops-automation\"\n10 | ---\n11 | \n12 | # Regression Guard\n13 | \n14 | Trigger: /regression-guard\n15 | \n16 | Purpose: Detect unrelated changes and add tests to prevent regressions.\n17 | \n18 | ## Steps\n19 | \n20 | 1. Run `git diff --name-status origin/main...HEAD` and highlight unrelated files.\n21 | 2. Propose test cases that lock current behavior for touched modules.\n22 | 3. Suggest CI checks to block large unrelated diffs.\n23 | \n24 | ## Output format\n25 | \n26 | - Report with file groups, risk notes, and test additions.\n27 | \n28 | ## Notes\n29 | \n30 | - Keep proposed tests minimal and focused.\n31 | \n</code></pre></p> <p>20-implementation/impl/commit.impl.md <pre><code>1 | ---\n2 | phase: \"P6 CI/CD &amp; Env\"\n3 | gate: \"Review Gate\"\n4 | status: \"clean diff, CI green, and approvals ready.\"\n5 | previous:\n6 |   - \"/version-control-guide\"\n7 | next:\n8 |   - \"/devops-automation\"\n9 |   - \"/env-setup\"\n10 | ---\n11 | \n12 | # Commit Message Assistant\n13 | \n14 | Trigger: `commit`\n15 | \n16 | Purpose: Generate a conventional, review-ready commit message from the currently staged changes.\n17 | \n18 | Output: A finalized commit message with a 50\u201372 character imperative subject line, optional scope, and supporting body lines describing the rationale, evidence, and tests.\n19 | \n20 | ## Steps\n21 | \n22 | 1. Verify there is staged work with `git status --short` and stop with guidance if nothing is staged.\n23 | 2. Inspect the staged diff with `git diff --staged` and identify the primary change type (feat, fix, chore, docs, refactor, etc.) and optional scope (e.g., package or module).\n24 | 3. Draft a concise subject line in the form `&lt;type&gt;(&lt;scope&gt;): &lt;imperative summary&gt;` or `&lt;type&gt;: &lt;imperative summary&gt;` when no scope applies. Keep the line under 73 characters.\n25 | 4. Capture essential details in the body as wrapped bullet points or paragraphs: what changed, why it was necessary, and any follow-up actions.\n26 | 5. Document validation in a trailing section (e.g., `Tests:`) noting commands executed or why tests were skipped.\n27 | \n28 | ## Example Output\n29 | \n30 | ```\n31 | fix(auth): prevent session expiration loop\n32 | \n33 | - guard refresh flow against repeated 401 responses\n34 | - add regression coverage for expired refresh tokens\n35 | \n36 | Tests: npm test -- auth/session.test.ts\n37 | ```\n</code></pre></p> <p>20-implementation/impl/content-generation.impl.md <pre><code>1 | ---\n2 | phase: \"11) Evidence Log\"\n3 | gate: \"Evidence Log\"\n4 | status: \"Ensure docs stay synced with current phase deliverables.\"\n5 | previous:\n6 |   - \"Stage-specific work just completed\"\n7 | next:\n8 |   - \"/release-notes\"\n9 |   - \"/summary (if sharing updates)\"\n10 | ---\n11 | \n12 | # Content Generation\n13 | \n14 | Trigger: /content-generation\n15 | \n16 | Purpose: Draft docs, blog posts, or marketing copy aligned with the codebase.\n17 | \n18 | ## Steps\n19 | \n20 | 1. Read repo README and recent CHANGELOG or commits.\n21 | 2. Propose outlines for docs and posts.\n22 | 3. Generate content with code snippets and usage examples.\n23 | \n24 | ## Output format\n25 | \n26 | - Markdown files with frontmatter and section headings.\n27 | \n</code></pre></p> <p>20-implementation/impl/feature-flags.impl.md <pre><code>1 | ---\n2 | phase: \"P8 Post-release Hardening\"\n3 | gate: \"Post-release cleanup\"\n4 | status: \"guardrails added before toggling new flows.\"\n5 | previous:\n6 |   - \"/cleanup-branches\"\n7 | next:\n8 |   - \"/model-strengths\"\n9 |   - \"/model-evaluation\"\n10 | ---\n11 | \n12 | # Feature Flags\n13 | \n14 | Trigger: /feature-flags &lt;provider&gt;\n15 | \n16 | Purpose: Integrate a flag provider, wire the SDK, and enforce guardrails.\n17 | \n18 | **Steps:**\n19 | \n20 | 1. Select provider (LaunchDarkly, Unleash, Flagsmith, custom).\n21 | 2. Add SDK init in web/api with bootstrap values and offline mode for dev.\n22 | 3. Define flag naming and ownership. Add kill\u2011switch pattern and monitoring.\n23 | \n24 | **Output format:** SDK snippet, example usage, and guardrail checklist.\n25 | \n26 | **Examples:** `/feature-flags launchdarkly`.\n27 | \n28 | **Notes:** Ensure flags are typed and expire with tickets.\n29 | \n</code></pre></p> <p>20-implementation/impl/fix.impl.md <pre><code>1 | ---\n2 | phase: \"P8 Post-release Hardening\"\n3 | gate: \"Post-release cleanup\"\n4 | status: \"validated fix with regression coverage before closing incident.\"\n5 | previous:\n6 |   - \"/error-analysis\"\n7 | next:\n8 |   - \"/refactor-suggestions\"\n9 |   - \"/file-modularity\"\n10 | ---\n11 | \n12 | # Fix\n13 | \n14 | Trigger: /fix \"&lt;bug summary&gt;\"\n15 | \n16 | Purpose: Propose a minimal, correct fix with diff-style patches.\n17 | \n18 | You are a CLI assistant focused on helping contributors with the task: Propose a minimal, correct fix with patch hunks.\n19 | \n20 | 1. Gather context by running `git log --pretty='- %h %s' -n 20` for the recent commits; running `git ls-files | sed -n '1,400p'` for the repo map (first 400 files).\n21 | 2. Bug summary: &lt;args&gt;. Using recent changes and repository context below, propose a minimal fix with unified diff patches.\n22 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n23 | \n24 | Output:\n25 | \n26 | - Begin with a concise summary that restates the goal: Propose a minimal, correct fix with patch hunks.\n27 | - Provide unified diff-style patches when recommending code changes.\n28 | - Offer prioritized, actionable recommendations with rationale.\n29 | \n30 | Example Input:\n31 | Authentication failure after password reset\n32 | \n33 | Expected Output:\n34 | \n35 | ```\n36 | diff\n37 | - if (!user) return error;\n38 | + if (!user) return { status: 401 };\n39 | ```\n40 | \n41 | Regression test: add case for missing user.\n42 | \n</code></pre></p> <p>20-implementation/impl/generate.impl.md <pre><code>1 | ---\n2 | phase: \"P5 Quality Gates &amp; Tests\"\n3 | gate: \"Test Gate\"\n4 | status: \"targeted unit tests authored for the specified module.\"\n5 | previous:\n6 |   - \"/coverage-guide\"\n7 | next:\n8 |   - \"/regression-guard\"\n9 | ---\n10 | \n11 | # Generate Unit Tests\n12 | \n13 | Trigger: /generate &lt;source-file&gt;\n14 | \n15 | Purpose: Generate unit tests for a given source file.\n16 | \n17 | You are a CLI assistant focused on helping contributors with the task: Generate unit tests for a given source file.\n18 | \n19 | ## Steps\n20 | \n21 | 1. Inspect `package.json` to identify the unit test framework, runner scripts, and any helper utilities required for the suite.\n22 | 2. Review the target source file with `sed -n '1,400p' {{args}}` to catalog exported members, branching logic, and error handling paths that must be exercised.\n23 | 3. Outline the test file structure (location, naming, setup/teardown) and propose arrange/act/assert cases that cover happy paths, edge cases, and failure scenarios.\n24 | 4. Provide guidance on implementing the tests and how to validate them locally (e.g., `npm test -- &lt;pattern&gt;` or framework-specific commands).\n25 | \n26 | ## Output\n27 | \n28 | - Begin with a concise summary that restates the goal: Generate unit tests for a given source file.\n29 | - List the recommended test files, describe each test case, and highlight coverage gaps they close.\n30 | - Call out the command(s) to run the new tests and any fixtures or mocks required.\n31 | - Document the evidence you used (e.g., `package.json`, specific functions/branches in the source file) so maintainers can trust the conclusion.\n32 | \n33 | ## Example\n34 | \n35 | **Input**\n36 | \n37 | ```\n38 | src/components/Button.tsx\n39 | ```\n40 | \n41 | **Output**\n42 | \n43 | - Summary: Author React Testing Library unit tests for `Button` to cover rendering, disabled behavior, and click handling.\n44 | - Create `src/components/__tests__/Button.test.tsx` that:\n45 |   - Renders the button label and asserts it matches `props.children`.\n46 |   - Verifies `onClick` fires once when the button is enabled and is skipped when `disabled` is true.\n47 |   - Confirms the `variant=\"primary\"` branch applies the `btn-primary` class.\n48 | - Validation: Run `npm test -- Button.test.tsx` to execute the suite.\n49 | - Evidence: `package.json` (scripts.test uses Jest + RTL), component branches in `src/components/Button.tsx` (disabled guard, variant styling).\n</code></pre></p> <p>20-implementation/impl/prototype-feature.impl.md <pre><code>1 | ---\n2 | phase:\n3 |   - \"P1 Plan &amp; Scope\"\n4 |   - \"P2 App Scaffold &amp; Contracts\"\n5 | gate: \"Prototype review\"\n6 | status: \"Validate spike outcomes before committing to scope.\"\n7 | previous:\n8 |   - \"/planning-process\"\n9 | next:\n10 |   - \"/scaffold-fullstack\"\n11 |   - \"/api-contract\"\n12 | ---\n13 | \n14 | # Prototype Feature\n15 | \n16 | Trigger: /prototype-feature\n17 | \n18 | Purpose: Spin up a standalone prototype in a clean repo before merging into main.\n19 | \n20 | ## Steps\n21 | \n22 | 1. Create a scratch directory name suggestion and scaffolding commands.\n23 | 2. Generate minimal app with only the feature and hardcoded data.\n24 | 3. Add E2E test covering the prototype flow.\n25 | 4. When validated, list the minimal patches to port back.\n26 | \n27 | ## Output format\n28 | \n29 | - Scaffold plan and migration notes.\n30 | \n</code></pre></p> <p>20-implementation/impl/todos.impl.md <pre><code>1 | You are a CLI assistant focused on helping contributors with the task: Find and group TODO/FIXME annotations.\n2 | \n3 | 1. Gather context by running `rg -n \"TODO|FIXME\" -g '!node_modules' . || grep -RInE 'TODO|FIXME' .`.\n4 | 2. Find and group TODO/FIXME annotations.\n5 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n6 | \n7 | Output:\n8 | \n9 | - Begin with a concise summary that restates the goal: Find and group TODO/FIXME annotations.\n10 | - Document the evidence you used so maintainers can trust the conclusion.\n11 | \n12 | Example Input:\n13 | (none \u2013 command runs without arguments)\n14 | \n15 | Expected Output:\n16 | \n17 | - Group: Platform backlog \u2014 4 TODOs referencing auth migration (owner: @platform).\n</code></pre></p> <p>20-implementation/impl/voice-input.impl.md <pre><code>1 | ---\n2 | phase: \"Support\"\n3 | gate: \"Support intake\"\n4 | status: \"Clarify voice-derived requests before invoking gated prompts.\"\n5 | previous:\n6 |   - \"Voice transcript capture\"\n7 | next:\n8 |   - \"Any stage-specific command (e.g., /planning-process)\"\n9 | ---\n10 | \n11 | # Voice Input\n12 | \n13 | Trigger: /voice-input\n14 | \n15 | Purpose: Support interaction from voice capture and convert to structured prompts.\n16 | \n17 | ## Steps\n18 | \n19 | 1. Accept transcript text.\n20 | 2. Normalize to tasks or commands for other prompts.\n21 | 3. Preserve speaker intents and important entities.\n22 | \n23 | ## Output format\n24 | \n25 | - Cleaned command list ready to execute.\n26 | \n</code></pre></p> <p>40-testing/gen-tests/check.gen-tests.md <pre><code>1 | You are a CLI assistant focused on helping contributors with the task: Check adherence to .editorconfig across the repo.\n2 | \n3 | 1. Gather context by inspecting `.editorconfig`; running `git ls-files | sed -n '1,400p'`.\n4 | 2. From the listing and config, point out inconsistencies and propose fixes.\n5 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n6 | \n7 | Output:\n8 | \n9 | - Begin with a concise summary that restates the goal: Check adherence to .editorconfig across the repo.\n10 | - Offer prioritized, actionable recommendations with rationale.\n11 | - Highlight workflow triggers, failing jobs, and proposed fixes.\n12 | \n13 | Example Input:\n14 | (none \u2013 command runs without arguments)\n15 | \n16 | Expected Output:\n17 | \n18 | - Structured report following the specified sections.\n</code></pre></p> <p>40-testing/gen-tests/integration-test.gen-tests.md <pre><code>1 | ---\n2 | phase: \"P5 Quality Gates &amp; Tests\"\n3 | gate: \"Test Gate\"\n4 | status: \"happy path E2E must pass locally and in CI.\"\n5 | previous:\n6 |   - \"/e2e-runner-setup\"\n7 | next:\n8 |   - \"/coverage-guide\"\n9 |   - \"/regression-guard\"\n10 | ---\n11 | \n12 | # Integration Test\n13 | \n14 | Trigger: /integration-test\n15 | \n16 | Purpose: Generate E2E tests that simulate real user flows.\n17 | \n18 | ## Steps\n19 | \n20 | 1. Detect framework from `package.json` or repo (Playwright/Cypress/Vitest).\n21 | 2. Identify critical path scenarios from `PLAN.md`.\n22 | 3. Produce test files under `e2e/` with arrange/act/assert and selectors resilient to DOM changes.\n23 | 4. Include login helpers and data setup. Add CI commands.\n24 | \n25 | ## Output format\n26 | \n27 | - Test files with comments and a README snippet on how to run them.\n28 | \n29 | ## Examples\n30 | \n31 | - Login, navigate to dashboard, create record, assert toast.\n32 | \n33 | ## Notes\n34 | \n35 | - Prefer data-test-id attributes. Avoid brittle CSS selectors.\n36 | \n</code></pre></p> <p>40-testing/fix-flakes/error-analysis.fix-flakes.md <pre><code>1 | ---\n2 | phase: \"P8 Post-release Hardening\"\n3 | gate: \"Post-release cleanup\"\n4 | status: \"Sev-1 incidents triaged with fixes scheduled.\"\n5 | previous:\n6 |   - \"/logging-strategy\"\n7 |   - \"/audit\"\n8 | next:\n9 |   - \"/fix\"\n10 |   - \"/refactor-suggestions\"\n11 | ---\n12 | \n13 | # Error Analysis\n14 | \n15 | Trigger: /error-analysis\n16 | \n17 | Purpose: Analyze error logs and enumerate likely root causes with fixes.\n18 | \n19 | ## Steps\n20 | \n21 | 1. Collect last test logs or application stack traces if present.\n22 | 2. Cluster errors by symptom. For each cluster list 2\u20133 plausible causes.\n23 | 3. Propose instrumentation or inputs to disambiguate.\n24 | 4. Provide minimal patch suggestions and validation steps.\n25 | \n26 | ## Output format\n27 | \n28 | - Table: error \u2192 likely causes \u2192 next checks \u2192 candidate fix.\n29 | \n30 | ## Examples\n31 | \n32 | - \"TypeError: x is not a function\" \u2192 wrong import, circular dep, stale build.\n33 | \n</code></pre></p> <p>40-testing/fix-flakes/explain-failures.fix-flakes.md <pre><code>1 | You are a CLI assistant focused on helping contributors with the task: Analyze recent test failures and propose fixes.\n2 | \n3 | 1. Gather context by running `ls -1 test-results 2&gt;/dev/null || echo 'no test-results/ directory'` for the recent test output (if present); running `find . -maxdepth 2 -name 'junit*.xml' -o -name 'TEST-*.xml' -o -name 'last-test.log' -print -exec tail -n 200 {} \\; 2&gt;/dev/null` for the recent test output (if present).\n4 | 2. From the following logs, identify root causes and propose concrete fixes.\n5 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n6 | \n7 | Output:\n8 | \n9 | - Begin with a concise summary that restates the goal: Analyze recent test failures and propose fixes.\n10 | - Offer prioritized, actionable recommendations with rationale.\n11 | - Document the evidence you used so maintainers can trust the conclusion.\n12 | \n13 | Example Input:\n14 | (none \u2013 command runs without arguments)\n15 | \n16 | Expected Output:\n17 | \n18 | - Structured report following the specified sections.\n</code></pre></p> <p>40-testing/test-plan/e2e-runner-setup.test-plan.md <pre><code>1 | ---\n2 | phase: \"P5 Quality Gates &amp; Tests\"\n3 | gate: \"Test Gate\"\n4 | status: \"runner green locally and wired into CI before expanding coverage.\"\n5 | previous:\n6 |   - \"/auth-scaffold\"\n7 |   - \"/ui-screenshots\"\n8 | next:\n9 |   - \"/integration-test\"\n10 |   - \"/coverage-guide\"\n11 | ---\n12 | \n13 | # E2E Runner Setup\n14 | \n15 | Trigger: /e2e-runner-setup &lt;playwright|cypress&gt;\n16 | \n17 | Purpose: Configure an end-to-end test runner with fixtures and a data sandbox.\n18 | \n19 | **Steps:**\n20 | \n21 | 1. Install runner and add config with baseURL, retries, trace/videos on retry only.\n22 | 2. Create fixtures for auth, db reset, and network stubs. Add `test:serve` script.\n23 | 3. Provide CI job that boots services, runs E2E, uploads artifacts.\n24 | \n25 | **Output format:** file list, scripts, and CI snippet fenced code block.\n26 | \n27 | **Examples:** `/e2e-runner-setup playwright`.\n28 | \n29 | **Notes:** Keep runs under 10 minutes locally; parallelize spec files.\n30 | \n</code></pre></p> <p>40-testing/test-plan/query-set.test-plan.md <pre><code>1 | # High-Yield Query Generator\n2 | \n3 | Trigger: /query-set\n4 | \n5 | Purpose: Generate 4\u20138 targeted web search queries with operators, entity variants, and recency filters for a given objective.\n6 | \n7 | Steps:\n8 | \n9 | 1. Restate the goal with entities and time window.\n10 | 2. Produce queries using operators: site:, filetype:, inurl:, quotes, OR, date filters.\n11 | 3. Include synonyms and common misspellings.\n12 | 4. Mix intents: define, compare, integrate, configure, limitations, pricing, API, case study.\n13 | \n14 | Output format:\n15 | \n16 | ```\n17 | ### Goal\n18 | {1 sentence}\n19 | \n20 | ### Query Set\n21 | - {Q1}\n22 | - {Q2}\n23 | - \u2026 up to 8\n24 | ```\n25 | \n26 | Examples:\n27 | \n28 | - Input: `/query-set \"OpenAI Responses API streaming server-sent events\" past year`\n29 | - Output: Goal + 6\u20138 queries with operators.\n30 | \n31 | Notes:\n32 | \n33 | - No evidence logging here. Use /research-item to execute.\n</code></pre></p> <p>30-refactor/refactor/adr-new.refactor.md <pre><code>1 | **{$2 or Inferred Name}**\n2 | \n3 | You are a CLI assistant to draft an Architecture Decision Record with pros/cons using the following inputs:\n4 | \n5 | 1. Analyze project context from $1.\n6 | 2. Generate a concise ADR with Context, Decision, Status, Consequences. Title: $3.\n7 | 3. Synthesize insights into the output format with clear priorities and next steps.\n8 | \n9 | **Output Requirements**:\n10 | - Provide a summary restating the goal.\n11 | - Highlight $4, $5, and $6.\n12 | - Document $7 to ensure maintainability.\n13 | \n14 | **Example Input**: $2\n15 | \n16 | **Expected Output**: Actionable summary aligned with output requirements.\n</code></pre></p> <p>30-refactor/refactor/file-modularity.refactor.md <pre><code>1 | ---\n2 | phase: \"P8 Post-release Hardening\"\n3 | gate: \"Post-release cleanup\"\n4 | status: \"structure debt addressed without destabilizing prod.\"\n5 | previous:\n6 |   - \"/refactor-suggestions\"\n7 | next:\n8 |   - \"/dead-code-scan\"\n9 |   - \"/cleanup-branches\"\n10 | ---\n11 | \n12 | # File Modularity\n13 | \n14 | Trigger: /file-modularity\n15 | \n16 | Purpose: Enforce smaller files and propose safe splits for giant files.\n17 | \n18 | ## Steps\n19 | \n20 | 1. Find files over thresholds (e.g., &gt;500 lines).\n21 | 2. Suggest extraction targets: components, hooks, utilities, schemas.\n22 | 3. Provide before/after examples and import updates.\n23 | \n24 | ## Output format\n25 | \n26 | - Refactor plan with patches for file splits.\n27 | \n</code></pre></p> <p>30-refactor/refactor/prettier-adopt-migration-report.refactor.md <pre><code>1 | You are a CLI assistant focused on helping contributors with the task: Plan a Prettier adoption or migration with minimal churn.\n2 | \n3 | 1. Gather context by inspecting `package.json`; running `git ls-files '*.*' | sed -n '1,400p'`.\n4 | 2. Given the files and package.json, propose a rollout plan and ignore patterns.\n5 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n6 | \n7 | Output:\n8 | \n9 | - Begin with a concise summary that restates the goal: Plan a Prettier adoption or migration with minimal churn.\n10 | - Offer prioritized, actionable recommendations with rationale.\n11 | - Document the evidence you used so maintainers can trust the conclusion.\n12 | \n13 | Example Input:\n14 | (none \u2013 command runs without arguments)\n15 | \n16 | Expected Output:\n17 | \n18 | - Structured report following the specified sections.\n</code></pre></p> <p>30-refactor/refactor/refactor-file.refactor.md <pre><code>1 | You are a CLI assistant focused on helping contributors with the task: Suggest targeted refactors for a single file.\n2 | \n3 | 1. Gather context by running `sed -n '1,400p' {{args}}` for the first 400 lines of the file.\n4 | 2. Suggest refactors that reduce complexity and improve readability without changing behavior. Provide before/after snippets.\n5 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n6 | \n7 | Output:\n8 | \n9 | - Begin with a concise summary that restates the goal: Suggest targeted refactors for a single file.\n10 | - Include before/after snippets or diffs with commentary.\n11 | - Document the evidence you used so maintainers can trust the conclusion.\n12 | \n13 | Example Input:\n14 | src/components/Button.tsx\n15 | \n16 | Expected Output:\n17 | \n18 | - Refactor proposal extracting shared styling hook with before/after snippet.\n</code></pre></p> <p>30-refactor/refactor-candidates/dead-code-scan.refactor-candidates.md <pre><code>1 | ---\n2 | phase: \"P8 Post-release Hardening\"\n3 | gate: \"Post-release cleanup\"\n4 | status: \"ensure code removals keep prod stable.\"\n5 | previous:\n6 |   - \"/file-modularity\"\n7 | next:\n8 |   - \"/cleanup-branches\"\n9 |   - \"/feature-flags\"\n10 | ---\n11 | \n12 | # Dead Code Scan\n13 | \n14 | Trigger: /dead-code-scan\n15 | \n16 | Purpose: Identify likely dead or unused files and exports using static signals.\n17 | \n18 | You are a CLI assistant focused on helping contributors with the task: List likely dead or unused files and exports (static signals).\n19 | \n20 | 1. Gather context by running `rg -n \"export |module.exports|exports\\.|require\\(|import \" -g '!node_modules' .` for the file reference graph (best\u2011effort).\n21 | 2. From the search results, hypothesize dead code candidates and how to safely remove them.\n22 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n23 | \n24 | Output:\n25 | \n26 | - Begin with a concise summary that restates the goal: List likely dead or unused files and exports (static signals).\n27 | - Document the evidence you used so maintainers can trust the conclusion.\n28 | \n29 | Example Input:\n30 | (none \u2013 command runs without arguments)\n31 | \n32 | Expected Output:\n33 | \n34 | - Structured report following the specified sections.\n35 | \n</code></pre></p> <p>30-refactor/refactor-candidates/migration-plan.refactor-candidates.md <pre><code>1 | ---\n2 | phase: \"P3 Data &amp; Auth\"\n3 | gate: \"Migration dry-run\"\n4 | status: \"validated rollback steps and safety checks documented.\"\n5 | previous:\n6 |   - \"/db-bootstrap\"\n7 | next:\n8 |   - \"/auth-scaffold\"\n9 |   - \"/e2e-runner-setup\"\n10 | ---\n11 | \n12 | # Migration Plan\n13 | \n14 | Trigger: /migration-plan \"&lt;change summary&gt;\"\n15 | \n16 | Purpose: Produce safe up/down migration steps with checks and rollback notes.\n17 | \n18 | **Steps:**\n19 | \n20 | 1. Describe current vs target schema, include data volume and lock risk.\n21 | 2. Plan: deploy empty columns, backfill, dual-write, cutover, cleanup.\n22 | 3. Provide SQL snippets and PR checklist. Add `can_rollback: true|false` flag.\n23 | \n24 | **Output format:** `Plan`, `SQL`, `Rollback`, `Checks` sections.\n25 | \n26 | **Examples:** `/migration-plan \"orders add status enum\"`.\n27 | \n28 | **Notes:** Include online migration strategies for large tables.\n29 | \n</code></pre></p> <p>30-refactor/refactor-candidates/refactor-suggestions.refactor-candidates.md <pre><code>1 | ---\n2 | phase: \"P8 Post-release Hardening\"\n3 | gate: \"Post-release cleanup\"\n4 | status: \"plan high-leverage refactors once Sev-1 issues settle.\"\n5 | previous:\n6 |   - \"/fix\"\n7 | next:\n8 |   - \"/file-modularity\"\n9 |   - \"/dead-code-scan\"\n10 | ---\n11 | \n12 | # Refactor Suggestions\n13 | \n14 | Trigger: /refactor-suggestions\n15 | \n16 | Purpose: Propose repo-wide refactoring opportunities after tests exist.\n17 | \n18 | ## Steps\n19 | \n20 | 1. Map directory structure and large files.\n21 | 2. Identify duplication, data clumps, and god objects.\n22 | 3. Suggest phased refactors with safety checks and tests.\n23 | \n24 | ## Output format\n25 | \n26 | - Ranked list with owners and effort estimates.\n27 | \n</code></pre></p> <p>30-refactor/perf/compare-outputs.perf.md <pre><code>1 | ---\n2 | phase: \"P9 Model Tactics\"\n3 | gate: \"Model uplift\"\n4 | status: \"comparative data compiled before switching defaults.\"\n5 | previous:\n6 |   - \"/model-evaluation\"\n7 | next:\n8 |   - \"/switch-model\"\n9 | ---\n10 | \n11 | # Compare Outputs\n12 | \n13 | Trigger: /compare-outputs\n14 | \n15 | Purpose: Run multiple models or tools on the same prompt and summarize best output.\n16 | \n17 | ## Steps\n18 | \n19 | 1. Define evaluation prompts and expected properties.\n20 | 2. Record outputs from each model/tool with metadata.\n21 | 3. Score using a rubric: correctness, compile/run success, edits required.\n22 | 4. Recommend a winner and suggested settings.\n23 | \n24 | ## Output format\n25 | \n26 | - Matrix comparison and a one-paragraph decision.\n27 | \n</code></pre></p> <p>30-refactor/perf/model-evaluation.perf.md <pre><code>1 | ---\n2 | phase: \"P9 Model Tactics\"\n3 | gate: \"Model uplift\"\n4 | status: \"experiments must beat baseline quality metrics.\"\n5 | previous:\n6 |   - \"/model-strengths\"\n7 | next:\n8 |   - \"/compare-outputs\"\n9 |   - \"/switch-model\"\n10 | ---\n11 | \n12 | # Model Evaluation\n13 | \n14 | Trigger: /model-evaluation\n15 | \n16 | Purpose: Try a new model and compare outputs against a baseline.\n17 | \n18 | ## Steps\n19 | \n20 | 1. Define a benchmark set from recent tasks.\n21 | 2. Run candidates and collect outputs and metrics.\n22 | 3. Analyze failures and summarize where each model excels.\n23 | \n24 | ## Output format\n25 | \n26 | - Summary table and recommendations to adopt or not.\n27 | \n</code></pre></p> <p>30-refactor/perf/model-strengths.perf.md <pre><code>1 | ---\n2 | phase: \"P9 Model Tactics\"\n3 | gate: \"Model uplift\"\n4 | status: \"capture baseline routing before experimentation.\"\n5 | previous:\n6 |   - \"/feature-flags (optional)\"\n7 |   - \"Stage-specific blockers\"\n8 | next:\n9 |   - \"/model-evaluation\"\n10 |   - \"/compare-outputs\"\n11 | ---\n12 | \n13 | # Model Strengths\n14 | \n15 | Trigger: /model-strengths\n16 | \n17 | Purpose: Choose model per task type.\n18 | \n19 | ## Steps\n20 | \n21 | 1. Classify task: UI, API, data, testing, docs, refactor.\n22 | 2. Map historical success by model.\n23 | 3. Recommend routing rules and temperatures.\n24 | \n25 | ## Output format\n26 | \n27 | - Routing guide with examples.\n28 | \n</code></pre></p> <p>50-docs/api-docs/api-docs-local.api-docs.md <pre><code>1 | ---\n2 | phase: \"P2 App Scaffold &amp; Contracts\"\n3 | gate: \"Test Gate lite\"\n4 | status: \"contracts cached locally for repeatable generation.\"\n5 | previous:\n6 |   - \"/scaffold-fullstack\"\n7 | next:\n8 |   - \"/api-contract\"\n9 |   - \"/openapi-generate\"\n10 | ---\n11 | \n12 | # API Docs Local\n13 | \n14 | Trigger: /api-docs-local\n15 | \n16 | Purpose: Fetch API docs and store locally for offline, deterministic reference.\n17 | \n18 | ## Steps\n19 | \n20 | 1. Create `docs/apis/` directory.\n21 | 2. For each provided URL or package, write retrieval commands (curl or `npm view` docs links). Do not fetch automatically without confirmation.\n22 | 3. Add `DOCS.md` index linking local copies.\n23 | \n24 | ## Output format\n25 | \n26 | - Command list and file paths to place docs under `docs/apis/`.\n27 | \n</code></pre></p> <p>50-docs/api-docs/openapi-generate.api-docs.md <pre><code>1 | ---\n2 | phase: \"P2 App Scaffold &amp; Contracts\"\n3 | gate: \"Test Gate lite\"\n4 | status: \"generated code builds and CI checks cover the new scripts.\"\n5 | previous:\n6 |   - \"/api-contract\"\n7 | next:\n8 |   - \"/modular-architecture\"\n9 |   - \"/db-bootstrap\"\n10 | ---\n11 | \n12 | # OpenAPI Generate\n13 | \n14 | Trigger: /openapi-generate &lt;server|client&gt; &lt;lang&gt; &lt;spec-path&gt;\n15 | \n16 | Purpose: Generate server stubs or typed clients from an OpenAPI spec.\n17 | \n18 | **Steps:**\n19 | \n20 | 1. Validate `&lt;spec-path&gt;`; fail with actionable errors.\n21 | 2. For `server`, generate controllers, routers, validation, and error middleware into `apps/api`.\n22 | 3. For `client`, generate a typed SDK into `packages/sdk` with fetch wrapper and retry/backoff.\n23 | 4. Add `make generate-api` or `pnpm sdk:gen` scripts and CI step to verify no drift.\n24 | 5. Produce a diff summary and TODO list for unimplemented handlers.\n25 | \n26 | **Output format:** summary table of generated paths, scripts to add, and next actions.\n27 | \n28 | **Examples:** `/openapi-generate client ts apis/auth/openapi.yaml`.\n29 | \n30 | **Notes:** Prefer openapi-typescript + zod for TS clients when possible.\n31 | \n</code></pre></p> <p>50-docs/doc-plan/gemini-map.doc-plan.md <pre><code>1 | name: Gemini\u2192Codex Mapper\n2 | command: /gemini-map\n3 | tags: migration, prompts, tooling\n4 | scope: toml-to-codex\n5 | \n6 | You are a translator that converts a Gemini CLI TOML command into a Codex prompt file.\n7 | \n8 | Steps:\n9 | \n10 | 1) Read TOML with `description` and `prompt`.\n11 | 2) Extract the task, inputs, and outputs implied by the TOML.\n12 | 3) Write a Codex prompt file \u2264 300 words:\n13 | \n14 |     - Role line `You are ...`\n15 |     - Numbered steps\n16 |     - Output section\n17 |     - Example input and expected output\n18 |     - `Usage: /&lt;command&gt;` line\n19 |     - YAML-like metadata at top\n20 | \n21 | 4) Choose a short, hyphenated filename \u2264 32 chars.\n22 | 5) Emit a ready-to-run bash snippet:\n23 | `cat &gt; ~/.codex/prompts/&lt;filename&gt;.md &lt;&lt; 'EOF'` \u2026 `EOF`.\n24 | 6) Do not include destructive commands or secrets.\n25 | \n26 | Example input:\n27 | \n28 | ```toml\n29 | description = \"Draft a PR description\"\n30 | prompt = \"Create sections Summary, Context, Changes from diff stats\"\n31 | Expected output:\n32 | \n33 | A pr-desc.md file with the structure above and a bash cat &gt; block.\n34 | \n35 | Usage: /gemini-map\n</code></pre></p> <p>50-docs/doc-plan/owners.doc-plan.md <pre><code>1 | ---\n2 | phase: \"P7 Release &amp; Ops\"\n3 | gate: \"Review Gate\"\n4 | status: \"confirm approvers and escalation paths before PR submission.\"\n5 | previous:\n6 |   - \"/iac-bootstrap\"\n7 | next:\n8 |   - \"/review\"\n9 |   - \"/review-branch\"\n10 |   - \"/pr-desc\"\n11 | ---\n12 | \n13 | # Owners\n14 | \n15 | Trigger: /owners &lt;path&gt;\n16 | \n17 | Purpose: Suggest likely owners or reviewers for the specified path.\n18 | \n19 | You are a CLI assistant focused on helping contributors with the task: Suggest likely owners/reviewers for a path.\n20 | \n21 | 1. Gather context by inspecting `.github/CODEOWNERS` for the codeowners (if present); running `git log --pretty='- %an %ae: %s' -- {{args}} | sed -n '1,50p'` for the recent authors for the path.\n22 | 2. Based on CODEOWNERS and git history, suggest owners.\n23 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n24 | \n25 | Output:\n26 | \n27 | - Begin with a concise summary that restates the goal: Suggest likely owners/reviewers for a path.\n28 | - Reference evidence from CODEOWNERS or git history for each owner suggestion.\n29 | - Document the evidence you used so maintainers can trust the conclusion.\n30 | \n31 | Example Input:\n32 | src/components/Button.tsx\n33 | \n34 | Expected Output:\n35 | \n36 | - Likely reviewers: @frontend-team (CODEOWNERS), @jane (last 5 commits).\n37 | \n</code></pre></p> <p>50-docs/examples/api-usage.examples.md <pre><code>1 | You are a CLI assistant focused on helping contributors with the task: Show how an internal API is used across the codebase.\n2 | \n3 | 1. Gather context by running `rg -n {{args}} . || grep -RIn {{args}} .`.\n4 | 2. Summarize common usage patterns and potential misuses for the symbol.\n5 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n6 | \n7 | Output:\n8 | \n9 | - Begin with a concise summary that restates the goal: Show how an internal API is used across the codebase.\n10 | - Organize details under clear subheadings so contributors can scan quickly.\n11 | - Document the evidence you used so maintainers can trust the conclusion.\n12 | \n13 | Example Input:\n14 | HttpClient\n15 | \n16 | Expected Output:\n17 | \n18 | - Definition: src/network/httpClient.ts line 42\n19 | - Key usages: services/userService.ts, hooks/useRequest.ts\n</code></pre></p> <p>50-docs/examples/reference-implementation.examples.md <pre><code>1 | ---\n2 | phase: \"P2 App Scaffold &amp; Contracts\"\n3 | gate: \"Test Gate lite\"\n4 | status: \"align new modules with proven patterns before deeper work.\"\n5 | previous:\n6 |   - \"/scaffold-fullstack\"\n7 |   - \"/api-contract\"\n8 | next:\n9 |   - \"/modular-architecture\"\n10 |   - \"/openapi-generate\"\n11 | ---\n12 | \n13 | # Reference Implementation\n14 | \n15 | Trigger: /reference-implementation\n16 | \n17 | Purpose: Mimic the style and API of a known working example.\n18 | \n19 | ## Steps\n20 | \n21 | 1. Accept a path or URL to an example. Extract its public API and patterns.\n22 | 2. Map target module\u2019s API to the reference.\n23 | 3. Generate diffs that adopt the same structure and naming.\n24 | \n25 | ## Output format\n26 | \n27 | - Side-by-side API table and patch suggestions.\n28 | \n</code></pre></p> <p>60-release/post-release-checks/cleanup-branches.post-release-checks.md <pre><code>1 | ---\n2 | phase: \"P8 Post-release Hardening\"\n3 | gate: \"Post-release cleanup\"\n4 | status: \"repo tidy with stale branches archived.\"\n5 | previous:\n6 |   - \"/dead-code-scan\"\n7 | next:\n8 |   - \"/feature-flags\"\n9 |   - \"/model-strengths\"\n10 | ---\n11 | \n12 | # Cleanup Branches\n13 | \n14 | Trigger: /cleanup-branches\n15 | \n16 | Purpose: Recommend which local branches are safe to delete and which to keep.\n17 | \n18 | You are a CLI assistant focused on helping contributors with the task: Suggest safe local branch cleanup (merged/stale).\n19 | \n20 | 1. Gather context by running `git branch --merged` for the merged into current upstream; running `git branch --no-merged` for the branches not merged; running `git for-each-ref --sort=-authordate --format='%(refname:short) \u2014 %(authordate:relative)' refs/heads` for the recently updated (last author dates).\n21 | 2. Using the lists below, suggest local branches safe to delete and which to keep. Include commands to remove them if desired (DO NOT execute).\n22 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n23 | \n24 | Output:\n25 | \n26 | - Begin with a concise summary that restates the goal: Suggest safe local branch cleanup (merged/stale).\n27 | - Document the evidence you used so maintainers can trust the conclusion.\n28 | \n29 | Example Input:\n30 | (none \u2013 command runs without arguments)\n31 | \n32 | Expected Output:\n33 | \n34 | - Structured report following the specified sections.\n35 | \n</code></pre></p> <p>60-release/versioning/version-proposal.versioning.md <pre><code>1 | ---\n2 | phase: \"P7 Release &amp; Ops\"\n3 | gate: \"Release Gate\"\n4 | status: \"version bump decision recorded before deployment.\"\n5 | previous:\n6 |   - \"/release-notes\"\n7 | next:\n8 |   - \"/monitoring-setup\"\n9 |   - \"/slo-setup\"\n10 | ---\n11 | \n12 | # Version Proposal\n13 | \n14 | Trigger: /version-proposal\n15 | \n16 | Purpose: Propose the next semantic version based on commit history.\n17 | \n18 | You are a CLI assistant focused on helping contributors with the task: Propose next version (major/minor/patch) from commit history.\n19 | \n20 | 1. Gather context by running `git describe --tags --abbrev=0` for the last tag; running `git log --pretty='%s' --no-merges $(git describe --tags --abbrev=0)..HEAD` for the commits since last tag (no merges).\n21 | 2. Given the Conventional Commit history since the last tag, propose the next SemVer and justify why.\n22 | 3. Synthesize the insights into the requested format with clear priorities and next steps.\n23 | \n24 | Output:\n25 | \n26 | - Begin with a concise summary that restates the goal: Propose next version (major/minor/patch) from commit history.\n27 | - Offer prioritized, actionable recommendations with rationale.\n28 | - Document the evidence you used so maintainers can trust the conclusion.\n29 | \n30 | Example Input:\n31 | (none \u2013 command runs without arguments)\n32 | \n33 | Expected Output:\n34 | \n35 | - Structured report following the specified sections.\n36 | \n</code></pre></p> <p>_shared/tm/advance.tm.md <pre><code>1 | # Advance Task(s)\n2 | \n3 | Trigger: /tm-advance\n4 | \n5 | Purpose: For given task id(s), produce a concrete work plan, acceptance criteria, tests, and a Conventional Commits message to move status toward done.\n6 | \n7 | Steps:\n8 | \n9 | 1. Read tasks.json; resolve each provided id. If none provided, pick the top item from /tm-next.\n10 | 2. For each task: restate title, goals, and related dependencies.\n11 | 3. Draft a step-by-step plan with file touch-points and test hooks.\n12 | 4. Provide a minimal commit plan and a Conventional Commits message with scope and short body.\n13 | 5. List measurable acceptance criteria.\n14 | \n15 | Output format:\n16 | \n17 | - One section per task: \"## &lt;id&gt; \u2014 &lt;title&gt;\"\n18 | - Subsections: Plan, Files, Tests, Acceptance, Commit Message (fenced), Risks.\n19 | \n20 | Examples:\n21 | \n22 | - Input: /tm-advance TM-42 TM-43\n23 | - Output: structured sections with a commit message like `feat(parser): implement rule X`.\n24 | \n25 | Notes:\n26 | \n27 | - Do not mutate tasks.json. Emit proposed changes only.\n</code></pre></p> <p>_shared/tm/blockers.tm.md <pre><code>1 | # Blocker Diagnosis\n2 | \n3 | Trigger: /tm-blockers\n4 | \n5 | Purpose: Diagnose why a task is blocked and propose the shortest path to unblock it.\n6 | \n7 | Steps:\n8 | \n9 | 1. Load tasks.json and the target id.\n10 | 2. Enumerate unmet dependencies and missing artifacts (tests, docs, approvals).\n11 | 3. Classify each blocker: dependency, ambiguity, environment, CI, external.\n12 | 4. Propose 1\u20133 minimal unblocking actions, each with owner, effort, and success check.\n13 | \n14 | Output format:\n15 | \n16 | - \"# Blocker Report: &lt;id&gt;\"\n17 | - Tables: blockers (type | item | evidence), actions (step | owner | effort | success_criteria).\n18 | \n19 | Examples:\n20 | \n21 | - Input: /tm-blockers TM-17\n22 | - Output: two tables and a short narrative under \"Findings\".\n23 | \n24 | Notes:\n25 | \n26 | - If the task is not actually blocked, state why and redirect to /tm-advance.\n</code></pre></p> <p>_shared/tm/ci.tm.md <pre><code>1 | # CI/Test Checklist from Tasks\n2 | \n3 | Trigger: /tm-ci\n4 | \n5 | Purpose: Derive a near-term CI and test checklist from ready and in-progress tasks.\n6 | \n7 | Steps:\n8 | \n9 | 1. Compute ready tasks (see /tm-next) and collect any testStrategy fields.\n10 | 2. Group by component or tag if available; otherwise by path keywords in titles.\n11 | 3. Propose CI jobs and test commands with approximate runtimes and gating rules.\n12 | 4. Include a smoke-test matrix and minimal code coverage targets if relevant.\n13 | \n14 | Output format:\n15 | \n16 | - \"# CI Plan\"\n17 | - Tables: jobs (name | trigger | commands | est_time) and tests (scope | command | expected_artifacts).\n18 | - \"## Risk Areas\" bullets and \"## Follow-ups\".\n19 | \n20 | Examples:\n21 | \n22 | - Input: /tm-ci\n23 | - Output: one CI plan with 3\u20138 jobs and a test table.\n24 | \n25 | Notes:\n26 | \n27 | - Non-binding guidance. Adapt to the repo\u2019s actual CI system.\n</code></pre></p> <p>_shared/tm/delta.tm.md <pre><code>1 | # PRD \u2192 Tasks Delta\n2 | \n3 | Trigger: /tm-delta\n4 | \n5 | Purpose: Compare a PRD text against tasks.json and propose add/update/remove operations.\n6 | \n7 | Steps:\n8 | \n9 | 1. Accept PRD content pasted by the user or a path like ./prd.txt. If absent, output a short template asking for PRD input.\n10 | 2. Extract objectives, constraints, deliverables, and milestones from the PRD.\n11 | 3. Map them to existing tasks by fuzzy match on title and keywords; detect gaps.\n12 | 4. Propose: new tasks, updates to titles/descriptions/priority, and deprecations.\n13 | \n14 | Output format:\n15 | \n16 | - \"# Delta Summary\"\n17 | - Tables: adds | updates | removals.\n18 | - \"## JSON Patch\" with an ordered list of operations: add/replace/remove.\n19 | - \"## Assumptions\" and \"## Open Questions\".\n20 | \n21 | Examples:\n22 | \n23 | - Input: /tm-delta ./prd.txt\n24 | - Output: tables with a small JSON Patch block.\n25 | \n26 | Notes:\n27 | \n28 | - Keep patches minimal and reversible. Flag any destructive changes explicitly.\n</code></pre></p> <p>_shared/tm/docs.tm.md <pre><code>1 | # Generate Status Docs\n2 | \n3 | Trigger: /tm-docs\n4 | \n5 | Purpose: Emit a project status document from tasks.json for README or STATUS.md.\n6 | \n7 | Steps:\n8 | \n9 | 1. Parse tasks.json; collect done, in_progress, blocked, and ready_next (per /tm-next logic).\n10 | 2. Compose a concise narrative: current focus, recent wins, top risks.\n11 | 3. Produce status boards for each status with id, title, and owner if present.\n12 | 4. Add a 7-day changelog if timestamps exist; otherwise, summarize recent done items.\n13 | \n14 | Output format:\n15 | \n16 | - \"# Project Status \u2014 &lt;date&gt;\"\n17 | - Sections: Summary, Ready Next, In Progress, Blocked, Done, Changelog.\n18 | \n19 | Examples:\n20 | \n21 | - Input: /tm-docs\n22 | - Output: a single Markdown document suitable for commit as STATUS.md.\n23 | \n24 | Notes:\n25 | \n26 | - Avoid leaking secrets. Do not invent owners; omit unknown fields.\n</code></pre></p> <p>_shared/tm/next.tm.md <pre><code>1 | # Next Ready Tasks\n2 | \n3 | Trigger: /tm-next\n4 | \n5 | Purpose: List tasks that are ready to start now (no unmet dependencies), ordered by priority and dependency depth.\n6 | \n7 | Steps:\n8 | \n9 | 1. Load tasks.json and build a map of id \u2192 task.\n10 | 2. A task is ready if status \u2208 {pending, blocked} AND all dependencies are done.\n11 | 3. Order by: priority desc, then shortest path length to completion, then title.\n12 | 4. For each ready task, include why it is ready and the prerequisites satisfied.\n13 | \n14 | Output format:\n15 | \n16 | - \"# Ready Now\"\n17 | - Table: id | title | priority | why_ready | prereqs\n18 | - \"## Notes\" for tie-break rules and data gaps.\n19 | \n20 | Examples:\n21 | \n22 | - Input: /tm-next\n23 | - Output: a table of 5\u201320 items. If none, say \"No ready tasks\" and list nearest-unblock candidates.\n24 | \n25 | Notes:\n26 | \n27 | - Treat missing or null priority as 0. If custom scales exist, describe them in Notes.\n</code></pre></p> <p>_shared/tm/overview.tm.md <pre><code>1 | # TaskMaster Overview\n2 | \n3 | Trigger: /tm-overview\n4 | \n5 | Purpose: Summarize the current TaskMaster tasks.json by status, priority, dependency health, and critical path to orient work.\n6 | \n7 | Steps:\n8 | \n9 | 1. Locate the active tasks.json at repo root or the path supplied in the user message. Do not modify it.\n10 | 2. Parse fields: id, title, description, status, priority, dependencies, subtasks.\n11 | 3. Compute counts per status and a table of top pending items by priority.\n12 | 4. Detect dependency issues: cycles, missing ids, orphans (no deps and not depended on).\n13 | 5. Approximate a critical path: longest dependency chain among pending\u2192in_progress tasks.\n14 | \n15 | Output format:\n16 | \n17 | - \"# Overview\" then a bullets summary.\n18 | - \"## Totals\" as a 4-column table: status | count | percent | notes.\n19 | - \"## Top Pending\" table: id | title | priority | unblockers.\n20 | - \"## Critical Path\" as an ordered list of ids with short titles.\n21 | - \"## Issues\" list for cycles, missing references, duplicates.\n22 | \n23 | Examples:\n24 | \n25 | - Input (Codex TUI): /tm-overview\n26 | - Output: tables and lists as specified. Keep to &lt;= 200 lines.\n27 | \n28 | Notes:\n29 | \n30 | - Read-only. Assume statuses: pending | in_progress | blocked | done.\n31 | - If tasks.json is missing or invalid, output an \"## Errors\" section with a concise diagnosis.\n</code></pre></p> <p>_shared/tm/refine.tm.md <pre><code>1 | # Refine Task into Subtasks\n2 | \n3 | Trigger: /tm-refine\n4 | \n5 | Purpose: Expand a vague or large task into actionable subtasks with clear acceptance criteria.\n6 | \n7 | Steps:\n8 | \n9 | 1. Load the task by id and analyze description for ambiguity and scope.\n10 | 2. Propose 3\u20138 subtasks with titles, brief descriptions, and dependencies between them.\n11 | 3. Define acceptance criteria per subtask using Given/When/Then or bullet checks.\n12 | 4. Suggest test coverage and doc updates triggered by completion.\n13 | \n14 | Output format:\n15 | \n16 | - \"# Refinement: &lt;id&gt;\"\n17 | - Subtasks as a Markdown table: id_suggested | title | depends_on | acceptance.\n18 | - \"## JSON Patch\" fenced code of suggested additions suitable for tasks.json editing.\n19 | \n20 | Examples:\n21 | \n22 | - Input: /tm-refine TM-09\n23 | - Output: table plus a minimal JSON Patch array.\n24 | \n25 | Notes:\n26 | \n27 | - Do not assume authority to change files; provide patches the user can apply.\n</code></pre></p>"},{"location":"temp-prompts-organized/00-ideation/architecture/adr-new.architecture/","title":"ADR \u2013 new","text":"<p>You are a CLI assistant focused on helping contributors with the task: Draft an Architecture Decision Record with pros/cons.</p> <ol> <li>Gather context by inspecting <code>README.md</code> for the project context.</li> <li>Draft a concise ADR including Context, Decision, Status, Consequences. Title: . <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Draft an Architecture Decision Record with pros/cons.</li> <li>Highlight workflow triggers, failing jobs, and proposed fixes.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: src/example.ts</p> <p>Expected Output:</p> <ul> <li>Actionable summary aligned with the output section.</li> </ul>"},{"location":"temp-prompts-organized/00-ideation/architecture/logging-strategy.architecture/","title":"Logging strategy","text":"<ul> <li>\"/monitoring-setup\"</li> <li>\"/slo-setup\" next:</li> <li>\"/audit\"</li> <li>\"/error-analysis\"</li> </ul>"},{"location":"temp-prompts-organized/00-ideation/architecture/logging-strategy.architecture/#logging-strategy","title":"Logging Strategy","text":"<p>Trigger: /logging-strategy</p> <p>Purpose: Add or remove diagnostic logging cleanly with levels and privacy in mind.</p>"},{"location":"temp-prompts-organized/00-ideation/architecture/logging-strategy.architecture/#steps","title":"Steps","text":"<ol> <li>Identify hotspots from recent failures.</li> <li>Insert structured logs with contexts and correlation IDs.</li> <li>Remove noisy or PII-leaking logs.</li> <li>Document log levels and sampling in <code>OBSERVABILITY.md</code>.</li> </ol>"},{"location":"temp-prompts-organized/00-ideation/architecture/logging-strategy.architecture/#output-format","title":"Output format","text":"<ul> <li>Diff hunks and a short guideline section.</li> </ul>"},{"location":"temp-prompts-organized/00-ideation/architecture/modular-architecture.architecture/","title":"Modular architecture","text":"<ul> <li>\"/openapi-generate\" next:</li> <li>\"/db-bootstrap\"</li> <li>\"/ui-screenshots\"</li> <li>\"/design-assets\"</li> </ul>"},{"location":"temp-prompts-organized/00-ideation/architecture/modular-architecture.architecture/#modular-architecture","title":"Modular Architecture","text":"<p>Trigger: /modular-architecture</p> <p>Purpose: Enforce modular boundaries and clear external interfaces.</p>"},{"location":"temp-prompts-organized/00-ideation/architecture/modular-architecture.architecture/#steps","title":"Steps","text":"<ol> <li>Identify services/modules and their public contracts.</li> <li>Flag cross-module imports and circular deps.</li> <li>Propose boundaries, facades, and internal folders.</li> <li>Add \"contract tests\" for public APIs.</li> </ol>"},{"location":"temp-prompts-organized/00-ideation/architecture/modular-architecture.architecture/#output-format","title":"Output format","text":"<ul> <li>Diagram-ready list of modules and edges, plus diffs.</li> </ul>"},{"location":"temp-prompts-organized/00-ideation/architecture/stack-evaluation.architecture/","title":"Stack Evaluation","text":"<p>Trigger: /stack-evaluation</p> <p>Purpose: Evaluate language/framework choices relative to AI familiarity and repo goals.</p>"},{"location":"temp-prompts-organized/00-ideation/architecture/stack-evaluation.architecture/#steps","title":"Steps","text":"<ol> <li>Detect current stack and conventions.</li> <li>List tradeoffs: maturity, tooling, available examples, hiring, and AI training coverage.</li> <li>Recommend stay-or-switch with migration outline if switching.</li> </ol>"},{"location":"temp-prompts-organized/00-ideation/architecture/stack-evaluation.architecture/#output-format","title":"Output format","text":"<ul> <li>Decision memo with pros/cons and next steps.</li> </ul>"},{"location":"temp-prompts-organized/00-ideation/design/action-diagram.design/","title":"Action diagram","text":"<p>You are a CLI assistant focused on helping contributors with the task: Explain workflow triggers and dependencies as a diagram\u2011ready outline.</p> <ol> <li>Gather context by inspecting <code>.github/workflows</code>.</li> <li>Explain workflow triggers and dependencies as a diagram\u2011ready outline.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Explain workflow triggers and dependencies as a diagram\u2011ready outline.</li> <li>Organize details under clear subheadings so contributors can scan quickly.</li> <li>List nodes and edges to make diagram creation straightforward.</li> <li>Highlight workflow triggers, failing jobs, and proposed fixes.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p>"},{"location":"temp-prompts-organized/00-ideation/design/action-diagram.design/#nodes","title":"Nodes","text":"<ul> <li>build</li> <li>deploy</li> </ul>"},{"location":"temp-prompts-organized/00-ideation/design/action-diagram.design/#edges","title":"Edges","text":"<ul> <li>push -&gt; build</li> <li>build -&gt; deploy</li> </ul>"},{"location":"temp-prompts-organized/00-ideation/design/api-contract.design/","title":"API Contract","text":"<p>Trigger: /api-contract \"\" <p>Purpose: Author an initial OpenAPI 3.1 or GraphQL SDL contract from requirements.</p> <p>Steps:</p> <ol> <li>Parse inputs and existing docs. If REST, prefer OpenAPI 3.1 YAML; if GraphQL, produce SDL.</li> <li>Define resources, operations, request/response schemas, error model, auth, and rate limit headers.</li> <li>Add examples for each endpoint or type. Include pagination and filtering conventions.</li> <li>Save to <code>apis/&lt;domain&gt;/openapi.yaml</code> or <code>apis/&lt;domain&gt;/schema.graphql</code>.</li> <li>Emit changelog entry <code>docs/api/CHANGELOG.md</code> with rationale and breaking-change flags.</li> </ol> <p>Output format:</p> <ul> <li><code>Contract Path</code>, <code>Design Notes</code>, and a fenced code block with the spec body.</li> </ul> <p>Examples:</p> <ul> <li><code>/api-contract \"accounts &amp; auth\"</code> \u2192 <code>apis/auth/openapi.yaml</code> with OAuth 2.1 flows.</li> </ul> <p>Notes:</p> <ul> <li>Follow JSON:API style for REST unless caller specifies otherwise. Include <code>429</code> and <code>5xx</code> models.</li> </ul>"},{"location":"temp-prompts-organized/00-ideation/design/design-assets.design/","title":"Design Assets","text":"<p>Trigger: /design-assets</p> <p>Purpose: Generate favicons and small design snippets from product brand.</p>"},{"location":"temp-prompts-organized/00-ideation/design/design-assets.design/#steps","title":"Steps","text":"<ol> <li>Extract brand colors and name from README or config.</li> <li>Produce favicon set, social preview, and basic UI tokens.</li> <li>Document asset locations and references.</li> </ol>"},{"location":"temp-prompts-organized/00-ideation/design/design-assets.design/#output-format","title":"Output format","text":"<ul> <li>Asset checklist and generation commands.</li> </ul>"},{"location":"temp-prompts-organized/00-ideation/design/ui-screenshots.design/","title":"UI Screenshots","text":"<p>Trigger: /ui-screenshots</p> <p>Purpose: Analyze screenshots for UI bugs or inspiration and propose actionable UI changes.</p>"},{"location":"temp-prompts-organized/00-ideation/design/ui-screenshots.design/#steps","title":"Steps","text":"<ol> <li>Accept screenshot paths or links.</li> <li>Describe visual hierarchy, spacing, contrast, and alignment issues.</li> <li>Output concrete CSS or component changes.</li> </ol>"},{"location":"temp-prompts-organized/00-ideation/design/ui-screenshots.design/#output-format","title":"Output format","text":"<ul> <li>Issue list and code snippets to fix visuals.</li> </ul>"},{"location":"temp-prompts-organized/00-ideation/requirements/plan-delta.requirements/","title":"plan-delta","text":"<p>Trigger: /plan-delta</p> <p>Purpose: Orchestrate mid-project planning deltas on an existing task graph with history preservation, lineage, and readiness recalculation.</p> <p>Steps:</p> <ol> <li>Discover repository context:</li> <li>Detect tasks file path: prefer <code>tasks.json</code>; else search <code>**/tasks.json</code>.</li> <li>Detect latest plan doc: prefer <code>PRD.md</code> or <code>docs/PRD.md</code>; else <code>**/*(prd|spec|plan)*.md</code>.</li> <li>Snapshot:</li> <li>Create <code>./artifacts/</code> if missing.</li> <li>Copy the current tasks file to <code>./artifacts/tasks-$(date +%Y%m%d-%H%M%S).json</code> using: <code>cp -f &lt;tasks.json&gt; ./artifacts/tasks-$(date +%Y%m%d-%H%M%S).json</code>.</li> <li>Input collection:</li> <li>Read new objectives, constraints, and findings from the user input or provided delta text.</li> <li>Parse selection rules to choose mode: Continue, Hybrid Rebaseline, or Full Rebaseline.</li> <li>Delta Doc generation:</li> <li>Create <code>./artifacts/delta-$(date +%Y%m%d-%H%M%S).md</code> containing sections:<ul> <li>Objectives (new)</li> <li>Constraints (new)</li> <li>Impacts</li> <li>Decisions</li> <li>Evidence log (sources, dates, links)</li> </ul> </li> <li>Task graph update:</li> <li>Never alter historical states <code>done|in_progress|blocked</code> of existing tasks.</li> <li>Do not reuse IDs. For any replaced task, set <code>superseded_by</code> on the old task and include its ID in the new task's <code>supersedes[]</code>.</li> <li>Add <code>source_doc</code>, <code>lineage[]</code> on all new or changed tasks.</li> <li>Create new tasks only for new or changed work. Link predecessors via <code>dependencies</code> or <code>relations</code>.</li> <li>Keep deprecated tasks in graph with <code>status: \"deprecated\"</code> and a <code>reason</code>.</li> <li>Graph maintenance:</li> <li>Recompute dependency order and validate acyclicity.</li> <li>Flag contradictions or invalidated edges as <code>blocked</code> with a machine-readable <code>blocked_reason</code>.</li> <li>Bubble critical-path tasks to the active frontier by recomputing earliest-start and slack.</li> <li>Readiness and selection:</li> <li>Implement <code>ready/next()</code> over the graph: select tasks with all dependencies <code>done</code> and not <code>blocked</code>.</li> <li>Produce a short readiness report grouped by <code>ready | blocked | deprecated</code>.</li> <li>Outputs:</li> <li>Write the updated tasks file in-place, preserving formatting where possible.</li> <li>Persist the Delta Doc under <code>./artifacts/</code>.</li> <li>Emit decision hooks: one line per change stating what it enables.</li> <li>Termination:</li> <li>Stop when all deltas are merged and readiness recalculated, or when a prerequisite cannot be resolved with available evidence.</li> </ol> <p>Output format:</p> <ul> <li>Produce three artifacts:</li> <li>Updated tasks file: valid JSON. Preserve existing fields. Append only the new or changed tasks and relations. Do not mutate historical statuses.</li> <li>Delta document: Markdown with the exact headings <code># Delta</code>, <code>## Objectives</code>, <code>## Constraints</code>, <code>## Impacts</code>, <code>## Decisions</code>, <code>## Evidence</code>.</li> <li>Readiness report: Plain text with sections <code>READY</code>, <code>BLOCKED</code>, <code>DEPRECATED</code>. Each item as <code>- &lt;id&gt; &lt;title&gt;</code>; blocked items add <code>[reason=&lt;code&gt;]</code>.</li> <li>Print Decision hooks as lines starting with <code>HOOK: &lt;id&gt; enables &lt;capability&gt;</code>.</li> </ul> <p>Examples:</p> <ul> <li>Input \u2192</li> </ul> <pre><code>Mode: Continue\nNew objectives: add offline export for tasks\nConstraints: no DB migrations\nFindings: existing export lib supports JSON only\n</code></pre> <p>Output \u2192   - Updated <code>tasks.json</code> with new task <code>T-342</code> { title: \"Add CSV export\", dependencies: [\"T-120\"], source_doc: \"delta-20250921.md\", lineage: [\"T-120\"], supersedes: [] }.   - <code>artifacts/delta-20250921-160500.md</code> populated with objectives, constraints, impacts, decisions, evidence.   - Readiness report lists <code>T-342</code> under READY if deps done.</p> <ul> <li>Input \u2192</li> </ul> <pre><code>Mode: Hybrid Rebaseline\nChanges: ~30% of scope affected by auth provider swap\n</code></pre> <p>Output \u2192   - Minor-plan version bump recorded in Delta Doc.   - New tasks added for provider swap; prior tasks kept with <code>deprecated</code> or <code>blocked</code> and lineage links.</p> <p>Notes:</p> <ul> <li>Never write outside the repo. Keep artifacts in <code>./artifacts/</code>.</li> <li>Evidence log entries include <code>source</code>, <code>date</code>, <code>summary</code>, and optional <code>link</code>.</li> <li>Selection rules: Continue (&lt;20% change), Hybrid (20\u201340%), Full (&gt;40% or goals/KPIs/architecture pivot).</li> <li>If inputs are insufficient, emit a TERMINATION note with missing evidence keys.</li> </ul>"},{"location":"temp-prompts-organized/00-ideation/requirements/planning-process.requirements/","title":"Planning Process","text":"<p>Trigger: /planning-process</p> <p>Purpose: Draft, refine, and execute a feature plan with strict scope control and progress tracking.</p>"},{"location":"temp-prompts-organized/00-ideation/requirements/planning-process.requirements/#steps","title":"Steps","text":"<ol> <li>If no plan file exists, create <code>PLAN.md</code>. If it exists, load it.</li> <li>Draft sections: Goal, User Story, Milestones, Tasks, Won't do, Ideas for later, Validation, Risks.</li> <li>Trim bloat. Convert vague bullets into testable tasks with acceptance criteria.</li> <li>Tag each task with an owner and estimate. Link to files or paths that will change.</li> <li>Maintain two backlogs: Won't do (explicit non-goals) and Ideas for later (deferrable work).</li> <li>Mark tasks done after tests pass. Append commit SHAs next to completed items.</li> <li>After each milestone: run tests, update Validation, then commit <code>PLAN.md</code>.</li> </ol>"},{"location":"temp-prompts-organized/00-ideation/requirements/planning-process.requirements/#output-format","title":"Output format","text":"<ul> <li>Update or create <code>PLAN.md</code> with the sections above.</li> <li>Include a checklist for Tasks. Keep lines under 100 chars.</li> </ul>"},{"location":"temp-prompts-organized/00-ideation/requirements/planning-process.requirements/#examples","title":"Examples","text":"<p>Input: \"Add OAuth login\"</p> <p>Output:</p> <ul> <li>Goal: Let users sign in with Google.</li> <li>Tasks: [ ] add Google client, [ ] callback route, [ ] session, [ ] E2E test.</li> <li>Won't do: org SSO.</li> <li>Ideas for later: Apple login.</li> </ul>"},{"location":"temp-prompts-organized/00-ideation/requirements/planning-process.requirements/#notes","title":"Notes","text":"<ul> <li>Planning only. No code edits.</li> <li>Assume a Git repo with test runner available.</li> </ul>"},{"location":"temp-prompts-organized/00-ideation/requirements/prd-generator.requirements/","title":"PRD Generator","text":"<p>Trigger: /prd-generate Purpose: Produce a complete <code>prd.txt</code> in the exact section order, headers, and tone of the inline example PRD using only the repository README and visible link texts. Steps:</p> <p>&lt;&lt;&lt;&lt;&lt;&lt;&lt; Updated upstream 1. Read <code>README.md</code> at repo root; do not fetch external links. 2. Extract: product name, problem, target users, value, scope, constraints, features, flows, integrations, data, non-functional needs, risks. 3. If links exist, include their visible text or titles only as contextual hints. 4. Fill gaps with conservative assumptions to keep the PRD complete; collect assumptions for the Appendix. 5. Enforce strict structure identical to the example PRD\u2019s top-level headers and order. 6. For each core feature, include What, Why, High-level How, and Acceptance criteria. 7. In Technical Architecture, document optional platform-specific features and required fallbacks; mirror related risks. 8. In Development Roadmap, group by phases (MVP and later); include acceptance criteria; exclude timelines. 9. In Logical Dependency Chain, order from foundations to visible value; keep items atomic. 10. Run an internal consistency check: features appear in roadmap; risks reflect platform and data concerns; all sections non-empty. 11. Output only the final <code>prd.txt</code> content starting with <code># Overview</code> and ending with <code># Appendix</code>. Output format:</p> <ul> <li>Plain text PRD starting with <code># Overview</code> and ending with <code># Appendix</code>.</li> <li>No preamble, no postscript, no meta commentary. Notes:</li> <li>Reject generation if <code>README.md</code> is missing.</li> <li>Do not browse external sources.</li> <li> </li> </ul>"},{"location":"temp-prompts-organized/00-ideation/requirements/prd-generator.requirements/#derived-from-example_prdtxt-extracted-summaries-only-secrets-redacted","title":"Derived from example_prd.txt, extracted summaries only; secrets redacted.","text":"Output a plain-text file named <code>prd.txt</code> containing only these sections in this order (separated by one blank line):"},{"location":"temp-prompts-organized/00-ideation/requirements/prd-generator.requirements/#overview","title":"Overview","text":""},{"location":"temp-prompts-organized/00-ideation/requirements/prd-generator.requirements/#core-features","title":"Core Features","text":""},{"location":"temp-prompts-organized/00-ideation/requirements/prd-generator.requirements/#user-experience","title":"User Experience","text":""},{"location":"temp-prompts-organized/00-ideation/requirements/prd-generator.requirements/#technical-architecture","title":"Technical Architecture","text":""},{"location":"temp-prompts-organized/00-ideation/requirements/prd-generator.requirements/#development-roadmap","title":"Development Roadmap","text":""},{"location":"temp-prompts-organized/00-ideation/requirements/prd-generator.requirements/#logical-dependency-chain","title":"Logical Dependency Chain","text":""},{"location":"temp-prompts-organized/00-ideation/requirements/prd-generator.requirements/#risks-and-mitigations","title":"Risks and Mitigations","text":""},{"location":"temp-prompts-organized/00-ideation/requirements/prd-generator.requirements/#appendix","title":"Appendix","text":"<p>Output Format</p> <ul> <li><code># Overview</code>: $3</li> <li><code># Core Features</code>: Each includes What, Why, High-level How, and BDD criteria:   <code>Given ...</code> <code>When ...</code> <code>Then ...</code></li> <li><code># User Experience</code>: Personas, key flows, UI/UX, accessibility</li> <li><code># Technical Architecture</code>: Components, data models, APIs/integrations, infrastructure, NFRs</li> <li><code># Development Roadmap</code>: MVP and Future Enhancements with acceptance criteria (no dates)</li> <li><code># Logical Dependency Chain</code>: Work ordering for foundations, earliest front end, extensible units</li> <li><code># Risks and Mitigations</code>: Each includes Description, Likelihood, Impact, Mitigation</li> <li><code># Appendix</code>:   \u2022 Assumptions (bulleted)   \u2022 Research findings from $1   \u2022 Context notes (<code>- &lt;visible text&gt; \u2014 inferred topic</code>)   \u2022 Technical specs</li> </ul> <p>Validation Checks</p> <ul> <li>Headers present and ordered</li> <li>All BDD criteria included for features/fallbacks</li> <li>Risks include likelihood and impact</li> <li>No URLs/secrets; exactly one blank line between sections</li> <li>$1 contains only visible link text (no external browsing) <p>Stashed changes</p> </li> </ul>"},{"location":"temp-prompts-organized/00-ideation/requirements/scope-control.requirements/","title":"Scope Control","text":"<p>Trigger: /scope-control</p> <p>Purpose: Enforce explicit scope boundaries and maintain \"won't do\" and \"ideas for later\" lists.</p>"},{"location":"temp-prompts-organized/00-ideation/requirements/scope-control.requirements/#steps","title":"Steps","text":"<ol> <li>Parse <code>PLAN.md</code> or create it if absent.</li> <li>For each open task, confirm linkage to the current milestone.</li> <li>Detect off-scope items and move them to Won't do or Ideas for later with rationale.</li> <li>Add a \"Scope Gate\" checklist before merging.</li> </ol>"},{"location":"temp-prompts-organized/00-ideation/requirements/scope-control.requirements/#output-format","title":"Output format","text":"<ul> <li>Patch to <code>PLAN.md</code> showing changes in sections and checklists.</li> </ul>"},{"location":"temp-prompts-organized/00-ideation/requirements/scope-control.requirements/#examples","title":"Examples","text":"<p>Input: off-scope request \"Add email templates\" during OAuth feature. Output: Move to Ideas for later with reason \"Not needed for OAuth MVP\".</p>"},{"location":"temp-prompts-organized/00-ideation/requirements/scope-control.requirements/#notes","title":"Notes","text":"<ul> <li>Never add new scope without recording tradeoffs.</li> </ul>"},{"location":"temp-prompts-organized/10-scaffold/ci-setup/devops-automation.ci-setup/","title":"DevOps Automation","text":"<p>Trigger: /devops-automation</p> <p>Purpose: Configure servers, DNS, SSL, CI/CD at a pragmatic level.</p>"},{"location":"temp-prompts-organized/10-scaffold/ci-setup/devops-automation.ci-setup/#steps","title":"Steps","text":"<ol> <li>Inspect repo for IaC or deploy scripts.</li> <li>Generate Terraform or Docker Compose templates if missing.</li> <li>Propose CI workflows for tests, builds, and deploys.</li> <li>Provide runbooks for rollback.</li> </ol>"},{"location":"temp-prompts-organized/10-scaffold/ci-setup/devops-automation.ci-setup/#output-format","title":"Output format","text":"<ul> <li>Infra plan with checkpoints and secrets placeholders.</li> </ul>"},{"location":"temp-prompts-organized/10-scaffold/ci-setup/env-setup.ci-setup/","title":"Env Setup","text":"<p>Trigger: /env-setup</p> <p>Purpose: Create .env.example, runtime schema validation, and per-env overrides.</p> <p>Steps:</p> <ol> <li>Scan repo for <code>process.env</code> usage and collected keys.</li> <li>Emit <code>.env.example</code> with comments and safe defaults.</li> <li>Add runtime validation via <code>zod</code> or <code>envsafe</code> in <code>packages/config</code>.</li> <li>Document <code>development</code>, <code>staging</code>, <code>production</code> precedence and loading order.</li> </ol> <p>Output format: <code>.env.example</code> content block and <code>config/env.ts</code> snippet.</p> <p>Examples: <code>/env-setup</code>.</p> <p>Notes: Do not include real credentials. Enforce <code>STRICT_ENV=true</code> in CI.</p>"},{"location":"temp-prompts-organized/10-scaffold/ci-setup/monitoring-setup.ci-setup/","title":"Monitoring Setup","text":"<p>Trigger: /monitoring-setup</p> <p>Purpose: Bootstrap logs, metrics, and traces with dashboards per domain.</p> <p>Steps:</p> <ol> <li>Choose stack: OpenTelemetry \u2192 Prometheus/Grafana, or vendor.</li> <li>Instrument web and api for request latency, error rate, throughput, and core domain metrics.</li> <li>Provide default dashboards JSON and alert examples.</li> </ol> <p>Output format: instrumentation checklist and dashboard links/paths.</p> <p>Examples: <code>/monitoring-setup</code>.</p> <p>Notes: Avoid high\u2011cardinality labels. Sample traces selectively in prod.</p>"},{"location":"temp-prompts-organized/10-scaffold/ci-setup/secrets-manager-setup.ci-setup/","title":"Secrets Manager Setup","text":"<p>Trigger: /secrets-manager-setup  <p>Purpose: Provision a secrets store and map application variables to it.</p> <p>Steps:</p> <ol> <li>Choose provider: 1Password, Doppler, AWS Secrets Manager, GCP Secret Manager, Vault.</li> <li>Define secret names and scopes. Generate read paths for web and api.</li> <li>Add dev bootstrap instructions and CI access policy docs.</li> </ol> <p>Output format: mapping table <code>ENV_VAR \u2192 provider path</code> and bootstrap steps.</p> <p>Examples: <code>/secrets-manager-setup doppler</code>.</p> <p>Notes: Never echo secret values. Include rotation policy.</p>"},{"location":"temp-prompts-organized/10-scaffold/ci-setup/slo-setup.ci-setup/","title":"SLO Setup","text":"<p>Trigger: /slo-setup</p> <p>Purpose: Define Service Level Objectives, burn alerts, and runbooks.</p> <p>Steps:</p> <ol> <li>Choose SLI/metrics per user journey. Define SLO targets and error budgets.</li> <li>Create burn alerts (fast/slow) and link to runbooks.</li> <li>Add <code>SLO.md</code> with rationale and review cadence.</li> </ol> <p>Output format: SLO table and alert rules snippet.</p> <p>Examples: <code>/slo-setup</code>.</p> <p>Notes: Tie SLOs to deploy gates and incident severity.</p>"},{"location":"temp-prompts-organized/10-scaffold/conventions/version-control-guide.conventions/","title":"Version Control Guide","text":"<p>Trigger: /version-control-guide</p> <p>Purpose: Enforce clean incremental commits and clean-room re-implementation when finalizing.</p>"},{"location":"temp-prompts-organized/10-scaffold/conventions/version-control-guide.conventions/#steps","title":"Steps","text":"<ol> <li>Start each feature from a clean branch: <code>git switch -c &lt;feat&gt;</code>.</li> <li>Commit in vertical slices with passing tests: <code>git add -p &amp;&amp; git commit</code>.</li> <li>When solution is proven, recreate a minimal clean diff: stash or copy results, reset, then apply only the final changes.</li> <li>Use <code>git revert</code> for bad commits instead of force-pushing shared branches.</li> </ol>"},{"location":"temp-prompts-organized/10-scaffold/conventions/version-control-guide.conventions/#output-format","title":"Output format","text":"<ul> <li>Checklist plus suggested commands for the current repo state.</li> </ul>"},{"location":"temp-prompts-organized/10-scaffold/conventions/version-control-guide.conventions/#examples","title":"Examples","text":"<ul> <li>Convert messy spike into three commits: setup, feature, tests.</li> </ul>"},{"location":"temp-prompts-organized/10-scaffold/conventions/version-control-guide.conventions/#notes","title":"Notes","text":"<ul> <li>Never modify remote branches without confirmation.</li> </ul>"},{"location":"temp-prompts-organized/10-scaffold/scaffold/auth.scaffold/","title":"Auth Scaffold","text":"<p>Trigger: /auth-scaffold  <p>Purpose: Scaffold auth flows, routes, storage, and a basic threat model.</p> <p>Steps:</p> <ol> <li>Select provider (OAuth/OIDC/email) and persistence for sessions.</li> <li>Generate routes: login, callback, logout, session refresh.</li> <li>Add CSRF, state, PKCE where applicable. Include secure cookie flags.</li> <li>Document threat model: replay, fixation, token leakage, SSRF on callbacks.</li> <li>Wire to frontend with protected routes and user context.</li> </ol> <p>Output format: route list, config keys, and mitigations table.</p> <p>Examples: <code>/auth-scaffold oauth</code> \u2192 NextAuth/Passport/Custom adapter plan.</p> <p>Notes: Never print real secrets. Use placeholders in <code>.env.example</code>.</p>"},{"location":"temp-prompts-organized/10-scaffold/scaffold/db-bootstrap.scaffold/","title":"DB Bootstrap","text":"<p>Trigger: /db-bootstrap  <p>Purpose: Pick a database, initialize migrations, local compose, and seed scripts.</p> <p>Steps:</p> <ol> <li>Create <code>db/compose.yaml</code> for local dev (skip for sqlite).</li> <li>Choose ORM/driver (Prisma or Drizzle for SQL). Add migration config.</li> <li>Create <code>prisma/schema.prisma</code> or <code>drizzle/*.ts</code> with baseline tables (users, sessions, audit_log).</li> <li>Add <code>pnpm db:migrate</code>, <code>db:reset</code>, <code>db:seed</code> scripts. Write seed data for local admin user.</li> <li>Update <code>.env.example</code> with <code>DATABASE_URL</code> and test connection script.</li> </ol> <p>Output format: Migration plan list and generated file paths.</p> <p>Examples: <code>/db-bootstrap postgres</code> \u2192 Prisma + Postgres docker-compose.</p> <p>Notes: Avoid destructive defaults; provide <code>--preview-feature</code> warnings if relevant.</p>"},{"location":"temp-prompts-organized/10-scaffold/scaffold/fullstack.scaffold/","title":"Scaffold Full\u2011Stack App","text":"<p>Trigger: /scaffold-fullstack  <p>Purpose: Create a minimal, production-ready monorepo template with app, API, tests, CI seeds, and infra stubs.</p> <p>Steps:</p> <ol> <li>Read repository context: <code>git rev-parse --is-inside-work-tree</code>.</li> <li>If repo is empty, initialize: <code>git init -b main</code> and create <code>.editorconfig</code>, <code>.gitignore</code>, <code>README.md</code>.</li> <li>For <code>&lt;stack&gt;</code> derive presets (examples):</li> <li><code>ts-next-express-pg</code>: Next.js app, Express API, Prisma + PostgreSQL, Playwright, pnpm workspaces.</li> <li><code>ts-vite-fastify-sqlite</code>: Vite + React app, Fastify API, Drizzle + SQLite.</li> <li>Create workspace layout:</li> <li>root: <code>package.json</code> with <code>pnpm</code> workspaces, <code>tsconfig.base.json</code>, <code>eslint</code>, <code>prettier</code>.</li> <li>apps/web, apps/api, packages/ui, packages/config.</li> <li>Add scripts:</li> <li>root: <code>dev</code>, <code>build</code>, <code>lint</code>, <code>typecheck</code>, <code>test</code>, <code>e2e</code>, <code>format</code>.</li> <li>web: Next/Vite scripts. api: dev with ts-node or tsx.</li> <li>Seed CI files: <code>.github/workflows/ci.yml</code> with jobs [lint, typecheck, test, build, e2e] and artifact uploads.</li> <li>Add example routes:</li> <li>web: <code>/health</code> page. api: <code>GET /health</code> returning <code>{ ok: true }</code>.</li> <li>Write docs to <code>README.md</code>: how to run dev, test, build, and env variables.</li> <li>Stage files, but do not commit. Output a tree and next commands.</li> </ol> <p>Output format:</p> <ul> <li>Title line: <code>Scaffold created: &lt;stack&gt;</code></li> <li>Sections: <code>Repo Tree</code>, <code>Next Steps</code>, <code>CI Seeds</code>.</li> <li>Include a fenced code block of the <code>tree</code> and sample scripts.</li> </ul> <p>Examples:</p> <ul> <li>Input: <code>/scaffold-fullstack ts-next-express-pg</code> Output: Summary + tree with <code>apps/web</code>, <code>apps/api</code>, <code>packages/ui</code>.</li> <li>Input: <code>/scaffold-fullstack ts-vite-fastify-sqlite</code> Output: Summary + tree + Drizzle config.</li> </ul> <p>Notes:</p> <ul> <li>Assume pnpm and Node 20+. Do not run package installs automatically; propose commands instead.</li> <li>Respect existing files; avoid overwriting without explicit confirmation.</li> </ul>"},{"location":"temp-prompts-organized/10-scaffold/scaffold/iac-bootstrap.scaffold/","title":"IaC Bootstrap","text":"<p>Trigger: /iac-bootstrap  <p>Purpose: Create minimal Infrastructure-as-Code for the chosen platform plus CI hooks.</p> <p>Steps:</p> <ol> <li>Select tool (Terraform, Pulumi). Initialize backend and state.</li> <li>Define stacks for <code>preview</code>, <code>staging</code>, <code>prod</code>. Add outputs (URLs, connection strings).</li> <li>Add CI jobs: plan on PR, apply on main with manual approval.</li> <li>Document rollback and drift detection.</li> </ol> <p>Output format: stack diagram, file list, CI snippets.</p> <p>Examples: <code>/iac-bootstrap aws</code>.</p> <p>Notes: Prefer least privilege IAM and remote state with locking.</p>"},{"location":"temp-prompts-organized/20-implementation/impl/commit.impl/","title":"Commit Message Assistant","text":"<p>Trigger: <code>commit</code></p> <p>Purpose: Generate a conventional, review-ready commit message from the currently staged changes.</p> <p>Output: A finalized commit message with a 50\u201372 character imperative subject line, optional scope, and supporting body lines describing the rationale, evidence, and tests.</p>"},{"location":"temp-prompts-organized/20-implementation/impl/commit.impl/#steps","title":"Steps","text":"<ol> <li>Verify there is staged work with <code>git status --short</code> and stop with guidance if nothing is staged.</li> <li>Inspect the staged diff with <code>git diff --staged</code> and identify the primary change type (feat, fix, chore, docs, refactor, etc.) and optional scope (e.g., package or module).</li> <li>Draft a concise subject line in the form <code>&lt;type&gt;(&lt;scope&gt;): &lt;imperative summary&gt;</code> or <code>&lt;type&gt;: &lt;imperative summary&gt;</code> when no scope applies. Keep the line under 73 characters.</li> <li>Capture essential details in the body as wrapped bullet points or paragraphs: what changed, why it was necessary, and any follow-up actions.</li> <li>Document validation in a trailing section (e.g., <code>Tests:</code>) noting commands executed or why tests were skipped.</li> </ol>"},{"location":"temp-prompts-organized/20-implementation/impl/commit.impl/#example-output","title":"Example Output","text":"<pre><code>fix(auth): prevent session expiration loop\n\n- guard refresh flow against repeated 401 responses\n- add regression coverage for expired refresh tokens\n\nTests: npm test -- auth/session.test.ts\n</code></pre>"},{"location":"temp-prompts-organized/20-implementation/impl/content-generation.impl/","title":"Content Generation","text":"<p>Trigger: /content-generation</p> <p>Purpose: Draft docs, blog posts, or marketing copy aligned with the codebase.</p>"},{"location":"temp-prompts-organized/20-implementation/impl/content-generation.impl/#steps","title":"Steps","text":"<ol> <li>Read repo README and recent CHANGELOG or commits.</li> <li>Propose outlines for docs and posts.</li> <li>Generate content with code snippets and usage examples.</li> </ol>"},{"location":"temp-prompts-organized/20-implementation/impl/content-generation.impl/#output-format","title":"Output format","text":"<ul> <li>Markdown files with frontmatter and section headings.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/impl/feature-flags.impl/","title":"Feature Flags","text":"<p>Trigger: /feature-flags  <p>Purpose: Integrate a flag provider, wire the SDK, and enforce guardrails.</p> <p>Steps:</p> <ol> <li>Select provider (LaunchDarkly, Unleash, Flagsmith, custom).</li> <li>Add SDK init in web/api with bootstrap values and offline mode for dev.</li> <li>Define flag naming and ownership. Add kill\u2011switch pattern and monitoring.</li> </ol> <p>Output format: SDK snippet, example usage, and guardrail checklist.</p> <p>Examples: <code>/feature-flags launchdarkly</code>.</p> <p>Notes: Ensure flags are typed and expire with tickets.</p>"},{"location":"temp-prompts-organized/20-implementation/impl/fix.impl/","title":"Fix","text":"<p>Trigger: /fix \"\" <p>Purpose: Propose a minimal, correct fix with diff-style patches.</p> <p>You are a CLI assistant focused on helping contributors with the task: Propose a minimal, correct fix with patch hunks.</p> <ol> <li>Gather context by running <code>git log --pretty='- %h %s' -n 20</code> for the recent commits; running <code>git ls-files | sed -n '1,400p'</code> for the repo map (first 400 files).</li> <li>Bug summary: . Using recent changes and repository context below, propose a minimal fix with unified diff patches. <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Propose a minimal, correct fix with patch hunks.</li> <li>Provide unified diff-style patches when recommending code changes.</li> <li>Offer prioritized, actionable recommendations with rationale.</li> </ul> <p>Example Input: Authentication failure after password reset</p> <p>Expected Output:</p> <pre><code>diff\n- if (!user) return error;\n+ if (!user) return { status: 401 };\n</code></pre> <p>Regression test: add case for missing user.</p>"},{"location":"temp-prompts-organized/20-implementation/impl/generate.impl/","title":"Generate Unit Tests","text":"<p>Trigger: /generate  <p>Purpose: Generate unit tests for a given source file.</p> <p>You are a CLI assistant focused on helping contributors with the task: Generate unit tests for a given source file.</p>"},{"location":"temp-prompts-organized/20-implementation/impl/generate.impl/#steps","title":"Steps","text":"<ol> <li>Inspect <code>package.json</code> to identify the unit test framework, runner scripts, and any helper utilities required for the suite.</li> <li>Review the target source file with <code>sed -n '1,400p' {{args}}</code> to catalog exported members, branching logic, and error handling paths that must be exercised.</li> <li>Outline the test file structure (location, naming, setup/teardown) and propose arrange/act/assert cases that cover happy paths, edge cases, and failure scenarios.</li> <li>Provide guidance on implementing the tests and how to validate them locally (e.g., <code>npm test -- &lt;pattern&gt;</code> or framework-specific commands).</li> </ol>"},{"location":"temp-prompts-organized/20-implementation/impl/generate.impl/#output","title":"Output","text":"<ul> <li>Begin with a concise summary that restates the goal: Generate unit tests for a given source file.</li> <li>List the recommended test files, describe each test case, and highlight coverage gaps they close.</li> <li>Call out the command(s) to run the new tests and any fixtures or mocks required.</li> <li>Document the evidence you used (e.g., <code>package.json</code>, specific functions/branches in the source file) so maintainers can trust the conclusion.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/impl/generate.impl/#example","title":"Example","text":"<p>Input</p> <pre><code>src/components/Button.tsx\n</code></pre> <p>Output</p> <ul> <li>Summary: Author React Testing Library unit tests for <code>Button</code> to cover rendering, disabled behavior, and click handling.</li> <li>Create <code>src/components/__tests__/Button.test.tsx</code> that:</li> <li>Renders the button label and asserts it matches <code>props.children</code>.</li> <li>Verifies <code>onClick</code> fires once when the button is enabled and is skipped when <code>disabled</code> is true.</li> <li>Confirms the <code>variant=\"primary\"</code> branch applies the <code>btn-primary</code> class.</li> <li>Validation: Run <code>npm test -- Button.test.tsx</code> to execute the suite.</li> <li>Evidence: <code>package.json</code> (scripts.test uses Jest + RTL), component branches in <code>src/components/Button.tsx</code> (disabled guard, variant styling).</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/impl/prototype-feature.impl/","title":"Prototype Feature","text":"<p>Trigger: /prototype-feature</p> <p>Purpose: Spin up a standalone prototype in a clean repo before merging into main.</p>"},{"location":"temp-prompts-organized/20-implementation/impl/prototype-feature.impl/#steps","title":"Steps","text":"<ol> <li>Create a scratch directory name suggestion and scaffolding commands.</li> <li>Generate minimal app with only the feature and hardcoded data.</li> <li>Add E2E test covering the prototype flow.</li> <li>When validated, list the minimal patches to port back.</li> </ol>"},{"location":"temp-prompts-organized/20-implementation/impl/prototype-feature.impl/#output-format","title":"Output format","text":"<ul> <li>Scaffold plan and migration notes.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/impl/todos.impl/","title":"TODOs","text":"<p>You are a CLI assistant focused on helping contributors with the task: Find and group TODO/FIXME annotations.</p> <ol> <li>Gather context by running <code>rg -n \"TODO|FIXME\" -g '!node_modules' . || grep -RInE 'TODO|FIXME' .</code>.</li> <li>Find and group TODO/FIXME annotations.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Find and group TODO/FIXME annotations.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p> <ul> <li>Group: Platform backlog \u2014 4 TODOs referencing auth migration (owner: @platform).</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/impl/voice-input.impl/","title":"Voice Input","text":"<p>Trigger: /voice-input</p> <p>Purpose: Support interaction from voice capture and convert to structured prompts.</p>"},{"location":"temp-prompts-organized/20-implementation/impl/voice-input.impl/#steps","title":"Steps","text":"<ol> <li>Accept transcript text.</li> <li>Normalize to tasks or commands for other prompts.</li> <li>Preserve speaker intents and important entities.</li> </ol>"},{"location":"temp-prompts-organized/20-implementation/impl/voice-input.impl/#output-format","title":"Output format","text":"<ul> <li>Cleaned command list ready to execute.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/review/audit.review/","title":"Audit","text":"<p>Trigger: /audit</p> <p>Purpose: Audit repository hygiene and suggest improvements.</p>"},{"location":"temp-prompts-organized/20-implementation/review/audit.review/#steps","title":"Steps","text":"<ol> <li>Gather context by running <code>ls -la</code> for the top-level listing. Inspect <code>.editorconfig</code>, <code>.gitignore</code>, <code>.geminiignore</code>, <code>.eslintrc.cjs</code>, <code>.eslintrc.js</code>, <code>tsconfig.json</code>, and <code>pyproject.toml</code> if present to understand shared conventions.</li> <li>Assess repository hygiene across documentation, testing, CI, linting, and security. Highlight gaps and existing automation.</li> <li>Synthesize the findings into a prioritized checklist with recommended next steps.</li> </ol>"},{"location":"temp-prompts-organized/20-implementation/review/audit.review/#output-format","title":"Output format","text":"<ul> <li>Begin with a concise summary that restates the goal: Audit repository hygiene and suggest improvements.</li> <li>Offer prioritized, actionable recommendations with rationale.</li> <li>Call out test coverage gaps and validation steps.</li> <li>Highlight workflow triggers, failing jobs, and proposed fixes.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/review/audit.review/#example-input","title":"Example input","text":"<p>(none \u2013 command runs without arguments)</p>"},{"location":"temp-prompts-organized/20-implementation/review/audit.review/#expected-output","title":"Expected output","text":"<ul> <li>Structured report following the specified sections.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/review/cross-check.review/","title":"Conflict Resolver","text":"<p>Trigger: /cross-check</p> <p>Purpose: Compare conflicting findings and decide which source prevails with rationale.</p> <p>Steps:</p> <ol> <li>Accept a list of SourceIDs or URLs with short findings.</li> <li>Evaluate publisher authority, recency, directness to primary data.</li> <li>Select the prevailing source; note contradictions and rationale.</li> </ol> <p>Output format:</p> <pre><code>### Contradictions\n- {S2 vs S5 \u2192 rationale}\n\n### Prevails\n- {SourceID} because {reason}\n</code></pre> <p>Examples:</p> <ul> <li>Input: <code>/cross-check S2: blog vs S5: RFC</code></li> <li>Output: RFC prevails due to primary standard.</li> </ul> <p>Notes:</p> <ul> <li>Always explain why one source prevails.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/review/evidence-capture.review/","title":"Evidence Logger","text":"<p>Trigger: /evidence-capture</p> <p>Purpose: Capture sources for a specified claim with dates, \u226425-word quotes, findings, relevance, and confidence.</p> <p>Steps:</p> <ol> <li>Read the claim text and optional URLs provided.</li> <li>For each source, record metadata and a \u226425-word quote.</li> <li>Add a brief Finding, Relevance (H/M/L), and Confidence (0.0\u20131.0).</li> </ol> <p>Output format:</p> <pre><code>### Evidence Log\n| SourceID | Title | Publisher | URL | PubDate | Accessed | Quote (\u226425w) | Finding | Rel | Conf |\n|---|---|---|---|---|---|---|---|---|---|\n</code></pre> <p>Examples:</p> <ul> <li>Input: <code>/evidence-capture \"Next.js 15 requires React 19 RC\"</code> with official links.</li> <li>Output: Evidence table entries with dates.</li> </ul> <p>Notes:</p> <ul> <li>Mark missing PubDate as n/a. Prefer official documentation.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/review/pr-desc.review/","title":"PR Description","text":"<p>Trigger: /pr-desc  <p>Purpose: Draft a PR description from the branch diff.</p> <p>You are a CLI assistant focused on helping contributors with the task: Draft a PR description from the branch diff.</p> <ol> <li>Gather context by running <code>git diff --name-status origin/main...HEAD</code> for the changed files (name + status); running <code>git diff --shortstat origin/main...HEAD</code> for the high\u2011level stats.</li> <li>Create a crisp PR description following this structure: Summary, Context, Changes, Screenshots (if applicable), Risk, Test Plan, Rollback, Release Notes (if user\u2011facing). Base branch: origin/main User context: . <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Draft a PR description from the branch diff.</li> <li>Offer prioritized, actionable recommendations with rationale.</li> <li>Call out test coverage gaps and validation steps.</li> <li>Highlight workflow triggers, failing jobs, and proposed fixes.</li> </ul> <p>Example Input: src/example.ts</p> <p>Expected Output:</p> <ul> <li>Actionable summary aligned with the output section.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/review/review-branch.review/","title":"Review Branch","text":"<p>Trigger: /review-branch</p> <p>Purpose: Provide a high-level review of the current branch versus origin/main.</p> <p>You are a CLI assistant focused on helping contributors with the task: Provide a high\u2011level review of the current branch vs origin/main.</p> <ol> <li>Gather context by running <code>git diff --stat origin/main...HEAD</code> for the diff stats; running <code>git diff origin/main...HEAD | sed -n '1,200p'</code> for the ```diff.</li> <li>Provide a reviewer\u2011friendly overview: goals, scope, risky areas, test impact.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Provide a high\u2011level review of the current branch vs origin/main.</li> <li>Organize details under clear subheadings so contributors can scan quickly.</li> <li>Call out test coverage gaps and validation steps.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p> <ul> <li>Structured report following the specified sections.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/review/review.review/","title":"Review","text":"<p>Trigger: /review  <p>Purpose: Review code matching a pattern and deliver actionable feedback.</p> <p>You are a CLI assistant focused on helping contributors with the task: Review code matching a pattern and give actionable feedback.</p> <ol> <li>Gather context by running <code>rg -n {{args}} . || grep -RIn {{args}} .</code> for the search results for {{args}} (filename or regex).</li> <li>Perform a thorough code review. Focus on correctness, complexity, readability, security, and performance. Provide concrete patch suggestions.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Review code matching a pattern and give actionable feedback.</li> <li>Provide unified diff-style patches when recommending code changes.</li> <li>Organize details under clear subheadings so contributors can scan quickly.</li> </ul> <p>Example Input: HttpClient</p> <p>Expected Output:</p> <ul> <li>Usage cluster in src/network/* with note on inconsistent error handling.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/review/todo-report.review/","title":"TODO report","text":"<p>You are a CLI assistant focused on helping contributors with the task: Summarize TODO/FIXME/XXX annotations across the codebase.</p> <ol> <li>Gather context by running <code>rg -n \"TODO|FIXME|XXX\" -g '!node_modules' . || grep -RInE 'TODO|FIXME|XXX' .</code>.</li> <li>Aggregate and group TODO/FIXME/XXX by area and priority. Propose a triage plan.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Summarize TODO/FIXME/XXX annotations across the codebase.</li> <li>Offer prioritized, actionable recommendations with rationale.</li> <li>Organize details under clear subheadings so contributors can scan quickly.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p> <ul> <li>Group: Platform backlog \u2014 4 TODOs referencing auth migration (owner: @platform).</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/review/tsconfig-review.review/","title":"TSConfig review","text":"<p>You are a CLI assistant focused on helping contributors with the task: Review tsconfig for correctness and DX.</p> <ol> <li>Gather context by inspecting <code>tsconfig.json</code>.</li> <li>Provide recommendations for module/target, strictness, paths, incremental builds.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Review tsconfig for correctness and DX.</li> <li>Offer prioritized, actionable recommendations with rationale.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p> <ul> <li>Structured report following the specified sections.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/blame-summary.spec-orient/","title":"Blame summary","text":"<p>You are a CLI assistant focused on helping contributors with the task: Summarize authorship hotspots for a file using git blame.</p> <ol> <li>Gather context by running <code>git blame -w --line-porcelain {{args}} | sed -n 's/^author //p' | sort | uniq -c | sort -nr | sed -n '1,25p'</code> for the blame authors (top contributors first).</li> <li>Given the blame summary below, identify ownership hotspots and potential reviewers.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Summarize authorship hotspots for a file using git blame.</li> <li>Organize details under clear subheadings so contributors can scan quickly.</li> <li>Reference evidence from CODEOWNERS or git history for each owner suggestion.</li> </ul> <p>Example Input: src/components/Button.tsx</p> <p>Expected Output:</p> <ul> <li>Refactor proposal extracting shared styling hook with before/after snippet.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/changed-files.spec-orient/","title":"Changed files","text":"<p>You are a CLI assistant focused on helping contributors with the task: Summarize changed files between HEAD and origin/main.</p> <ol> <li>Gather context by running <code>git diff --name-status origin/main...HEAD</code>.</li> <li>List and categorize changed files: added/modified/renamed/deleted. Call out risky changes.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Summarize changed files between HEAD and origin/main.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p> <ul> <li>Structured report following the specified sections.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/explain-code.spec-orient/","title":"Explain Code","text":"<p>Trigger: /explain-code</p> <p>Purpose: Provide line-by-line explanations for a given file or diff.</p>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/explain-code.spec-orient/#steps","title":"Steps","text":"<ol> <li>Accept a file path or apply to staged diff.</li> <li>Explain blocks with comments on purpose, inputs, outputs, and caveats.</li> <li>Highlight risky assumptions and complexity hot spots.</li> </ol>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/explain-code.spec-orient/#output-format","title":"Output format","text":"<ul> <li>Annotated markdown with code fences and callouts.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/explain-symbol.spec-orient/","title":"Explain symbol","text":"<p>You are a CLI assistant focused on helping contributors with the task: Explain where and how a symbol is defined and used.</p> <ol> <li>Gather context by running <code>rg -n {{args}} . || grep -RIn {{args}} .</code> for the results.</li> <li>Explain where and how a symbol is defined and used.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Explain where and how a symbol is defined and used.</li> <li>Organize details under clear subheadings so contributors can scan quickly.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: HttpClient</p> <p>Expected Output:</p> <ul> <li>Definition: src/network/httpClient.ts line 42</li> <li>Key usages: services/userService.ts, hooks/useRequest.ts</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/grep.spec-orient/","title":"Grep","text":"<p>You are a CLI assistant focused on helping contributors with the task: Recursive text search with ripgrep/grep injection.</p> <ol> <li>Gather context by running <code>rg -n {{args}} . || grep -RIn {{args}} .</code>.</li> <li>Show matched lines with file paths and line numbers.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Recursive text search with ripgrep/grep injection.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: HttpClient</p> <p>Expected Output:</p> <ul> <li>Usage cluster in src/network/* with note on inconsistent error handling.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/research-batch.spec-orient/","title":"Conversation-Aware Research \u2014 Batch WBRO","text":"<p>Trigger: /research-batch</p> <p>Purpose: Process a numbered work-breakdown list of objectives with carry-forward context across items and produce a roll-up summary.</p> <p>Steps:</p> <ol> <li>Parse numbered WBRO items from the input after the trigger.</li> <li>Before Item 1: list \u22645 bullets of starting context.</li> <li>For each item i: execute the per-item workflow and include a Conversation State Update.</li> <li>If blocked by prior gaps, emit Dependency Blocked with a minimal micro-query.</li> <li>After all items: emit a Roll-up Summary with per-item status, enabled decisions, unresolved risks, and a domain-type count of sources.</li> </ol> <p>Output format:</p> <ul> <li>Repeat the single-item format per item.</li> <li>End with:</li> </ul> <pre><code>## Roll-up Summary\n- Item {n}: {status} \u2014 decision enabled: {\u2026}; risks: {\u2026}\n- Sources by domain type: {gov, org, docs, blog, news}\n</code></pre> <p>Examples:</p> <ul> <li>Input: <code>/research-batch 1) Validate Next.js 15 stability. 2) Compare Bun vs Node for CI. 3) Licensing risks for MIT vs Apache-2.0.</code></li> <li>Output: Per-item sections plus roll-up.</li> </ul> <p>Notes:</p> <ul> <li>Keep quotes \u226425 words. Prefer primary docs.</li> </ul>"},{"location":"temp-prompts-organized/20-implementation/spec-orient/research-item.spec-orient/","title":"Conversation-Aware Research \u2014 Single Item","text":"<p>Trigger: /research-item</p> <p>Purpose: Run the full per-item research workflow for one objective and return queries, evidence, synthesis, contradictions, gaps, decision hook, plus a conversation state update.</p> <p>Steps:</p> <ol> <li>Read the objective text following the trigger.</li> <li>Capture starting context if provided.</li> <li>Apply the Process (per item): Goal, Assumptions, Query Set (4\u20138), Search Plan, Run &amp; Capture, Cross-check, Synthesis, Gaps &amp; Next, Decision Hook.</li> <li>Track PubDate and Accessed (ISO) for every source; prefer primary docs.</li> <li>Enforce quotes \u226425 words; mark inferences as \"Inference\".</li> </ol> <p>Output format:</p> <pre><code>## Item 1: {short title}\n\n### Goal\n{1 sentence}\n\n### Assumptions\n- {only if needed}\n\n### Query Set\n- {Q1}\n- {Q2}\n- {Q3}\n- {Q4\u2013Q8}\n\n### Evidence Log\n| SourceID | Title | Publisher | URL | PubDate | Accessed | Quote (\u226425w) | Finding | Rel | Conf |\n|---|---|---|---|---|---|---|---|---|---|\n\n### Synthesis\n- {claim with [S1,S3]}\n- {finding with [S2]}\n- {risk/edge with [S4]}\n\n### Contradictions\n- {S2 vs S5 \u2192 rationale}\n\n### Gaps &amp; Next\n- {follow-up or test}\n\n### Decision Hook\n{one line}\n\n### Conversation State Update\n- New facts: {bullets}\n- Constraints learned: {bullets}\n- Entities normalized: {canonical forms}\n</code></pre> <p>Examples:</p> <ul> <li>Input: <code>/research-item Compare OpenAPI 3.1 tooling for Python clients in 2024; budget $0; prefer official docs.</code></li> <li>Output: As per format with SourceIDs and dates.</li> </ul> <p>Notes:</p> <ul> <li>Safety: No personal data. Do not fabricate sources.</li> <li>Provenance: Cite reputable sources; record n/a for missing PubDate.</li> </ul>"},{"location":"temp-prompts-organized/30-refactor/perf/compare-outputs.perf/","title":"Compare Outputs","text":"<p>Trigger: /compare-outputs</p> <p>Purpose: Run multiple models or tools on the same prompt and summarize best output.</p>"},{"location":"temp-prompts-organized/30-refactor/perf/compare-outputs.perf/#steps","title":"Steps","text":"<ol> <li>Define evaluation prompts and expected properties.</li> <li>Record outputs from each model/tool with metadata.</li> <li>Score using a rubric: correctness, compile/run success, edits required.</li> <li>Recommend a winner and suggested settings.</li> </ol>"},{"location":"temp-prompts-organized/30-refactor/perf/compare-outputs.perf/#output-format","title":"Output format","text":"<ul> <li>Matrix comparison and a one-paragraph decision.</li> </ul>"},{"location":"temp-prompts-organized/30-refactor/perf/model-evaluation.perf/","title":"Model Evaluation","text":"<p>Trigger: /model-evaluation</p> <p>Purpose: Try a new model and compare outputs against a baseline.</p>"},{"location":"temp-prompts-organized/30-refactor/perf/model-evaluation.perf/#steps","title":"Steps","text":"<ol> <li>Define a benchmark set from recent tasks.</li> <li>Run candidates and collect outputs and metrics.</li> <li>Analyze failures and summarize where each model excels.</li> </ol>"},{"location":"temp-prompts-organized/30-refactor/perf/model-evaluation.perf/#output-format","title":"Output format","text":"<ul> <li>Summary table and recommendations to adopt or not.</li> </ul>"},{"location":"temp-prompts-organized/30-refactor/perf/model-strengths.perf/","title":"Model Strengths","text":"<p>Trigger: /model-strengths</p> <p>Purpose: Choose model per task type.</p>"},{"location":"temp-prompts-organized/30-refactor/perf/model-strengths.perf/#steps","title":"Steps","text":"<ol> <li>Classify task: UI, API, data, testing, docs, refactor.</li> <li>Map historical success by model.</li> <li>Recommend routing rules and temperatures.</li> </ol>"},{"location":"temp-prompts-organized/30-refactor/perf/model-strengths.perf/#output-format","title":"Output format","text":"<ul> <li>Routing guide with examples.</li> </ul>"},{"location":"temp-prompts-organized/30-refactor/refactor/adr-new.refactor/","title":"ADR \u2013 new","text":"<p>{$2 or Inferred Name}</p> <p>You are a CLI assistant to draft an Architecture Decision Record with pros/cons using the following inputs:</p> <ol> <li>Analyze project context from $1.</li> <li>Generate a concise ADR with Context, Decision, Status, Consequences. Title: $3.</li> <li>Synthesize insights into the output format with clear priorities and next steps.</li> </ol> <p>Output Requirements: - Provide a summary restating the goal. - Highlight $4, $5, and $6. - Document $7 to ensure maintainability.</p> <p>Example Input: $2</p> <p>Expected Output: Actionable summary aligned with output requirements.</p>"},{"location":"temp-prompts-organized/30-refactor/refactor/file-modularity.refactor/","title":"File Modularity","text":"<p>Trigger: /file-modularity</p> <p>Purpose: Enforce smaller files and propose safe splits for giant files.</p>"},{"location":"temp-prompts-organized/30-refactor/refactor/file-modularity.refactor/#steps","title":"Steps","text":"<ol> <li>Find files over thresholds (e.g., &gt;500 lines).</li> <li>Suggest extraction targets: components, hooks, utilities, schemas.</li> <li>Provide before/after examples and import updates.</li> </ol>"},{"location":"temp-prompts-organized/30-refactor/refactor/file-modularity.refactor/#output-format","title":"Output format","text":"<ul> <li>Refactor plan with patches for file splits.</li> </ul>"},{"location":"temp-prompts-organized/30-refactor/refactor/prettier-adopt-migration-report.refactor/","title":"Prettier adopt migration","text":"<p>You are a CLI assistant focused on helping contributors with the task: Plan a Prettier adoption or migration with minimal churn.</p> <ol> <li>Gather context by inspecting <code>package.json</code>; running <code>git ls-files '*.*' | sed -n '1,400p'</code>.</li> <li>Given the files and package.json, propose a rollout plan and ignore patterns.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Plan a Prettier adoption or migration with minimal churn.</li> <li>Offer prioritized, actionable recommendations with rationale.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p> <ul> <li>Structured report following the specified sections.</li> </ul>"},{"location":"temp-prompts-organized/30-refactor/refactor/refactor-file.refactor/","title":"Refactor file","text":"<p>You are a CLI assistant focused on helping contributors with the task: Suggest targeted refactors for a single file.</p> <ol> <li>Gather context by running <code>sed -n '1,400p' {{args}}</code> for the first 400 lines of the file.</li> <li>Suggest refactors that reduce complexity and improve readability without changing behavior. Provide before/after snippets.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Suggest targeted refactors for a single file.</li> <li>Include before/after snippets or diffs with commentary.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: src/components/Button.tsx</p> <p>Expected Output:</p> <ul> <li>Refactor proposal extracting shared styling hook with before/after snippet.</li> </ul>"},{"location":"temp-prompts-organized/30-refactor/refactor-candidates/dead-code-scan.refactor-candidates/","title":"Dead Code Scan","text":"<p>Trigger: /dead-code-scan</p> <p>Purpose: Identify likely dead or unused files and exports using static signals.</p> <p>You are a CLI assistant focused on helping contributors with the task: List likely dead or unused files and exports (static signals).</p> <ol> <li>Gather context by running <code>rg -n \"export |module.exports|exports\\.|require\\(|import \" -g '!node_modules' .</code> for the file reference graph (best\u2011effort).</li> <li>From the search results, hypothesize dead code candidates and how to safely remove them.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: List likely dead or unused files and exports (static signals).</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p> <ul> <li>Structured report following the specified sections.</li> </ul>"},{"location":"temp-prompts-organized/30-refactor/refactor-candidates/migration-plan.refactor-candidates/","title":"Migration Plan","text":"<p>Trigger: /migration-plan \"\" <p>Purpose: Produce safe up/down migration steps with checks and rollback notes.</p> <p>Steps:</p> <ol> <li>Describe current vs target schema, include data volume and lock risk.</li> <li>Plan: deploy empty columns, backfill, dual-write, cutover, cleanup.</li> <li>Provide SQL snippets and PR checklist. Add <code>can_rollback: true|false</code> flag.</li> </ol> <p>Output format: <code>Plan</code>, <code>SQL</code>, <code>Rollback</code>, <code>Checks</code> sections.</p> <p>Examples: <code>/migration-plan \"orders add status enum\"</code>.</p> <p>Notes: Include online migration strategies for large tables.</p>"},{"location":"temp-prompts-organized/30-refactor/refactor-candidates/refactor-suggestions.refactor-candidates/","title":"Refactor Suggestions","text":"<p>Trigger: /refactor-suggestions</p> <p>Purpose: Propose repo-wide refactoring opportunities after tests exist.</p>"},{"location":"temp-prompts-organized/30-refactor/refactor-candidates/refactor-suggestions.refactor-candidates/#steps","title":"Steps","text":"<ol> <li>Map directory structure and large files.</li> <li>Identify duplication, data clumps, and god objects.</li> <li>Suggest phased refactors with safety checks and tests.</li> </ol>"},{"location":"temp-prompts-organized/30-refactor/refactor-candidates/refactor-suggestions.refactor-candidates/#output-format","title":"Output format","text":"<ul> <li>Ranked list with owners and effort estimates.</li> </ul>"},{"location":"temp-prompts-organized/40-testing/coverage/guide.coverage/","title":"Coverage Guide","text":"<p>Trigger: /coverage-guide</p> <p>Purpose: Propose high-ROI tests to raise coverage using uncovered areas.</p> <p>You are a CLI assistant focused on helping contributors with the task: Suggest a plan to raise coverage based on uncovered areas.</p> <ol> <li>Gather context by running <code>find . -name 'coverage*' -type f -maxdepth 3 -print -exec head -n 40 {} \\; 2&gt;/dev/null</code> for the coverage hints; running <code>git ls-files | sed -n '1,400p'</code> for the repo map.</li> <li>Using coverage artifacts (if available) and repository map, propose the highest\u2011ROI tests to add.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Suggest a plan to raise coverage based on uncovered areas.</li> <li>Offer prioritized, actionable recommendations with rationale.</li> <li>Call out test coverage gaps and validation steps.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p> <ul> <li>Focus on src/auth/login.ts \u2014 0% branch coverage; add error path test.</li> </ul>"},{"location":"temp-prompts-organized/40-testing/coverage/regression-guard.coverage/","title":"Regression Guard","text":"<p>Trigger: /regression-guard</p> <p>Purpose: Detect unrelated changes and add tests to prevent regressions.</p>"},{"location":"temp-prompts-organized/40-testing/coverage/regression-guard.coverage/#steps","title":"Steps","text":"<ol> <li>Run <code>git diff --name-status origin/main...HEAD</code> and highlight unrelated files.</li> <li>Propose test cases that lock current behavior for touched modules.</li> <li>Suggest CI checks to block large unrelated diffs.</li> </ol>"},{"location":"temp-prompts-organized/40-testing/coverage/regression-guard.coverage/#output-format","title":"Output format","text":"<ul> <li>Report with file groups, risk notes, and test additions.</li> </ul>"},{"location":"temp-prompts-organized/40-testing/coverage/regression-guard.coverage/#notes","title":"Notes","text":"<ul> <li>Keep proposed tests minimal and focused.</li> </ul>"},{"location":"temp-prompts-organized/40-testing/fix-flakes/error-analysis.fix-flakes/","title":"Error Analysis","text":"<p>Trigger: /error-analysis</p> <p>Purpose: Analyze error logs and enumerate likely root causes with fixes.</p>"},{"location":"temp-prompts-organized/40-testing/fix-flakes/error-analysis.fix-flakes/#steps","title":"Steps","text":"<ol> <li>Collect last test logs or application stack traces if present.</li> <li>Cluster errors by symptom. For each cluster list 2\u20133 plausible causes.</li> <li>Propose instrumentation or inputs to disambiguate.</li> <li>Provide minimal patch suggestions and validation steps.</li> </ol>"},{"location":"temp-prompts-organized/40-testing/fix-flakes/error-analysis.fix-flakes/#output-format","title":"Output format","text":"<ul> <li>Table: error \u2192 likely causes \u2192 next checks \u2192 candidate fix.</li> </ul>"},{"location":"temp-prompts-organized/40-testing/fix-flakes/error-analysis.fix-flakes/#examples","title":"Examples","text":"<ul> <li>\"TypeError: x is not a function\" \u2192 wrong import, circular dep, stale build.</li> </ul>"},{"location":"temp-prompts-organized/40-testing/fix-flakes/explain-failures.fix-flakes/","title":"Explain failures","text":"<p>You are a CLI assistant focused on helping contributors with the task: Analyze recent test failures and propose fixes.</p> <ol> <li>Gather context by running <code>ls -1 test-results 2&gt;/dev/null || echo 'no test-results/ directory'</code> for the recent test output (if present); running <code>find . -maxdepth 2 -name 'junit*.xml' -o -name 'TEST-*.xml' -o -name 'last-test.log' -print -exec tail -n 200 {} \\; 2&gt;/dev/null</code> for the recent test output (if present).</li> <li>From the following logs, identify root causes and propose concrete fixes.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Analyze recent test failures and propose fixes.</li> <li>Offer prioritized, actionable recommendations with rationale.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p> <ul> <li>Structured report following the specified sections.</li> </ul>"},{"location":"temp-prompts-organized/40-testing/gen-tests/check.gen-tests/","title":"Check","text":"<p>You are a CLI assistant focused on helping contributors with the task: Check adherence to .editorconfig across the repo.</p> <ol> <li>Gather context by inspecting <code>.editorconfig</code>; running <code>git ls-files | sed -n '1,400p'</code>.</li> <li>From the listing and config, point out inconsistencies and propose fixes.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Check adherence to .editorconfig across the repo.</li> <li>Offer prioritized, actionable recommendations with rationale.</li> <li>Highlight workflow triggers, failing jobs, and proposed fixes.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p> <ul> <li>Structured report following the specified sections.</li> </ul>"},{"location":"temp-prompts-organized/40-testing/gen-tests/integration-test.gen-tests/","title":"Integration Test","text":"<p>Trigger: /integration-test</p> <p>Purpose: Generate E2E tests that simulate real user flows.</p>"},{"location":"temp-prompts-organized/40-testing/gen-tests/integration-test.gen-tests/#steps","title":"Steps","text":"<ol> <li>Detect framework from <code>package.json</code> or repo (Playwright/Cypress/Vitest).</li> <li>Identify critical path scenarios from <code>PLAN.md</code>.</li> <li>Produce test files under <code>e2e/</code> with arrange/act/assert and selectors resilient to DOM changes.</li> <li>Include login helpers and data setup. Add CI commands.</li> </ol>"},{"location":"temp-prompts-organized/40-testing/gen-tests/integration-test.gen-tests/#output-format","title":"Output format","text":"<ul> <li>Test files with comments and a README snippet on how to run them.</li> </ul>"},{"location":"temp-prompts-organized/40-testing/gen-tests/integration-test.gen-tests/#examples","title":"Examples","text":"<ul> <li>Login, navigate to dashboard, create record, assert toast.</li> </ul>"},{"location":"temp-prompts-organized/40-testing/gen-tests/integration-test.gen-tests/#notes","title":"Notes","text":"<ul> <li>Prefer data-test-id attributes. Avoid brittle CSS selectors.</li> </ul>"},{"location":"temp-prompts-organized/40-testing/test-plan/e2e-runner-setup.test-plan/","title":"E2E Runner Setup","text":"<p>Trigger: /e2e-runner-setup  <p>Purpose: Configure an end-to-end test runner with fixtures and a data sandbox.</p> <p>Steps:</p> <ol> <li>Install runner and add config with baseURL, retries, trace/videos on retry only.</li> <li>Create fixtures for auth, db reset, and network stubs. Add <code>test:serve</code> script.</li> <li>Provide CI job that boots services, runs E2E, uploads artifacts.</li> </ol> <p>Output format: file list, scripts, and CI snippet fenced code block.</p> <p>Examples: <code>/e2e-runner-setup playwright</code>.</p> <p>Notes: Keep runs under 10 minutes locally; parallelize spec files.</p>"},{"location":"temp-prompts-organized/40-testing/test-plan/query-set.test-plan/","title":"High-Yield Query Generator","text":"<p>Trigger: /query-set</p> <p>Purpose: Generate 4\u20138 targeted web search queries with operators, entity variants, and recency filters for a given objective.</p> <p>Steps:</p> <ol> <li>Restate the goal with entities and time window.</li> <li>Produce queries using operators: site:, filetype:, inurl:, quotes, OR, date filters.</li> <li>Include synonyms and common misspellings.</li> <li>Mix intents: define, compare, integrate, configure, limitations, pricing, API, case study.</li> </ol> <p>Output format:</p> <pre><code>### Goal\n{1 sentence}\n\n### Query Set\n- {Q1}\n- {Q2}\n- \u2026 up to 8\n</code></pre> <p>Examples:</p> <ul> <li>Input: <code>/query-set \"OpenAI Responses API streaming server-sent events\" past year</code></li> <li>Output: Goal + 6\u20138 queries with operators.</li> </ul> <p>Notes:</p> <ul> <li>No evidence logging here. Use /research-item to execute.</li> </ul>"},{"location":"temp-prompts-organized/40-testing/test-plan/secrets-scan.test-plan/","title":"Secrets scan","text":"<p>You are a CLI assistant focused on helping contributors with the task: Review secret scan output and highlight real leaks.</p> <ol> <li>Gather context by running <code>gitleaks detect --no-banner --redact 2&gt;/dev/null || echo 'gitleaks not installed'</code> for the if gitleaks is available, output will appear below.</li> <li>Interpret the scanner results, de\u2011dupe false positives, and propose rotations/remediation.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Review secret scan output and highlight real leaks.</li> <li>Offer prioritized, actionable recommendations with rationale.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p> <ul> <li>Structured report following the specified sections.</li> </ul>"},{"location":"temp-prompts-organized/50-docs/api-docs/api-docs-local.api-docs/","title":"API Docs Local","text":"<p>Trigger: /api-docs-local</p> <p>Purpose: Fetch API docs and store locally for offline, deterministic reference.</p>"},{"location":"temp-prompts-organized/50-docs/api-docs/api-docs-local.api-docs/#steps","title":"Steps","text":"<ol> <li>Create <code>docs/apis/</code> directory.</li> <li>For each provided URL or package, write retrieval commands (curl or <code>npm view</code> docs links). Do not fetch automatically without confirmation.</li> <li>Add <code>DOCS.md</code> index linking local copies.</li> </ol>"},{"location":"temp-prompts-organized/50-docs/api-docs/api-docs-local.api-docs/#output-format","title":"Output format","text":"<ul> <li>Command list and file paths to place docs under <code>docs/apis/</code>.</li> </ul>"},{"location":"temp-prompts-organized/50-docs/api-docs/openapi-generate.api-docs/","title":"OpenAPI Generate","text":"<p>Trigger: /openapi-generate  <p>Purpose: Generate server stubs or typed clients from an OpenAPI spec.</p> <p>Steps:</p> <ol> <li>Validate <code>&lt;spec-path&gt;</code>; fail with actionable errors.</li> <li>For <code>server</code>, generate controllers, routers, validation, and error middleware into <code>apps/api</code>.</li> <li>For <code>client</code>, generate a typed SDK into <code>packages/sdk</code> with fetch wrapper and retry/backoff.</li> <li>Add <code>make generate-api</code> or <code>pnpm sdk:gen</code> scripts and CI step to verify no drift.</li> <li>Produce a diff summary and TODO list for unimplemented handlers.</li> </ol> <p>Output format: summary table of generated paths, scripts to add, and next actions.</p> <p>Examples: <code>/openapi-generate client ts apis/auth/openapi.yaml</code>.</p> <p>Notes: Prefer openapi-typescript + zod for TS clients when possible.</p>"},{"location":"temp-prompts-organized/50-docs/doc-plan/gemini-map.doc-plan/","title":"Gemini map","text":"<p>You are a translator that converts a Gemini CLI TOML command into a Codex prompt file.</p> <p>Steps:</p> <p>1) Read TOML with <code>description</code> and <code>prompt</code>. 2) Extract the task, inputs, and outputs implied by the TOML. 3) Write a Codex prompt file \u2264 300 words:</p> <pre><code>- Role line `You are ...`\n- Numbered steps\n- Output section\n- Example input and expected output\n- `Usage: /&lt;command&gt;` line\n- YAML-like metadata at top\n</code></pre> <p>4) Choose a short, hyphenated filename \u2264 32 chars. 5) Emit a ready-to-run bash snippet: <code>cat &gt; ~/.codex/prompts/&lt;filename&gt;.md &lt;&lt; 'EOF'</code> \u2026 <code>EOF</code>. 6) Do not include destructive commands or secrets.</p> <p>Example input:</p> <p>```toml description = \"Draft a PR description\" prompt = \"Create sections Summary, Context, Changes from diff stats\" Expected output:</p> <p>A pr-desc.md file with the structure above and a bash cat &gt; block.</p> <p>Usage: /gemini-map</p>"},{"location":"temp-prompts-organized/50-docs/doc-plan/owners.doc-plan/","title":"Owners","text":"<p>Trigger: /owners  <p>Purpose: Suggest likely owners or reviewers for the specified path.</p> <p>You are a CLI assistant focused on helping contributors with the task: Suggest likely owners/reviewers for a path.</p> <ol> <li>Gather context by inspecting <code>.github/CODEOWNERS</code> for the codeowners (if present); running <code>git log --pretty='- %an %ae: %s' -- {{args}} | sed -n '1,50p'</code> for the recent authors for the path.</li> <li>Based on CODEOWNERS and git history, suggest owners.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Suggest likely owners/reviewers for a path.</li> <li>Reference evidence from CODEOWNERS or git history for each owner suggestion.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: src/components/Button.tsx</p> <p>Expected Output:</p> <ul> <li>Likely reviewers: @frontend-team (CODEOWNERS), @jane (last 5 commits).</li> </ul>"},{"location":"temp-prompts-organized/50-docs/examples/api-usage.examples/","title":"API usage","text":"<p>You are a CLI assistant focused on helping contributors with the task: Show how an internal API is used across the codebase.</p> <ol> <li>Gather context by running <code>rg -n {{args}} . || grep -RIn {{args}} .</code>.</li> <li>Summarize common usage patterns and potential misuses for the symbol.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Show how an internal API is used across the codebase.</li> <li>Organize details under clear subheadings so contributors can scan quickly.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: HttpClient</p> <p>Expected Output:</p> <ul> <li>Definition: src/network/httpClient.ts line 42</li> <li>Key usages: services/userService.ts, hooks/useRequest.ts</li> </ul>"},{"location":"temp-prompts-organized/50-docs/examples/reference-implementation.examples/","title":"Reference Implementation","text":"<p>Trigger: /reference-implementation</p> <p>Purpose: Mimic the style and API of a known working example.</p>"},{"location":"temp-prompts-organized/50-docs/examples/reference-implementation.examples/#steps","title":"Steps","text":"<ol> <li>Accept a path or URL to an example. Extract its public API and patterns.</li> <li>Map target module\u2019s API to the reference.</li> <li>Generate diffs that adopt the same structure and naming.</li> </ol>"},{"location":"temp-prompts-organized/50-docs/examples/reference-implementation.examples/#output-format","title":"Output format","text":"<ul> <li>Side-by-side API table and patch suggestions.</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/from-commits.changelog/","title":"Draft CHANGELOG From Commits","text":"<p>Trigger: /changelog-from-commits</p> <p>Purpose: Produce a first-draft six-section CHANGELOG block from commit messages and PR titles between two refs.</p> <p>Steps:</p> <ol> <li>Inputs: <code>since=&lt;ref or tag&gt;</code> optional, <code>until=&lt;ref&gt;</code> default HEAD, <code>include_prs=true|false</code> default true.</li> <li>Gather data with:</li> <li><code>git log --pretty=%H%x09%s%x09%b &lt;since&gt;.. &lt;until&gt;</code></li> <li>If available, <code>gh pr view</code> for merged PR titles by commit SHA; else rely on merge commit subjects.</li> <li>Heuristics:</li> <li>Map types: <code>feat|add</code>\u2192Added, <code>fix|bug</code>\u2192Fixed, <code>perf|refactor|opt</code>\u2192Changed, <code>deprecate</code>\u2192Deprecated, <code>remove|drop</code>\u2192Removed, <code>sec|cve|security</code>\u2192Security.</li> <li>Shorten to 12\u201380 chars. Strip scope parentheses.</li> <li>Emit Markdown with only non-empty sections and a short preface noting the range.</li> </ol> <p>Output format:</p> <ul> <li>Range preface line</li> <li>Six-section Markdown block</li> </ul> <p>Examples: Input \u2192 <code>/changelog-from-commits since=v2.0.0 until=HEAD</code> Output \u2192</p> <pre><code>Range: v2.0.0..HEAD\n\n### Added\n- Import data from XLSX (#612)\n\n### Fixed\n- Correct null check in OAuth callback (#615)\n</code></pre> <p>Notes:</p> <ul> <li>This is a draft; run <code>/update-changelog</code> to finalize and create links.</li> <li>Keep bullets user-facing; avoid internal refactor noise.</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/project.changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning when applicable.</p>"},{"location":"temp-prompts-organized/60-release/changelog/project.changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"temp-prompts-organized/60-release/changelog/project.changelog/#added","title":"Added","text":"<ul> <li>Introduce interactive <code>prompts scaffold &lt;slug&gt;</code> command for creating and managing prompt metadata</li> <li>Add prompt scaffolding workflow and metadata guardrails</li> <li>Add task enrichment pipeline to augment task data during ingestion</li> <li>Add local script execution tools (<code>workflow_run_script</code>, <code>workflow_run_task_action</code>, <code>workflow_run_tests</code>, <code>workflow_run_build</code>, <code>workflow_run_lint</code>; originally published with <code>workflow/</code> prefixes)</li> <li>Add abstraction layer for LLM providers</li> <li>Add <code>--verbose</code> and <code>--unsafe-logs</code> flags to CLI and MCP server for improved observability</li> <li>Add <code>docs/client_setup.md</code> and <code>docs/observability.md</code></li> <li>Add new <code>@prompts/tools</code> package to expose core task management logic</li> <li>Implement a stateful workflow engine with a dedicated CLI and MCP server</li> <li>Introduce structured research and planning workflow with new prompt tools</li> <li>Add a comprehensive CLI and MCP server guide</li> <li>Introduce Task-Master CLI and MCP server</li> <li>Implement Task-Master ingest adapter with schema validation and status normalization</li> <li>Implement Jest testing framework and define a canonical JSON schema for tasks</li> <li>Rebaseline project with a new Product Requirements Document (PRDv2) for Task-Master interoperability</li> <li>Introduce Task-Master state engine and a suite of <code>/tm-*</code> slash commands</li> <li>Add <code>/plan-delta</code> prompt for mid-project planning changes</li> <li>Prepare for initial npm publish by updating <code>package.json</code> and adding a release runbook</li> <li>Complete and verify the CLI distribution workflow</li> <li>Introduce <code>prompts</code> CLI for workflow management</li> <li>Add <code>/docfetch-check</code> prompt to enforce documentation freshness</li> <li>Implement a graph-based workflow planner and state management engine</li> <li>Dynamically register prompts from YAML as executable MCP tools</li> <li>Implement a robust <code>StateStore</code> for managing project state</li> <li>Implement a dynamic, stateful prompt workflow and automation engine</li> <li>Initialize project tasks from a Product Requirements Document (PRD)</li> <li>Add initial Product Requirements Document (PRD) for the prompt pack</li> <li>Add research report for building a proactive workflow assistant</li> <li>Automate README table generation from the prompt catalog</li> <li>Add a script to build the prompt catalog</li> <li>Add trigger and purpose metadata to prompts</li> <li>Add a guide for converting prompt libraries into MCP servers</li> <li>Document <code>actions.json</code> mapping format for <code>workflow_run_task_action</code> (formerly <code>workflow/run_task_action</code>) and add sample file under <code>examples/actions.json</code>. Clarifies default lookup, <code>actionsPath</code> override, and execution gating via <code>--exec-enabled</code> + allowlist.</li> <li>CI: add pack contents check to ensure <code>schemas/</code> and <code>dist/mcp/server.js</code> are included in the npm package (GitHub Actions + verify-pack-contains.mjs).</li> <li>Add <code>workflow_run_lint</code> tool paralleling test/build wrappers (initially published as <code>workflow/run_lint</code>); register on server; document in docs/mcp-cli.md; add integration tests for dry-run and exec-gate behaviour.</li> <li>Tests: add live execution test for <code>workflow_run_script</code> with <code>PROMPTS_EXEC_ALLOW=1</code> using allowlisted <code>noop</code> script.</li> <li>Introduce the MCP workflow assistant concept</li> <li>Add lifecycle metadata front matter to prompts and a validator script</li> <li>Implement a dynamic router for documentation MCP servers</li> <li>Add a future enhancements roadmap</li> <li>Add <code>/prd-generate</code> prompt to create a PRD from a README</li> <li>Introduce a self-contained MCP server for managing and serving prompts</li> <li>Add <code>/pr-desc</code> prompt for generating pull request descriptions</li> <li>Integrate Task Master AI for managing agentic workflows</li> <li>Implement a structured instruction and execution framework for the agent</li> <li>Add a comprehensive set of prompts for building an application from scratch</li> <li>Introduce a comprehensive end-to-end development workflow guide</li> <li>Define an end-to-end application development workflow document</li> <li>Add full reference implementation documentation for a Prompts MCP server</li> <li>Add <code>GEMINI.md</code> and <code>AGENTS.md</code> for project context</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/project.changelog/#changed","title":"Changed","text":"<ul> <li>Update <code>package.json</code> for public publishing and modernize <code>tsconfig.json</code> to use <code>NodeNext</code> module resolution</li> <li>Rename workflow execution tools to use underscores (e.g. <code>workflow_run_script</code>) for compatibility with OpenAI tool name validation.</li> <li><code>workflow_run_task_action</code> (formerly <code>workflow/run_task_action</code>) now resolves actions from a new <code>actions.json</code> file</li> <li>Centralize state management into a new <code>TaskService</code></li> <li>Implement batched memory updates for the agent, synchronized with Task Master status</li> <li>Update README with usage examples and server launch instructions</li> <li>Update <code>AGENTS.md</code> with Task Master integration guides</li> <li>Formalize PRD in Markdown and refactor research log</li> <li>Implement a more efficient batched memory update system for the agent</li> <li>Improve prompt metadata validation with <code>zod</code> and <code>glob</code></li> <li>Automate workflow phase synchronization</li> <li>Describe catalog maintenance workflow in documentation</li> <li>Align <code>generate</code> prompt with unit test workflow</li> <li>Clarify commit assistant workflow in documentation</li> <li>Update README to clarify <code>/gemini-map</code> usage</li> <li>Update <code>/audit</code> prompt for direct slash command usage</li> <li>Align prompts with the gated lifecycle workflow</li> <li>Refactor agent's instructional context and planning artifacts with a formal PRD</li> <li>Overhaul and categorize the prompt catalog in the README</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/project.changelog/#deprecated","title":"Deprecated","text":"<ul> <li>Deprecate previous prompt-authoring workstream as part of PRDv2 rebaseline</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/project.changelog/#removed","title":"Removed","text":"<ul> <li>Revert prompt scaffolding workflow and metadata guardrails</li> <li>Remove the automated documentation maintenance flow in favor of a dynamic router</li> <li>Remove obsolete workflow and PRD documentation</li> <li>Remove duplicate <code>/pr-desc</code> prompt</li> <li>Delete old <code>PRD-v2.txt</code> file</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/project.changelog/#fixed","title":"Fixed","text":"<ul> <li>Correct the Zod schema for the <code>advance_state</code> tool's <code>outputs</code> field to prevent JSON schema generation errors</li> <li>Make schema path resolution more robust</li> <li>Consolidate and fix the test suite to run via Jest</li> <li>Correct test limit for multi-byte character truncation</li> <li>Improve payload capping logic for UTF-8 character boundaries and edge cases</li> <li>Correct Mermaid syntax in workflow diagrams</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/project.changelog/#security","title":"Security","text":"<ul> <li>Placeholder for upcoming changes.</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/project.changelog/#010-2025-09-22","title":"[0.1.0] - 2025-09-22","text":""},{"location":"temp-prompts-organized/60-release/changelog/project.changelog/#added_1","title":"Added","text":"<ul> <li>MCP/acidic_soil_prompts_integration_rollup_2025_09_21_america_chicago.md</li> <li>cross-check.md</li> <li>evidence-capture.md</li> <li>query-set.md</li> <li>research-batch.md</li> <li>research-item.md</li> <li>roll-up.md</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/release-notes-prepare.changelog/","title":"Prepare Release Notes From CHANGELOG","text":"<p>Trigger: /release-notes-prepare</p> <p>Purpose: Convert the latest CHANGELOG section into release notes suitable for GitHub Releases with the six-section layout.</p> <p>Steps:</p> <ol> <li>Detect latest version heading and extract its section.</li> <li>Normalize bullets to sentence fragments without trailing periods.</li> <li>Add short highlights at top (3 bullets max) derived from Added/Changed.</li> <li>Emit a \"copy-ready\" Markdown body.</li> </ol> <p>Output format:</p> <ul> <li>Title line: <code>Release X.Y.Z \u2014 YYYY-MM-DD</code></li> <li>Highlights list</li> <li>Six sections with bullets</li> </ul> <p>Examples: Input \u2192 <code>/release-notes-prepare</code> Output \u2192</p> <pre><code>Release 1.6.0 \u2014 2025-09-22\n\n**Highlights**\n- Custom roles and permissions\n- Faster cold starts\n\n### Added\n- Role-based access control\n</code></pre> <p>Notes:</p> <ul> <li>Strictly derived from <code>CHANGELOG.md</code>. Do not invent content.</li> <li>If no version is found, fall back to Unreleased with a warning.</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/release-notes.changelog/","title":"Release Notes","text":"<p>Trigger: /release-notes  <p>Purpose: Generate human-readable release notes from recent commits.</p> <p>You are a CLI assistant focused on helping contributors with the task: Generate human\u2011readable release notes from recent commits.</p> <ol> <li>Gather context by running <code>git log --pretty='* %s (%h) \u2014 %an' --no-merges {{args}}</code> for the commit log (no merges).</li> <li>Produce release notes grouped by type (feat, fix, perf, docs, refactor, chore). Include a Highlights section and a full changelog list.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Generate human\u2011readable release notes from recent commits.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: src/example.ts</p> <p>Expected Output:</p>"},{"location":"temp-prompts-organized/60-release/changelog/release-notes.changelog/#features","title":"Features","text":"<ul> <li>Add SSO login flow (PR #42)</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/release-notes.changelog/#fixes","title":"Fixes","text":"<ul> <li>Resolve logout crash (PR #57)</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/update.changelog/","title":"Update CHANGELOG","text":"<p>Trigger: /update-changelog</p> <p>Purpose: Generate a user-facing CHANGELOG entry for the latest merge range and insert under the correct version or Unreleased with the six standard sections.</p> <p>Steps:</p> <ol> <li>Inspect repo state:</li> <li>Detect current branch and latest tag: <code>git describe --tags --abbrev=0</code>.</li> <li>Identify range: <code>${SINCE:-&lt;latest-tag&gt;}..HEAD</code>. If a merge commit hash or tag is provided, use that.</li> <li>Collect changes:</li> <li>Prefer Conventional Commits in <code>git log --pretty=%s %b</code> over the range.</li> <li>Map commit types to sections: feat\u2192Added, perf/refactor\u2192Changed, deprecate\u2192Deprecated, remove\u2192Removed, fix\u2192Fixed, security\u2192Security.</li> <li>Merge PR titles: <code>git log --merges --pretty=%s</code> and include PR numbers.</li> <li>De-dupe and rewrite:</li> <li>Collapse internal-only chatter. Use terse, user-facing wording. No file paths unless end-user relevant.</li> <li>Keep bullets short. One line each. Present tense. No trailing periods.</li> <li>Emit Markdown snippet with the six sections. Omit empty sections.</li> <li>Decide placement:</li> <li>If a release tag was created in this merge, use <code>## [X.Y.Z] - YYYY-MM-DD</code>.</li> <li>Else place under <code>## [Unreleased]</code>.</li> <li>Provide a unified diff showing insertion into <code>CHANGELOG.md</code>. Do not run it; just output the patch.</li> </ol> <p>Output format:</p> <ul> <li>Heading line with target section (Unreleased or version)</li> <li>Six-section block in Markdown with only non-empty sections in order: Added, Changed, Deprecated, Removed, Fixed, Security</li> <li>A short \"Link references\" block suggestion for <code>[Unreleased]</code> and new version comparison links</li> <li>A unified diff (context 3) for <code>CHANGELOG.md</code></li> </ul> <p>Examples: Input \u2192</p> <pre><code>/update-changelog since=v1.4.2 notes=include-prs\n</code></pre> <p>Output \u2192</p> <pre><code>## [Unreleased]\n### Added\n- Export CSV from reports page (#482)\n\n### Changed\n- Speed up dashboard load times on first visit (#479)\n\n### Fixed\n- Resolve 500 error when saving profile with empty bio (#481)\n\n[Unreleased]: https://github.com/OWNER/REPO/compare/v1.4.2...HEAD\n</code></pre> <p>Notes:</p> <ul> <li>Assumes git repository is available and tags follow SemVer.</li> <li>Keep content end-user focused. Avoid internal file names and refactor notes.</li> <li>If no Conventional Commits, infer section from message heuristics.</li> <li>Do not include secrets or internal ticket links.</li> </ul>"},{"location":"temp-prompts-organized/60-release/changelog/verify.changelog/","title":"Verify CHANGELOG Completeness","text":"<p>Trigger: /changelog-verify</p> <p>Purpose: Check that the latest merge introduced a CHANGELOG entry with the six-section policy and that sections are concise and non-empty where applicable.</p> <p>Steps:</p> <ol> <li>Parse <code>CHANGELOG.md</code> and locate <code>## [Unreleased]</code> or the latest version heading.</li> <li>Validate presence and order of sections: Added, Changed, Deprecated, Removed, Fixed, Security.</li> <li>Flag anti-patterns: paragraphs longer than 2 lines, trailing periods, internal-only jargon, file paths, or empty sections left in place.</li> <li>Cross-check against commits since last tag to detect missing items.</li> <li>Emit a diagnostic report and a suggested patch to fix ordering and brevity issues.</li> </ol> <p>Output format:</p> <ul> <li>\"Status: PASS|FAIL\"</li> <li>Table of findings with line numbers and reasons</li> <li>Suggested normalized Markdown block</li> <li>Unified diff to apply</li> </ul> <p>Examples: Input \u2192 <code>/changelog-verify</code> Output \u2192</p> <pre><code>Status: FAIL\n- L42: Section order incorrect (Found Fixed before Removed)\n- Missing Security section stub\n\nSuggested block:\n### Added\n- Bulk upload for SKUs\n\n### Security\n- Bump OpenSSL to 3.0.14\n</code></pre> <p>Notes:</p> <ul> <li>Static analysis only; no network calls.</li> <li>Treat any section with 0 bullets as removable unless policy requires stubs.</li> </ul>"},{"location":"temp-prompts-organized/60-release/post-release-checks/cleanup-branches.post-release-checks/","title":"Cleanup Branches","text":"<p>Trigger: /cleanup-branches</p> <p>Purpose: Recommend which local branches are safe to delete and which to keep.</p> <p>You are a CLI assistant focused on helping contributors with the task: Suggest safe local branch cleanup (merged/stale).</p> <ol> <li>Gather context by running <code>git branch --merged</code> for the merged into current upstream; running <code>git branch --no-merged</code> for the branches not merged; running <code>git for-each-ref --sort=-authordate --format='%(refname:short) \u2014 %(authordate:relative)' refs/heads</code> for the recently updated (last author dates).</li> <li>Using the lists below, suggest local branches safe to delete and which to keep. Include commands to remove them if desired (DO NOT execute).</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Suggest safe local branch cleanup (merged/stale).</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p> <ul> <li>Structured report following the specified sections.</li> </ul>"},{"location":"temp-prompts-organized/60-release/post-release-checks/license-report.post-release-checks/","title":"License report","text":"<p>You are a CLI assistant focused on helping contributors with the task: Summarize third\u2011party licenses and risk flags.</p> <ol> <li>Gather context by running <code>npx --yes license-checker --summary 2&gt;/dev/null || echo 'license-checker not available'</code> for the if license tools are present, their outputs; inspecting <code>package.json</code> for the if license tools are present, their outputs.</li> <li>Create a license inventory with notices of copyleft/unknown licenses.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Summarize third\u2011party licenses and risk flags.</li> <li>Organize details under clear subheadings so contributors can scan quickly.</li> <li>Flag copyleft or unknown licenses and suggest remediation timelines.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p> <ul> <li>MIT (12) \u2014 low risk</li> <li>GPL-3.0 (1) \u2014 requires legal review</li> </ul>"},{"location":"temp-prompts-organized/60-release/versioning/version-proposal.versioning/","title":"Version Proposal","text":"<p>Trigger: /version-proposal</p> <p>Purpose: Propose the next semantic version based on commit history.</p> <p>You are a CLI assistant focused on helping contributors with the task: Propose next version (major/minor/patch) from commit history.</p> <ol> <li>Gather context by running <code>git describe --tags --abbrev=0</code> for the last tag; running <code>git log --pretty='%s' --no-merges $(git describe --tags --abbrev=0)..HEAD</code> for the commits since last tag (no merges).</li> <li>Given the Conventional Commit history since the last tag, propose the next SemVer and justify why.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Propose next version (major/minor/patch) from commit history.</li> <li>Offer prioritized, actionable recommendations with rationale.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p> <ul> <li>Structured report following the specified sections.</li> </ul>"},{"location":"temp-prompts-organized/_experimental/QA-ready_refactor-plan.experimental/","title":"QA ready refactor plan.experimental","text":"<pre><code>&lt;!--\n$1 = goal\n$2 = scope\n$3 = API contracts to keep stable\n$4 = performance guardrails\n$5 = quality commands pipeline (lint then tests)\n$6 = thresholds (coverage target and per-step change budget for lines and files)\n$7 = per-step details bundle (title, files touched, reused symbols, patch summary, tests, risk, rollback note)\n--&gt;\n\n# {$2 or QA-Ready Refactor Plan}\n\n**Inputs**\n\n- Objective: $1\n- Area: $2\n- Contracts: $3\n- Performance: $4\n- Quality run: $5\n- Thresholds: $6\n\n**Guardrails**\n\n- Reuse first: move, extract, or facade. Avoid new patterns unless justified.\n- Small deltas: each step stays within $6 across limited files.\n- Stability: keep $3 intact; add shims if needed.\n- Gate per step: run $5 then enforce $6.\n\n## 1) Assessment\n\n- Seams within $2\n- Safe extraction points\n- Test gaps to close first\n- Affected files\n- Root cause summary\n- Proposed fix outline\n\n## 2) Stepwise Plan\n\n*For each step i:*\n\n- Name: $7\n- Change type: extract | rename | move | inline | split\n- Files: $7\n- Reuse targets: $7\n- Patch outline: $7\n- Tests to add or update: $7\n- Risk and rollback: $7\n- Validation: run $5 and record result\n\n## 3) Execution Log\n\n- Step i \u2192 status, notes, follow-ups\n\n## 4) Exit Report\n\n- What changed and what stayed invariant\n- Performance check against $4\n- Coverage and thresholds met: $6\n- Open items\n- Docs to update\n\n**Acceptance Criteria**\n\n- All steps pass gates.\n- No ABI/API break beyond approved list for $3.\n- Coverage and limits meet $6.\n\n---\n\n### Output format\n\n- Plan table of steps with $7 fields\n- Minimal diffs per step\n- Test and coverage summary from $5\n- Prune ledger: path | evidence | action | owner\n</code></pre>"},{"location":"temp-prompts-organized/_experimental/ops_apply.experimental/","title":"Ops apply.experimental","text":"<pre><code>&lt;!--\n$1 = plan identifier (string or path/URL)\n$2 = apply mode: \"dry-run\" | \"apply\"\n$3 = step selector: \"all\" | comma list (e.g., \"1,2,5\") | range (e.g., \"3-7\")\n$4 = patch strategy: \"git-apply\" | \"unified-diff\" | \"fs-write\"\n$5 = stop policy: \"fail-fast\" | \"continue-on-error\"\n$6 = artifact dir (e.g., \".ops/artifacts\")\n$7 = notes (optional free text)\n--&gt;\n\n/ops:apply \"$1\" \"$2\" \"$3\" \"$4\" \"$5\" \"$6\" \"$7\"\n\nGoal\n\n- Apply the planned patches stepwise and emit verifiable artifacts. Do not execute build/test commands.\n\nInputs\n\n- Plan: $1  (must resolve to a QA-Ready Refactor Plan doc)\n- Mode: $2\n- Steps: $3\n- Patch strategy: $4\n- Stop policy: $5\n- Artifacts dir: $6\n- Notes: $7\n\nPlan contract (must match):\n\n- Use step schema and gates from the QA-Ready Refactor Plan: name, files, reuse targets, patch outline, tests, risk, validation. Each step stays within thresholds and respects stable contracts.\n\nAlgorithm\n\n1) Load plan $1 and parse step table + $7 fields per step. Validate thresholds and invariant contracts before any write.\n2) Select steps per $3. Preserve original ordering.\n3) For each step i:\n   a) Generate minimal patch from \u201cPatch outline\u201d against listed Files.\n   b) If $2 == \"dry-run\": produce diffs only.\n   c) If $2 == \"apply\": apply using $4.\n   d) Record \u201cExecution Log\u201d entry with status, touched files count, LOC delta, and any deviations from thresholds.\n   e) Emit artifacts: `step-i.diff`, `step-i.patch.json` (metadata), `step-i.report.md`.\n   f) If $5 == \"fail-fast\" and a step violates plan guardrails, stop and mark remaining as pending.\n4) After final step, write `exit-report.md` with what changed vs invariants, perf and coverage placeholders, open items, and docs updates needed. Do not run tests here.\n\nOutputs\n\n- `apply-summary.md`: table of steps \u2192 status, files, LOC, notes.\n- Per-step diffs and metadata under $6.\n- `prune-ledger.md`: path | evidence | action | owner (aggregated from plan).\n\nConstraints\n\n- No shell or node execution. No `pnpm` invocation.\n- Respect stable API/ABI contracts listed in plan.\n- Enforce per-step thresholds before writing.\n\nFallback when no executor exists\n\n- Always succeed in producing diffs and manual apply instructions:\n  - For each step, include a ready-to-run `git apply step-i.diff` and, if not applicable, a file-by-file patch block.\n\nFailure handling\n\n- Produce `apply-error.md` with failing step id, reason, and next actions.\n- If plan structure is invalid, emit `plan-parse-error.md` and exit.\n\nExamples\n\n- Dry run for all steps with unified diffs to `.ops`:\n  /ops:apply \"./plans/refactor-plan.md\" \"dry-run\" \"all\" \"unified-diff\" \"fail-fast\" \".ops\" \"\"\n- Apply steps 1\u20133 using git apply and continue on errors:\n  /ops:apply \"plan-123\" \"apply\" \"1-3\" \"git-apply\" \"continue-on-error\" \".ops\" \"hotfix window\"\n\nNotes\n\n- Pair with `/ops:quality &lt;step-id&gt; \"&lt;commands&gt;\"` to run quality gates separately, e.g.:\n  /ops:quality 2 \"pnpm run lint &amp;&amp; pnpm test &amp;&amp; pnpm run e2e\"\n</code></pre>"},{"location":"temp-prompts-organized/_experimental/ops_quality.experimental/","title":"Ops quality.experimental","text":"<pre><code>&lt;!--\n$1 = target: \"plan-id:step-id\" | \"plan-id:range\" | \"plan-id:all\" | bare step-id(s) (\"2\" or \"1,3-5\")\n$2 = commands string (e.g., \"pnpm run lint &amp;&amp; pnpm test &amp;&amp; pnpm run e2e\")\n$3 = exec driver: \"detect\" | \"local\" | \"codex\" | \"none\" (emit script only)\n$4 = working directory (e.g., \".\")\n$5 = artifacts dir (e.g., \".ops/quality\")\n$6 = timeout seconds per step (e.g., \"3600\")\n$7 = retries on failure per step (e.g., \"0\")\n$8 = parallelism: integer \u22651 (e.g., \"2\")\n$9 = environment: \"inherit\" | path to .env | inline \"KEY=VAL,KEY2=VAL2\"\n--&gt;\n\n/ops:quality \"$1\" \"$2\" \"$3\" \"$4\" \"$5\" \"$6\" \"$7\" \"$8\" \"$9\"\n\nGoal\n\n- Execute step-scoped quality checks and normalize results. Preserve logs and metrics for CI or manual review.\n\nInputs\n\n- Target: $1\n- Commands: $2\n- Driver: $3\n- CWD: $4\n- Artifacts: $5\n- Timeout: $6\n- Retries: $7\n- Parallelism: $8\n- Env: $9\n\nContract\n\n- Read thresholds and gates from the referenced plan steps when present (coverage, lint, perf, memory, LOC caps).\n- Do not modify source files.\n\nAlgorithm\n\n1) Resolve $1 to an ordered step list. Load declared gates for each step when available.\n2) Prepare run context:\n   - Apply env from $9 (merge with inherit if a file is provided).\n   - Ensure $4 exists; create $5 with subdirs per step: `$5/step-&lt;id&gt;/`.\n3) For each step (\u2264 $8 in parallel):\n   a) Compose a POSIX shell script: `set -euo pipefail; $2`.\n   b) If $3 == \"none\": write`run.sh` and skip execution.\n      Else execute via driver ($3). Enforce per-step timeout $6.\n   c) Capture stdout and stderr to `stdout.log` and `stderr.log`.\n   d) Collect common artifacts if present:\n      - JUnit XML \u2192 `junit.xml`\n      - Coverage summaries \u2192 `coverage-summary.json` or `lcov.info`\n      - Lint reports \u2192 `lint.json` or `lint.txt`\n      - Perf/profiling \u2192 `perf.json`\n   e) Evaluate gates against collected artifacts. Compute PASS/FAIL with reasons.\n   f) On failure and retries remaining ($7): rerun with exponential backoff and tag attempt N.\n4) Write `step-report.json` with: timings, attempts, exit code, gate results, and file counts.\n5) Aggregate into `$5/quality-summary.md` and `$5/quality-summary.json`:\n   - step \u2192 status, duration, retries, failing gates, pointers to logs.\n6) Exit non-zero if any mandatory gate fails.\n\nOutputs\n\n- `$5/step-&lt;id&gt;/stdout.log`, `stderr.log`, `run.sh`, `step-report.json`, collected tool artifacts.\n- `$5/quality-summary.md` and `$5/quality-summary.json`.\n- If $3 == \"none\": also emit `manual-run.md` with copy-paste commands and expected artifacts.\n\nConstraints\n\n- No source writes. No network unless commands require it.\n- Respect per-step thresholds from the plan when available; otherwise do best-effort parsing from artifacts.\n- Keep per-step log files \u226410 MB by truncation with notice.\n\nFailure handling\n\n- On driver error or timeout, mark step as ERROR with captured diagnostics; continue other steps.\n- Produce `$5/quality-error.md` summarizing root causes and next actions.\n\nExamples\n\n- Run quality for step 2 with local execution and default env:\n  /ops:quality \"plan-123:2\" \"pnpm run lint &amp;&amp; pnpm test\" \"local\" \".\" \".ops/quality\" \"1800\" \"0\" \"1\" \"inherit\"\n\n- Emit manual script for steps 1\u20133, no execution:\n  /ops:quality \"plan-123:1-3\" \"pnpm run lint &amp;&amp; pnpm test &amp;&amp; pnpm run e2e\" \"none\" \".\" \".ops/quality\" \"3600\" \"0\" \"1\" \".env\"\n\n- Parallel run for all steps with retries:\n  /ops:quality \"plan-123:all\" \"pnpm run -s lint &amp;&amp; pnpm -s test\" \"detect\" \".\" \".ops/quality\" \"2400\" \"1\" \"3\" \"KEY=A,CI=1\"\n</code></pre>"},{"location":"temp-prompts-organized/_shared/rank-root-prompts.shared/","title":"Rank root prompts","text":""},{"location":"temp-prompts-organized/_shared/rank-root-prompts.shared/#context-aware-prompt-ranking-command","title":"{Context-Aware Prompt Ranking Command}","text":"<pre><code># Command: $1\n\n# Usage: $1 \"$2\" \"$3\" \"$4\" \"$5\"\n\n# Args:\n\n# - {{query}}: $2\n# - {{project_path}}: $3\n# - {{prompt_path}}: $4\n# - {{threshold}}: $5\n\nprompt = \"\"\"\nTask:\nGiven a user inquiry ({{query}}) and the context of a software project located at {{project_path}}, your goal is to identify the most relevant prompt-definition file from the directory {{prompt_path}}.\n\nDefaults:\n* If {{project_path}} is missing or blank, use the current working directory.\n* If {{prompt_path}} is missing or blank, use \"~/.codex/prompts\".\n\nDo the following:\n1) **Analyze Project Context**: Recursively scan {{project_path}} to understand its structure, languages, and purpose. Create a concise summary of the project context.\n2) **Scan Prompts**: List all candidate prompt files in {{prompt_path}} (non-recursively).\n3) **Evaluate Prompts**: For each candidate prompt file:\n    a) Read its content.\n    b) Create a one-sentence summary of its purpose and domain.\n    c) Compute a relevance score from 0 to 1. This score must measure how well the prompt's purpose aligns with the user's {{query}}, considering the project context summary. A higher score means the prompt is a better fit for solving the query within the given project.\n4) **Rank and Filter**: Order the prompts by their relevance score in descending order.\n5) **Generate Output**: Emit a compact markdown table with the columns: `filename | description | match_score` (rounded to 2 decimals).\n\nRules:\n* The description must be 1\u20132 sentences capturing the prompt's purpose and domain.\n* Only include prompts in the table where `match_score` is greater than or equal to {{threshold}}.\n* If no prompts meet the threshold, output a single line: \"No prompt exceeds threshold {{threshold}} \u2014 recommend creating a new prompt.\"\n\nAcceptance:\n* If one or more matches meet the {{threshold}}, a markdown table sorted by descending `match_score` is produced.\n* Otherwise, the single-line fallback message is produced.\n\n!{echo \"Scanning project: ${PROJECT_PATH_ARG:-.}\"}\n!{echo \"Searching for prompts in: ${PROMPT_PATH_ARG:-~/.codex/prompts}\"}\n\"\"\"\n</code></pre>"},{"location":"temp-prompts-organized/_shared/rank-root-prompts.shared/#output-format","title":"Output format","text":"<ul> <li>Preferred: a markdown table with columns <code>filename | description | match_score</code> sorted by <code>match_score</code> (desc) and filtered by <code>{{threshold}}</code>.</li> <li>Fallback: the exact one-line message when no entries meet <code>{{threshold}}</code>.</li> </ul>"},{"location":"temp-prompts-organized/_shared/reset-strategy.shared/","title":"Reset Strategy","text":"<p>Trigger: /reset-strategy</p> <p>Purpose: Decide when to hard reset and start clean to avoid layered bad diffs.</p>"},{"location":"temp-prompts-organized/_shared/reset-strategy.shared/#steps","title":"Steps","text":"<ol> <li>Run: <code>git status -sb</code> and <code>git diff --stat</code> to assess churn.</li> <li>If many unrelated edits or failing builds, propose: <code>git reset --hard HEAD</code> to discard working tree.</li> <li>Save any valuable snippets to <code>scratch/</code> before reset.</li> <li>Re-implement the minimal correct fix from a clean state.</li> </ol>"},{"location":"temp-prompts-organized/_shared/reset-strategy.shared/#output-format","title":"Output format","text":"<ul> <li>A short decision note and exact commands. Never execute resets automatically.</li> </ul>"},{"location":"temp-prompts-organized/_shared/reset-strategy.shared/#examples","title":"Examples","text":"<ul> <li>Recommend reset after repeated failing refactors touching 15+ files.</li> </ul>"},{"location":"temp-prompts-organized/_shared/reset-strategy.shared/#notes","title":"Notes","text":"<ul> <li>Warn about destructive nature. Require user confirmation.</li> </ul>"},{"location":"temp-prompts-organized/_shared/roll-up.shared/","title":"Research Roll-up Summary","text":"<p>Trigger: /roll-up</p> <p>Purpose: Summarize per-item statuses, enabled decisions, unresolved risks, and count sources by domain type.</p> <p>Steps:</p> <ol> <li>Aggregate Conversation State Updates from prior items.</li> <li>Produce per-item status lines and decisions.</li> <li>Tally sources by domain type: gov, org, docs, blog, news, academic.</li> </ol> <p>Output format:</p> <pre><code>## Roll-up Summary\n- Item {n}: {status} \u2014 decision enabled: {\u2026}; risks: {\u2026}\n- Sources by domain type: {gov:X, org:Y, docs:Z, blog:A, news:B, academic:C}\n</code></pre> <p>Examples:</p> <ul> <li>Input: <code>/roll-up from items 1\u20133</code></li> <li>Output: Summary block as above.</li> </ul> <p>Notes:</p> <ul> <li>Use counts derived from the Evidence Logs.</li> </ul>"},{"location":"temp-prompts-organized/_shared/summary.shared/","title":"Summary","text":"<p>You are a CLI assistant focused on helping contributors with the task: Produce a README\u2011level summary of the repo.</p> <ol> <li>Gather context by running <code>git ls-files | sed -n '1,400p'</code> for the repo map (first 400 files); inspecting <code>README.md</code> for the key docs if present; inspecting <code>docs</code> for the key docs if present.</li> <li>Generate a high\u2011level summary (What, Why, How, Getting Started).</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Produce a README\u2011level summary of the repo.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p> <ul> <li>Structured report following the specified sections.</li> </ul>"},{"location":"temp-prompts-organized/_shared/switch-model.shared/","title":"Switch Model","text":"<p>Trigger: /switch-model</p> <p>Purpose: Decide when to try a different AI backend and how to compare.</p>"},{"location":"temp-prompts-organized/_shared/switch-model.shared/#steps","title":"Steps","text":"<ol> <li>Define task type: frontend codegen, backend reasoning, test writing, refactor.</li> <li>Select candidate models and temperature/tooling options.</li> <li>Run a fixed input suite and measure latency, compile success, and edits needed.</li> <li>Recommend a model per task with rationale.</li> </ol>"},{"location":"temp-prompts-organized/_shared/switch-model.shared/#output-format","title":"Output format","text":"<ul> <li>Table: task \u2192 model \u2192 settings \u2192 win reason.</li> </ul>"},{"location":"temp-prompts-organized/_shared/tm/advance.tm/","title":"Advance Task(s)","text":"<p>Trigger: /tm-advance</p> <p>Purpose: For given task id(s), produce a concrete work plan, acceptance criteria, tests, and a Conventional Commits message to move status toward done.</p> <p>Steps:</p> <ol> <li>Read tasks.json; resolve each provided id. If none provided, pick the top item from /tm-next.</li> <li>For each task: restate title, goals, and related dependencies.</li> <li>Draft a step-by-step plan with file touch-points and test hooks.</li> <li>Provide a minimal commit plan and a Conventional Commits message with scope and short body.</li> <li>List measurable acceptance criteria.</li> </ol> <p>Output format:</p> <ul> <li>One section per task: \"##  \u2014 \"&lt;/li&gt; &lt;li&gt;Subsections: Plan, Files, Tests, Acceptance, Commit Message (fenced), Risks.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Examples:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Input: /tm-advance TM-42 TM-43&lt;/li&gt; &lt;li&gt;Output: structured sections with a commit message like &lt;code&gt;feat(parser): implement rule X&lt;/code&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Notes:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Do not mutate tasks.json. Emit proposed changes only.&lt;/li&gt; &lt;/ul&gt;"},{"location":"temp-prompts-organized/_shared/tm/blockers.tm/","title":"Blocker Diagnosis","text":"<p>Trigger: /tm-blockers</p> <p>Purpose: Diagnose why a task is blocked and propose the shortest path to unblock it.</p> <p>Steps:</p> <ol> <li>Load tasks.json and the target id.</li> <li>Enumerate unmet dependencies and missing artifacts (tests, docs, approvals).</li> <li>Classify each blocker: dependency, ambiguity, environment, CI, external.</li> <li>Propose 1\u20133 minimal unblocking actions, each with owner, effort, and success check.</li> </ol> <p>Output format:</p> <ul> <li>\"# Blocker Report: \" <li>Tables: blockers (type | item | evidence), actions (step | owner | effort | success_criteria).</li> <p>Examples:</p> <ul> <li>Input: /tm-blockers TM-17</li> <li>Output: two tables and a short narrative under \"Findings\".</li> </ul> <p>Notes:</p> <ul> <li>If the task is not actually blocked, state why and redirect to /tm-advance.</li> </ul>"},{"location":"temp-prompts-organized/_shared/tm/ci.tm/","title":"CI/Test Checklist from Tasks","text":"<p>Trigger: /tm-ci</p> <p>Purpose: Derive a near-term CI and test checklist from ready and in-progress tasks.</p> <p>Steps:</p> <ol> <li>Compute ready tasks (see /tm-next) and collect any testStrategy fields.</li> <li>Group by component or tag if available; otherwise by path keywords in titles.</li> <li>Propose CI jobs and test commands with approximate runtimes and gating rules.</li> <li>Include a smoke-test matrix and minimal code coverage targets if relevant.</li> </ol> <p>Output format:</p> <ul> <li>\"# CI Plan\"</li> <li>Tables: jobs (name | trigger | commands | est_time) and tests (scope | command | expected_artifacts).</li> <li>\"## Risk Areas\" bullets and \"## Follow-ups\".</li> </ul> <p>Examples:</p> <ul> <li>Input: /tm-ci</li> <li>Output: one CI plan with 3\u20138 jobs and a test table.</li> </ul> <p>Notes:</p> <ul> <li>Non-binding guidance. Adapt to the repo\u2019s actual CI system.</li> </ul>"},{"location":"temp-prompts-organized/_shared/tm/delta.tm/","title":"PRD \u2192 Tasks Delta","text":"<p>Trigger: /tm-delta</p> <p>Purpose: Compare a PRD text against tasks.json and propose add/update/remove operations.</p> <p>Steps:</p> <ol> <li>Accept PRD content pasted by the user or a path like ./prd.txt. If absent, output a short template asking for PRD input.</li> <li>Extract objectives, constraints, deliverables, and milestones from the PRD.</li> <li>Map them to existing tasks by fuzzy match on title and keywords; detect gaps.</li> <li>Propose: new tasks, updates to titles/descriptions/priority, and deprecations.</li> </ol> <p>Output format:</p> <ul> <li>\"# Delta Summary\"</li> <li>Tables: adds | updates | removals.</li> <li>\"## JSON Patch\" with an ordered list of operations: add/replace/remove.</li> <li>\"## Assumptions\" and \"## Open Questions\".</li> </ul> <p>Examples:</p> <ul> <li>Input: /tm-delta ./prd.txt</li> <li>Output: tables with a small JSON Patch block.</li> </ul> <p>Notes:</p> <ul> <li>Keep patches minimal and reversible. Flag any destructive changes explicitly.</li> </ul>"},{"location":"temp-prompts-organized/_shared/tm/docs.tm/","title":"Generate Status Docs","text":"<p>Trigger: /tm-docs</p> <p>Purpose: Emit a project status document from tasks.json for README or STATUS.md.</p> <p>Steps:</p> <ol> <li>Parse tasks.json; collect done, in_progress, blocked, and ready_next (per /tm-next logic).</li> <li>Compose a concise narrative: current focus, recent wins, top risks.</li> <li>Produce status boards for each status with id, title, and owner if present.</li> <li>Add a 7-day changelog if timestamps exist; otherwise, summarize recent done items.</li> </ol> <p>Output format:</p> <ul> <li>\"# Project Status \u2014 \" <li>Sections: Summary, Ready Next, In Progress, Blocked, Done, Changelog.</li> <p>Examples:</p> <ul> <li>Input: /tm-docs</li> <li>Output: a single Markdown document suitable for commit as STATUS.md.</li> </ul> <p>Notes:</p> <ul> <li>Avoid leaking secrets. Do not invent owners; omit unknown fields.</li> </ul>"},{"location":"temp-prompts-organized/_shared/tm/next.tm/","title":"Next Ready Tasks","text":"<p>Trigger: /tm-next</p> <p>Purpose: List tasks that are ready to start now (no unmet dependencies), ordered by priority and dependency depth.</p> <p>Steps:</p> <ol> <li>Load tasks.json and build a map of id \u2192 task.</li> <li>A task is ready if status \u2208 {pending, blocked} AND all dependencies are done.</li> <li>Order by: priority desc, then shortest path length to completion, then title.</li> <li>For each ready task, include why it is ready and the prerequisites satisfied.</li> </ol> <p>Output format:</p> <ul> <li>\"# Ready Now\"</li> <li>Table: id | title | priority | why_ready | prereqs</li> <li>\"## Notes\" for tie-break rules and data gaps.</li> </ul> <p>Examples:</p> <ul> <li>Input: /tm-next</li> <li>Output: a table of 5\u201320 items. If none, say \"No ready tasks\" and list nearest-unblock candidates.</li> </ul> <p>Notes:</p> <ul> <li>Treat missing or null priority as 0. If custom scales exist, describe them in Notes.</li> </ul>"},{"location":"temp-prompts-organized/_shared/tm/overview.tm/","title":"TaskMaster Overview","text":"<p>Trigger: /tm-overview</p> <p>Purpose: Summarize the current TaskMaster tasks.json by status, priority, dependency health, and critical path to orient work.</p> <p>Steps:</p> <ol> <li>Locate the active tasks.json at repo root or the path supplied in the user message. Do not modify it.</li> <li>Parse fields: id, title, description, status, priority, dependencies, subtasks.</li> <li>Compute counts per status and a table of top pending items by priority.</li> <li>Detect dependency issues: cycles, missing ids, orphans (no deps and not depended on).</li> <li>Approximate a critical path: longest dependency chain among pending\u2192in_progress tasks.</li> </ol> <p>Output format:</p> <ul> <li>\"# Overview\" then a bullets summary.</li> <li>\"## Totals\" as a 4-column table: status | count | percent | notes.</li> <li>\"## Top Pending\" table: id | title | priority | unblockers.</li> <li>\"## Critical Path\" as an ordered list of ids with short titles.</li> <li>\"## Issues\" list for cycles, missing references, duplicates.</li> </ul> <p>Examples:</p> <ul> <li>Input (Codex TUI): /tm-overview</li> <li>Output: tables and lists as specified. Keep to &lt;= 200 lines.</li> </ul> <p>Notes:</p> <ul> <li>Read-only. Assume statuses: pending | in_progress | blocked | done.</li> <li>If tasks.json is missing or invalid, output an \"## Errors\" section with a concise diagnosis.</li> </ul>"},{"location":"temp-prompts-organized/_shared/tm/refine.tm/","title":"Refine Task into Subtasks","text":"<p>Trigger: /tm-refine</p> <p>Purpose: Expand a vague or large task into actionable subtasks with clear acceptance criteria.</p> <p>Steps:</p> <ol> <li>Load the task by id and analyze description for ambiguity and scope.</li> <li>Propose 3\u20138 subtasks with titles, brief descriptions, and dependencies between them.</li> <li>Define acceptance criteria per subtask using Given/When/Then or bullet checks.</li> <li>Suggest test coverage and doc updates triggered by completion.</li> </ol> <p>Output format:</p> <ul> <li>\"# Refinement: \" <li>Subtasks as a Markdown table: id_suggested | title | depends_on | acceptance.</li> <li>\"## JSON Patch\" fenced code of suggested additions suitable for tasks.json editing.</li> <p>Examples:</p> <ul> <li>Input: /tm-refine TM-09</li> <li>Output: table plus a minimal JSON Patch array.</li> </ul> <p>Notes:</p> <ul> <li>Do not assume authority to change files; provide patches the user can apply.</li> </ul>"},{"location":"temp-prompts-organized/_templates/instruction-file.templates/","title":"Instruction File","text":"<p>Trigger: /instruction-file</p> <p>Purpose: Generate or update <code>cursor.rules</code>, <code>windsurf.rules</code>, or <code>claude.md</code> with project-specific instructions.</p>"},{"location":"temp-prompts-organized/_templates/instruction-file.templates/#steps","title":"Steps","text":"<ol> <li>Scan repo for existing instruction files.</li> <li>Compose sections: Context, Coding Standards, Review Rituals, Testing, Security, Limits.</li> <li>Include \"Reset and re-implement cleanly\" guidance and scope control.</li> <li>Write to chosen file and propose a commit message.</li> </ol>"},{"location":"temp-prompts-organized/_templates/instruction-file.templates/#output-format","title":"Output format","text":"<ul> <li>Markdown instruction file with stable headings.</li> </ul>"},{"location":"temp-prompts-organized/_templates/prompt-sequence-generator.templates/","title":"Prompt: Generate Prompt Execution Sequence","text":"<p>Purpose: Given a high-level goal and a set of available prompts, generate the logical execution sequence required to accomplish that goal by chaining the prompts together.</p>"},{"location":"temp-prompts-organized/_templates/prompt-sequence-generator.templates/#inputs","title":"Inputs","text":"<ul> <li> <p>High-Level Goal: {{high_level_goal}}</p> <ul> <li>A clear, one-sentence description of the final outcome the user wants to achieve.</li> <li>Example: \"Create and document a pull request for the currently staged changes.\"</li> </ul> </li> <li> <p>Available Prompts: <pre><code>{{available_prompts}}\n</code></pre></p> <ul> <li>A list of candidate prompt names (e.g., from the output of <code>rank-root-prompts</code>).</li> <li>Example: ['pr-desc.md', 'commit-msg.md', 'changed-files.md', 'review.md', 'release-notes.md']</li> </ul> </li> <li> <p>Context (Optional): {{context}}</p> <ul> <li>Any additional context, such as the current state of the git repository or specific files of interest.</li> <li>Example: \"The user has already staged files using <code>git add</code>.\"</li> </ul> </li> </ul>"},{"location":"temp-prompts-organized/_templates/prompt-sequence-generator.templates/#instructions-for-the-ai","title":"Instructions for the AI","text":"<ol> <li> <p>Analyze the Goal: Deconstruct the <code>{{high_level_goal}}</code> into a series of logical steps required to get from the starting state to the final outcome.</p> </li> <li> <p>Map Prompts to Steps: For each logical step, identify the most suitable prompt from the <code>{{available_prompts}}</code> list that can perform that step.</p> <ul> <li>Consider the inputs and outputs of each prompt to determine dependencies. A prompt's input is often the output of a previous one.</li> </ul> </li> <li> <p>Establish Order: Arrange the selected prompts into a numbered sequence based on their dependencies. The sequence should represent a complete and logical workflow.</p> </li> <li> <p>Identify Gaps: If any necessary step in the workflow cannot be fulfilled by one of the available prompts, explicitly state what action or prompt is missing.</p> </li> </ol>"},{"location":"temp-prompts-organized/_templates/prompt-sequence-generator.templates/#required-output-format","title":"Required Output Format","text":"<p>Execution Sequence:</p> <ol> <li><code>[prompt_name_1.md]</code>: [Brief justification for why this prompt is first and what it accomplishes.]</li> <li><code>[prompt_name_2.md]</code>: [Brief justification for why this prompt is second, and how it uses the output of the previous step.]</li> <li>...</li> </ol> <p>Identified Gaps (if any):</p> <ul> <li>[Description of a missing step or prompt needed to complete the workflow.]</li> </ul>"},{"location":"temp-prompts-organized/_templates/system-level-instruction-editor.templates/","title":"System-level instruction editor","text":"<ul> <li>\"/instruction-file.md\"</li> <li>\"/planning-process.md\" next:</li> <li>\"/AGENTS.md\"</li> <li>\"/GEMINI.md\" tags:</li> <li>\"instructions\"</li> <li>\"editor\"</li> </ul>"},{"location":"temp-prompts-organized/_templates/system-level-instruction-editor.templates/#system-instruction-canonical-instruction-file-editor","title":"System Instruction: Canonical Instruction File Editor","text":"<p>Trigger: / <p>Purpose: &lt;1\u20132 lines describing the objective and outcome criteria.&gt;</p>"},{"location":"temp-prompts-organized/_templates/system-level-instruction-editor.templates/#inputs","title":"Inputs","text":"<ul> <li> <li> <li> <li> <li>"},{"location":"temp-prompts-organized/_templates/system-level-instruction-editor.templates/#steps","title":"Steps","text":"<ol> <li>Collect relevant data (). <li>Group by symptom/pattern; for each group, list 2\u20133 plausible causes.</li> <li>Propose disambiguators (instrumentation, targeted inputs, experiments).</li> <li>Sketch minimal fixes (patches/config toggles/rollbacks) with risk notes.</li> <li>Validate fixes (tests to run, monitors to watch, acceptance criteria).</li> <li>Roll out &amp; verify (staged rollout plan, owners, ETA).</li> <li> <p>Capture follow-ups (refactors, docs, guardrails).</p> </li> <li> <p>Deconstruct the request: Identify the user\u2019s intent and the minimal set of sections that should be added or updated.</p> </li> <li>Locate insertion points: Use semantic matching on headings and content to find the best-fit sections for the user\u2019s request. If no clear section exists, create a new minimal section with a logically consistent title.</li> <li>Apply minimal coherent change: Insert or modify content to satisfy the request while preserving tone, structure, and cross-references. Keep unrelated sections unchanged.</li> <li> <p>Run invariants:</p> </li> <li> <p>The entire file must be present (no placeholders, no truncation).</p> </li> <li>Markdown structure and formatting must remain valid.</li> <li>Internal references and links stay accurate.</li> <li> <p>Render in Canvas:</p> </li> <li> <p>If editing an existing file: open in Canvas and replace the full contents with the updated version.</p> </li> <li>If creating a new file: create it in Canvas and display the entire file.</li> <li>Variants (optional or on request): Generate <code>GEMINI.md</code> and/or <code>CLAUDE.md</code> from the updated <code>AGENTS.md</code> using only the Platform Substitution Rules. Render each variant\u2019s entire file in Canvas (one file per Canvas operation).</li> <li> <p>Size-limit fallback: If a size cap prevents full-file rendering in Canvas, output the entire file in chat, then append:</p> </li> <li> <p>\u201cNote: Full content was output in chat due to a size limit preventing Canvas rendering.\u201d</p> </li>"},{"location":"temp-prompts-organized/_templates/system-level-instruction-editor.templates/#output-format","title":"Output format","text":"<ul> <li>Table:  \u2192  \u2192  \u2192  \u2192 ."},{"location":"temp-prompts-organized/_templates/system-level-instruction-editor.templates/#example-rows","title":"Example rows","text":"<ul> <li>\"\" \u2192  \u2192  \u2192  \u2192 ."},{"location":"temp-prompts-refactored/3-step-process-b4-refactoring/","title":"3-step process (pre-refactor)","text":"<pre><code>&lt;!-- $1 = task description (e.g., \"Refactor email configuration\") --&gt;\n&lt;!-- $2 = list of files to modify (e.g., [\"src/config/email.ts\"]) --&gt;\n&lt;!-- $3 = sample refactor file path (e.g., \"src/config/email.ts\") --&gt;\n\n**Refactoring Pre-Refactor Process**\n\n# 3-step-process-b4-refactoring\n\n## describe the task and call the plan tool\n1. $1. Draft a plan (don't code)\n\n## identify target files for modification\n2. Conduct code analysis to determine files requiring modification: $2\n\n## provide sample refactor implementation\n3. Provide a sample refactor for $3\n</code></pre>"},{"location":"temp-prompts-refactored/Prompt-Optimizer/","title":"Prompt Optimizer","text":"<p>Prompt Optimization Template</p> <p>You are $2 \u2014 Prompt Optimization Specialist. Transform any raw user prompt into up to 4 concise, high-leverage variants that preserve intent while improving clarity, constraints, and outcome specificity.</p> <p>Your job</p> <ul> <li>Keep the user\u2019s original goal intact. Remove fluff, tighten verbs, and make deliverables and success criteria explicit.</li> <li>Resolve ambiguity with neutral defaults or clearly marked placeholders like <code>{context}</code>, <code>{inputs}</code>, <code>{constraints}</code>, <code>{acceptance_criteria}</code>, <code>{format}</code>, <code>{deadline}</code>.</li> <li>Add structure (steps, bullets, numbered requirements) only when it improves execution.</li> <li>Match or gently improve the tone implied by the user (directive/spec-like, polite, collaborative). Never over-polish into marketing-speak.</li> <li>Do not introduce tools, external data, or scope changes unless the user asked for them.</li> <li>Prefer active voice, testable requirements, and measurable outputs.</li> </ul> <p>Output rules</p> <ul> <li>Return only the variants, each in its own fenced code block. No commentary, no preamble, no trailing notes.</li> <li>Produce 1\u20134 variants (default 3). Stop at 4 unless the user explicitly requests more.</li> <li>For each block, begin with a short bracketed style tag (e.g., <code>[Directive]</code>, <code>[Spec]</code>, <code>[Polite]</code>, <code>[QA-Ready]</code>) on the first line, then the optimized prompt on subsequent lines.</li> </ul> <p>Optimization checklist (apply silently)</p> <ul> <li>Clarify objective and end artifact</li> <li>Specify audience/user/environment if implied</li> <li>Pin input sources and constraints</li> <li>Define acceptance criteria and non-goals</li> <li>State format/structure and length limits</li> <li>Include edge cases or examples if hinted</li> <li>Keep placeholders where user must decide</li> <li>Common pitfalls: Ambiguous constraints, vague success metrics, over-engineering</li> <li>Expected output quality: Clear deliverables, testable criteria, minimal fluff</li> </ul> <p>Now optimize the next input. User prompt: $1</p>"},{"location":"temp-prompts-refactored/action-diagram/","title":"Action Diagram","text":""},{"location":"temp-prompts-refactored/action-diagram/#nodes","title":"Nodes","text":"<ul> <li>$1</li> <li>$2</li> </ul>"},{"location":"temp-prompts-refactored/action-diagram/#edges","title":"Edges","text":"<ul> <li>$3 -&gt; $4</li> </ul>"},{"location":"temp-prompts-refactored/adr-new/","title":"ADR \u2013 new","text":"<p>Architecture Decision Record Drafting Prompt</p> <p>You are a CLI assistant to draft an Architecture Decision Record with pros/cons using the following inputs:</p> <ol> <li>Analyze project context from $1.</li> <li>Generate a concise ADR with Context, Decision, Status, Consequences. Title: $3.</li> <li>Synthesize insights into the output format with clear priorities and next steps.</li> </ol> <p>Output Requirements: - Provide a summary restating the goal. - Highlight $4, $5, and $6. - Document $7 to ensure maintainability.</p> <p>Example Input: $2</p> <p>Expected Output: Actionable summary aligned with output requirements.</p>"},{"location":"temp-prompts-refactored/adr-new.refactor/","title":"ADR \u2013 new (refactor)","text":"<p>{$2 or Inferred Name}</p> <p>You are a CLI assistant to draft an Architecture Decision Record with pros/cons using the following inputs:</p> <ol> <li>Analyze project context from $1.</li> <li>Generate a concise ADR with Context, Decision, Status, Consequences. Title: $3.</li> <li>Synthesize insights into the output format with clear priorities and next steps.</li> </ol> <p>Output Requirements: - Provide a summary restating the goal. - Highlight $4, $5, and $6. - Document $7 to ensure maintainability.</p> <p>Example Input: $2</p> <p>Expected Output: Actionable summary aligned with output requirements.</p>"},{"location":"temp-prompts-refactored/api-contract/","title":"API contract","text":""},{"location":"temp-prompts-refactored/api-contract/#api-contract-generator","title":"API Contract Generator","text":"<p>Trigger: $1</p> <p>Purpose: Author an initial $3 contract from requirements.</p> <p>Steps:</p> <ol> <li>Parse inputs and existing docs. If REST, prefer $3; if GraphQL, produce $3.</li> <li>Define resources, operations, request/response schemas, error model, auth, and rate limit headers.</li> <li>Add examples for each endpoint or type. Include pagination and filtering conventions.</li> <li>Save to $5.</li> <li>Emit changelog entry $6 with rationale and breaking-change flags.</li> </ol> <p>Affected files: - $5 - $6</p> <p>Output format: - <code>Contract Path</code>: $4 - <code>Design Notes</code>: $7 - Fenced code block with spec body</p> <p>Examples: - <code>$1</code> \u2192 $5</p> <p>Notes: - Follow $7 style for REST unless specified.</p>"},{"location":"temp-prompts-refactored/api-docs-local/","title":"API Docs Local","text":"<p>Trigger: $1</p> <p>Purpose: $2</p>"},{"location":"temp-prompts-refactored/api-docs-local/#steps","title":"Steps","text":"<p>$3</p>"},{"location":"temp-prompts-refactored/api-docs-local/#output-format","title":"Output format","text":"<p>$4</p>"},{"location":"temp-prompts-refactored/api-docs-local/#affected-files","title":"Affected files","text":"<ul> <li>$5</li> </ul>"},{"location":"temp-prompts-refactored/api-docs-local/#root-cause","title":"Root cause","text":"<ul> <li>$6</li> </ul>"},{"location":"temp-prompts-refactored/api-docs-local/#proposed-fix","title":"Proposed fix","text":"<ul> <li>$7</li> </ul>"},{"location":"temp-prompts-refactored/api-docs-local/#tests","title":"Tests","text":"<ul> <li>$8</li> </ul>"},{"location":"temp-prompts-refactored/api-docs-local/#docs-gaps","title":"Docs gaps","text":"<ul> <li>$9</li> </ul>"},{"location":"temp-prompts-refactored/api-docs-local/#open-questions","title":"Open questions","text":"<ul> <li>$10</li> </ul>"},{"location":"temp-prompts-refactored/api-usage/","title":"API usage","text":"<pre><code>&lt;!-- Placeholder mapping for api-usage.md:\n$1 = Example input symbol (e.g., 'HttpClient')\n$2 = API usage pattern (e.g., 'Key usages')\n$3 = Evidence type (e.g., 'File paths')\n$4 = Definition source (e.g., 'src/network/httpClient.ts')\n --&gt;\n\n**How to show internal API usage**\n\n1. Gather context by running `rg -n $1 . || grep -RIn $1 .`.\n2. Summarize common usage patterns and potential misuses for the symbol.\n3. Synthesize the insights into the requested format with clear priorities and next steps.\n\n**Output format**\n\n- Begin with a concise summary that restates the goal: Show how an internal API is used across the codebase.\n- Organize details under clear subheadings so contributors can scan quickly.\n- Document the evidence you used so maintainers can trust the conclusion.\n\n**Example**\n\n- Input: $2\n- Expected output: \n  - Definition: $3\n  - Key usages: $4\n</code></pre>"},{"location":"temp-prompts-refactored/audit/","title":"Audit","text":"<p>Trigger: $1</p> <p>Purpose: $2</p>"},{"location":"temp-prompts-refactored/audit/#steps","title":"Steps","text":"<ol> <li>Gather context by running <code>ls -la</code> for the top-level listing. Inspect $3, $4, $5, $6, $7, and $8 if present to understand shared conventions.</li> <li>Assess repository hygiene across documentation, testing, CI, linting, and security. Highlight gaps and existing automation.</li> <li>Synthesize the findings into a prioritized checklist with recommended next steps.</li> </ol>"},{"location":"temp-prompts-refactored/audit/#output-format","title":"Output format","text":"<ul> <li>Begin with a concise summary that restates the goal: Audit repository hygiene and suggest improvements.</li> <li>Offer prioritized, actionable recommendations with rationale.</li> <li>Call out test coverage gaps and validation steps.</li> <li>Highlight workflow triggers, failing jobs, and proposed fixes.</li> </ul>"},{"location":"temp-prompts-refactored/audit/#missing-sections","title":"Missing sections","text":"<ul> <li>Affected files: $9</li> <li>Root cause: $10</li> <li>Proposed fix: $11</li> <li>Tests: $12</li> <li>Docs gaps: $13</li> <li>Open questions: $14</li> </ul>"},{"location":"temp-prompts-refactored/auth-scaffold/","title":"Auth scaffold","text":""},{"location":"temp-prompts-refactored/auth-scaffold/#1","title":"$1","text":"<p>Trigger: $2</p> <p>Purpose: $3</p> <p>Steps:</p> <p>$4</p> <p>Output format: $5</p> <p>Examples: $6</p> <p>Notes: $7</p>"},{"location":"temp-prompts-refactored/blame-summary/","title":"Blame summary","text":"<p>How-to: Summarize authorship hotspots</p> <ol> <li>Gather context by running <code>git blame -w --line-porcelain $1 | sed -n 's/^author //p' | sort | uniq -c | sort -nr | sed -n '1,25p'</code> for the blame authors (top contributors first).</li> <li>Given the blame summary below, identify ownership hotspots and potential reviewers.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output: - Begin with a concise summary that restates the goal: Summarize authorship hotspots for a file using git blame. - Organize details under clear subheadings so contributors can scan quickly. - Reference evidence from CODEOWNERS or git history for each owner suggestion.</p> <p>Example Input: $2</p> <p>Expected Output: $3</p> <p>Proposed Fix Examples: $4</p>"},{"location":"temp-prompts-refactored/changed-files/","title":"Changed files","text":"<p>CLI Summary Prompt</p> <ol> <li>Gather context by running <code>$2</code>.</li> <li>List and categorize changed files: <code>$3</code>. Call out risky changes: <code>$4</code>.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: <code>$1</code>.</li> <li>Document the evidence used: <code>$5</code>.</li> </ul> <p>Example Input: <code>$6</code></p> <p>Expected Output: <code>$7</code></p>"},{"location":"temp-prompts-refactored/changelog-from-commits/","title":"Changelog from commits","text":"<p>Draft CHANGELOG From Commits</p> <p>Purpose: Produce a first-draft six-section CHANGELOG block from commit messages and PR titles between $1.</p> <p>Steps:</p> <ol> <li>Inputs: <code>since=&lt;ref or tag&gt;</code> optional, <code>until=&lt;ref&gt;</code> default HEAD, <code>include_prs=true|false</code> default true.</li> <li>Gather data with:</li> <li><code>git log --pretty=%H%x09%s%x09%b &lt;since&gt;.. &lt;until&gt;</code></li> <li>If available, <code>gh pr view</code> for merged PR titles by commit SHA; else rely on merge commit subjects.</li> <li>Heuristics:</li> <li>Map types: <code>feat|add</code>\u2192\\(3, <code>fix|bug</code>\u2192\\)3, <code>perf|refactor|opt</code>\u2192\\(3, <code>deprecate</code>\u2192\\)3, <code>remove|drop</code>\u2192\\(3, <code>sec|cve|security</code>\u2192\\)3.</li> <li>Shorten to 12\u201380 chars. Strip scope parentheses.</li> <li>Emit Markdown with only non-empty sections and a short preface noting the range.</li> </ol> <p>Expected output: - Range preface line: <code>Range: $2</code> - Six-section Markdown block (each section starts with $3, followed by bullet points of $4 and $5)</p> <p>Notes: - This is a draft; run <code>/update-changelog</code> to finalize and create links. - Keep bullets user-facing; avoid internal refactor noise.</p>"},{"location":"temp-prompts-refactored/changelog-verify/","title":"Changelog verify","text":""},{"location":"temp-prompts-refactored/changelog-verify/#verify-changelog-completeness","title":"Verify CHANGELOG Completeness","text":"<p>Trigger: $1</p> <p>Purpose: Check that the latest merge introduced a CHANGELOG entry with the six-section policy and that sections are concise and non-empty where applicable.</p> <p>Steps:</p> <ol> <li>Parse $1 and locate <code>## [Unreleased]</code> or the latest version heading.</li> <li>Validate presence and order of sections: Added, Changed, Deprecated, Removed, Fixed, Security.</li> <li>Flag anti-patterns: paragraphs longer than 2 lines, trailing periods, internal-only jargon, file paths, or empty sections left in place.</li> <li>Cross-check against commits since last tag to detect missing items.</li> <li>Emit a diagnostic report and a suggested patch to fix ordering and brevity issues.</li> </ol> <p>Output format:</p> <ul> <li><code>$2</code></li> <li>Table of findings with line numbers (\\(3) and reasons (\\)4)</li> <li>Suggested normalized Markdown block ($5)</li> <li>Unified diff to apply ($6)</li> </ul> <p>Examples: Input \u2192 $1 Output \u2192</p> <pre><code>$2\n- $3: $4\n- Missing section stub\n\n$5\n</code></pre> <p>Constraints: - Static analysis only; no network calls. - Treat any section with 0 bullets as removable unless policy requires stubs.</p>"},{"location":"temp-prompts-refactored/check/","title":"Check","text":"<p>Editorconfig Adherence Check</p> <p>You are a CLI assistant focused on helping contributors with the task: $1.</p> <ol> <li>Gather context by inspecting <code>$1</code>; running <code>$2</code>.</li> <li>From the listing and config, point out inconsistencies and propose fixes.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output: - Begin with a concise summary that restates the goal: $1. - Offer prioritized, actionable recommendations with rationale: $3. - Highlight workflow triggers, failing jobs, and proposed fixes.</p> <p>Common pitfalls to watch for: - Missing <code>.editorconfig</code> files in the repo - Inconsistent indentation settings across files - Ignoring OS-specific config overrides</p>"},{"location":"temp-prompts-refactored/cleanup-branches/","title":"Cleanup branches","text":"<p>Cleanup Branches</p> <p>Trigger: $1</p> <p>Purpose: $2</p> <p>You are a CLI assistant focused on helping contributors with the task: $3.</p> <ol> <li>$4</li> <li>$5</li> <li>$6</li> </ol> <p>Affected files: Local branches</p> <p>Output format: - $7</p>"},{"location":"temp-prompts-refactored/commit-msg/","title":"Commit msg","text":"<p>/ Placeholder mapping: - $1 = Input description - $2 = Template name (default: 'commit-message') - $3 = Max placeholders (default: 7) /</p> <p>commit-message</p> <p>Input description: $1</p> <p>Output format: {   \"title\": \"\",   \"body\": \"\" }</p> <p>Ensure the output is a valid JSON object with the title and body fields.</p>"},{"location":"temp-prompts-refactored/commit/","title":"From Placeholders in prompts.md","text":"<p>Commit title: $1</p> <p>Commit body:</p> <ul> <li>Scope: $1</li> <li>Summary: $2</li> </ul> <p>Suggested checklist: - run tests - run linters</p>"},{"location":"temp-prompts-refactored/commit/#expected-output-format","title":"Expected output format","text":"<pre><code>{\n  \"reasoning\": \"\",\n  \"template_markdown\": \"\"\n}\n</code></pre> <p>Note: Replace $1 with commit title, $2 with summary text.</p>"},{"location":"temp-prompts-refactored/compare-outputs/","title":"Compare outputs","text":"<p>Compare Outputs</p> <ul> <li>$1</li> <li>$2</li> <li>$3</li> <li>$4</li> </ul> <p>Recommended output format</p> <ul> <li>$1</li> </ul> <p>Note: This template includes the following sections that were inferred to be relevant based on the context: Affected files, Root cause, Proposed fix, Tests, Docs gaps, Open questions.</p>"},{"location":"temp-prompts-refactored/content-generation/","title":"Content Generation","text":"<p>Trigger: $1</p> <p>Purpose: $2</p>"},{"location":"temp-prompts-refactored/content-generation/#steps","title":"Steps","text":"<p>$3</p>"},{"location":"temp-prompts-refactored/content-generation/#output-format","title":"Output format","text":"<p>$4</p> <p>$1 = Title of the content (e.g., 'Content Generation') $2 = Purpose statement (e.g., 'Draft docs, blog posts, or marketing copy aligned with the codebase') $3 = List of steps with numbers (e.g., '1. Read repo README and recent CHANGELOG or commits.\\n2. Propose outlines for docs and posts.\\n3. Generate content with code snippets and usage examples.') $4 = Description of output format (e.g., 'Markdown files with frontmatter and section headings.')</p>"},{"location":"temp-prompts-refactored/coverage-guide/","title":"Coverage Guide","text":"<p>Trigger: $1</p> <p>Purpose: $2</p> <p>You are a CLI assistant focused on helping contributors with the task: $3</p> <ol> <li>Gather context by running <code>find . -name 'coverage*' -type f -maxdepth 3 -print -exec head -n 40 {} \\; 2&gt;/dev/null</code> for the coverage hints; running <code>git ls-files | sed -n '1,400p'</code> for the repo map.</li> <li>Using coverage artifacts (if available) and repository map, propose the highest\u2011ROI tests to add.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: $4</li> <li>Offer prioritized, actionable recommendations with rationale.</li> <li>Call out test coverage gaps and validation steps.</li> </ul> <p>Example Input: $5</p> <p>Expected Output: $6</p>"},{"location":"temp-prompts-refactored/cross-check/","title":"Conflict Resolver","text":"<p>Trigger: $1</p> <p>Purpose: $2</p> <p>Steps:</p> <ol> <li>$3</li> <li>$4</li> <li>$5</li> </ol> <p>Output format:</p> <pre><code>### $6\n- $7\n</code></pre> <p>Examples:</p> <ul> <li>$8</li> </ul> <p>Notes:</p> <ul> <li>$9</li> </ul>"},{"location":"temp-prompts-refactored/db-bootstrap/","title":"DB Bootstrap","text":"<p>Trigger: $1</p> <p>Purpose: $2</p> <p>Steps:</p> <ol> <li>Create $3 for local dev (skip for sqlite).</li> <li>Choose ORM/driver ($4) for SQL. Add migration config.</li> <li>Create $5 with baseline tables (users, sessions, audit_log).</li> <li>Add $6, $7, $8 scripts. Write seed data for local admin user.</li> <li>Update $9 with <code>DATABASE_URL</code> and test connection script.</li> </ol> <p>Output format: Migration plan list and generated file paths.</p> <p>Examples: $10 \u2192 $11</p> <p>Notes: Avoid destructive defaults; provide <code>--preview-feature</code> warnings if relevant.</p>"},{"location":"temp-prompts-refactored/db-bootstrap/#affected-files","title":"Affected files","text":"<ul> <li>$12: db/compose.yaml</li> <li>$13: $5</li> <li>$14: $6</li> <li>$15: $7</li> <li>$16: $8</li> <li>$17: .env.example</li> </ul>"},{"location":"temp-prompts-refactored/dead-code-scan/","title":"Dead Code Scan Template","text":""},{"location":"temp-prompts-refactored/dead-code-scan/#dead-code-scan","title":"Dead Code Scan","text":"<p>Trigger: <code>/dead-code-scan</code></p> <p>Purpose: $3</p> <p>You are a CLI assistant focused on helping contributors with the task: $2.</p> <ol> <li>Gather context by running $1 for the file reference graph (best\u2011effort).</li> <li>From the search results, hypothesize dead code candidates and how to safely remove them.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: $2.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul>"},{"location":"temp-prompts-refactored/design-assets/","title":"Design Assets","text":"<p>Trigger: $1</p> <p>Purpose: $2</p>"},{"location":"temp-prompts-refactored/design-assets/#steps","title":"Steps","text":"<ol> <li>$3</li> <li>$4</li> <li>$5</li> </ol>"},{"location":"temp-prompts-refactored/design-assets/#output-format","title":"Output format","text":"<ul> <li>$6</li> </ul>"},{"location":"temp-prompts-refactored/devops-automation/","title":"DevOps automation","text":"<p>Automation Prompt Template</p>"},{"location":"temp-prompts-refactored/devops-automation/#devops-automation","title":"DevOps Automation","text":"<p>$1</p> <p>$2</p>"},{"location":"temp-prompts-refactored/devops-automation/#steps","title":"Steps","text":"<ol> <li>$3</li> <li>$4</li> <li>$5</li> <li>$6</li> </ol>"},{"location":"temp-prompts-refactored/devops-automation/#output-format","title":"Output format","text":"<ul> <li>$7</li> </ul>"},{"location":"temp-prompts-refactored/devops-automation/#affected-files","title":"Affected files","text":"<ul> <li>$8</li> </ul>"},{"location":"temp-prompts-refactored/devops-automation/#root-cause","title":"Root cause","text":"<ul> <li>$9</li> </ul>"},{"location":"temp-prompts-refactored/devops-automation/#proposed-fix","title":"Proposed fix","text":"<ul> <li>$10</li> </ul>"},{"location":"temp-prompts-refactored/devops-automation/#tests","title":"Tests","text":"<ul> <li>$11</li> </ul>"},{"location":"temp-prompts-refactored/devops-automation/#docs-gaps","title":"Docs gaps","text":"<ul> <li>$12</li> </ul>"},{"location":"temp-prompts-refactored/devops-automation/#open-questions","title":"Open questions","text":"<ul> <li>$13</li> </ul>"},{"location":"temp-prompts-refactored/docs-fulfilled-100/","title":"Docs fulfilled 100","text":"<p>Docs fulfilled $3</p> <p>To fulfill the plan $3, what docs are missing now? Do you need more information from $1 or $2 to solve this task $3 correctly? Just tell me.</p> <p>Affected files: - $1</p> <p>Root cause: - $4</p> <p>Proposed fix: - $5</p> <p>Tests: - $6</p> <p>Docs gaps: - $7</p>"},{"location":"temp-prompts-refactored/e2e-runner-setup/","title":"E2E runner setup","text":"<p>/ Placeholder mapping: $1 = Trigger $2 = Purpose $3 = Steps $4 = Output format $5 = Examples $6 = Notes $7 = Affected files $8 = Root cause $9 = Proposed fix $10 = Tests $11 = Docs gaps $12 = Open questions /</p>"},{"location":"temp-prompts-refactored/e2e-runner-setup/#1","title":"$1","text":"<p>$2</p> <p>$3:</p> <ol> <li>$4</li> <li>$5</li> <li>$6</li> </ol> <p>$7:</p> <pre><code>$8\n</code></pre> <p>Examples:</p> <p><code>$9</code></p> <p>Notes:</p> <p>$10</p>"},{"location":"temp-prompts-refactored/env-setup/","title":"Env setup","text":"<p>Env Setup</p> <p>Trigger: $1</p> <p>Purpose: $2</p> <p>Steps:</p> <p>$3</p> <p>Output format: $4</p> <p>Examples: $5</p> <p>Notes: $6</p>"},{"location":"temp-prompts-refactored/error-analysis/","title":"Error Analysis","text":"<p>Trigger: $1</p> <p>Purpose: $2</p>"},{"location":"temp-prompts-refactored/error-analysis/#steps","title":"Steps","text":"<ol> <li>$3</li> <li>$4</li> <li>$5</li> <li>$6</li> </ol>"},{"location":"temp-prompts-refactored/error-analysis/#output-format","title":"Output format","text":"<ul> <li>Table: $7 \u2192 $8 \u2192 $9 \u2192 $10</li> </ul>"},{"location":"temp-prompts-refactored/error-analysis/#examples","title":"Examples","text":"<ul> <li>$11</li> </ul>"},{"location":"temp-prompts-refactored/eslint-review/","title":"ESLint review","text":"<p>/ * Placeholders: * $1 = task description (e.g., 'Review ESLint config and suggest rule tweaks') * $2 = context sources (e.g., '.eslintrc.cjs', '.eslintrc.js', 'package.json') * $3 = key rules (e.g., 'no-unused-vars') * $4 = missing plugins (e.g., 'eslint-plugin-react') * $5 = performance considerations (e.g., 'avoid expensive rules') * $6 = expected output format (e.g., 'structured report') * $7 = next steps (e.g., 'document evidence') /</p> <p>How-to: ESLint Review</p> <ol> <li>Gather context by inspecting $1; inspecting $2; inspecting $3.</li> <li>Explain key rules, $4, and $5.</li> <li>Synthesize insights into $6 with clear priorities and $7.</li> </ol>"},{"location":"temp-prompts-refactored/eslint-review/#affected-files","title":"Affected files","text":"<ul> <li>$1</li> </ul>"},{"location":"temp-prompts-refactored/eslint-review/#root-cause","title":"Root cause","text":"<ul> <li>Missing $4</li> </ul>"},{"location":"temp-prompts-refactored/eslint-review/#proposed-fix","title":"Proposed fix","text":"<ul> <li>Add $4 to configuration</li> </ul>"},{"location":"temp-prompts-refactored/eslint-review/#tests","title":"Tests","text":"<ul> <li>Verify $4 with example code</li> </ul>"},{"location":"temp-prompts-refactored/eslint-review/#docs-gaps","title":"Docs gaps","text":"<ul> <li>Document $5 in contribution guidelines</li> </ul>"},{"location":"temp-prompts-refactored/eslint-review/#open-questions","title":"Open questions","text":"<ul> <li>How to optimize $5 for large projects?</li> </ul>"},{"location":"temp-prompts-refactored/evidence-capture/","title":"Evidence capture","text":"<pre><code>&lt;!-- Placeholder mapping (from input fields):\n$1 = Claim text\n$2 = Source URL\n$3 = Source Title\n$4 = Publisher\n$5 = Publication Date\n$6 = Access Date\n$7 = Quote (\u226425 words) --&gt;\n\n# Evidence Logger\n\nTrigger: /evidence-capture\n\nPurpose: Capture sources for a specified claim with dates, \u226425-word quotes, findings, relevance, and confidence.\n\nSteps:\n\n1. Read the claim text and optional URLs provided.\n2. For each source, record metadata and a \u226425-word quote.\n3. Add a brief Finding, Relevance (H/M/L), and Confidence (0.0\u20131.0).\n\nOutput format:\n</code></pre>"},{"location":"temp-prompts-refactored/evidence-capture/#evidence-log","title":"Evidence Log","text":"SourceID Title Publisher URL PubDate Accessed Quote (\u226425w) Finding Rel Conf <pre><code>Examples:\n\n- Input: `/evidence-capture $1` with $2\n- Output: Evidence table entries with dates.\n\nNotes:\n\n- Mark missing PubDate as n/a. Prefer official documentation.\n</code></pre>"},{"location":"temp-prompts-refactored/explain-code/","title":"Explain code","text":"<p>Code Explanation Template</p>"},{"location":"temp-prompts-refactored/explain-code/#1","title":"$1","text":"<p>Trigger: $2</p> <p>Purpose: $3</p>"},{"location":"temp-prompts-refactored/explain-code/#steps","title":"Steps","text":"<ol> <li> <p>$4</p> </li> <li> <p>$5</p> </li> <li> <p>$6</p> </li> </ol>"},{"location":"temp-prompts-refactored/explain-code/#output-format","title":"Output format","text":"<p>$7</p>"},{"location":"temp-prompts-refactored/explain-failures/","title":"Explain failures","text":"<p>Test Failure Analysis Template</p> <ol> <li>Task Context: Analyze recent test failures and propose fixes for $1.</li> <li>Root Cause Analysis: Identify root causes from $2.</li> <li>Proposed Fixes: Provide concrete fixes for $3.</li> <li>Affected Files: List files impacted by $4.</li> <li>Test Coverage Impact: Note how fixes affect test coverage ($5).</li> <li>Open Questions: Document unresolved issues ($6).</li> </ol> <p>Output Format: - Begin with a concise summary restating $1. - Prioritized recommendations with rationale for $2 and \\(3. - Evidence used to maintain trust (\\)4).</p> <p>Example Context: $7</p>"},{"location":"temp-prompts-refactored/explain-symbol/","title":"Explain symbol","text":"<p>Symbol Explanation Analysis</p> <p>Output: - Begin with a concise summary reiterating the goal: Explain where and how $1 is defined and used. - Structure findings under clear subheadings for quick scanning. - Document evidence: $2 (definition) and $3 (key usages). - Note documentation gaps: [specify any missing documentation or context]</p>"},{"location":"temp-prompts-refactored/feature-flags/","title":"Feature flags","text":"<p>How-to</p> <p>$1</p> <p>Trigger: $2</p> <p>Purpose: $3</p> <p>Steps: $4</p> <p>Output format: $5</p> <p>Examples: $6</p> <p>Notes: $7</p>"},{"location":"temp-prompts-refactored/file-modularity/","title":"File modularity","text":"<p>File Modularity</p> <p>Trigger: $1</p> <p>Purpose: Enforce smaller files and propose safe splits for giant files.</p>"},{"location":"temp-prompts-refactored/file-modularity/#steps","title":"Steps","text":"<ol> <li>Find files over thresholds ($2).</li> <li>Suggest extraction targets: $3.</li> <li>Provide before/after examples and $5.</li> </ol>"},{"location":"temp-prompts-refactored/file-modularity/#output-format","title":"Output format","text":"<ul> <li>$6</li> </ul>"},{"location":"temp-prompts-refactored/file-modularity/#affected-files","title":"Affected files","text":"<ul> <li>$1</li> </ul>"},{"location":"temp-prompts-refactored/file-modularity/#root-cause","title":"Root cause","text":"<ul> <li>Files exceeding size thresholds</li> </ul>"},{"location":"temp-prompts-refactored/file-modularity/#proposed-fix","title":"Proposed fix","text":"<ul> <li>$4</li> <li>$5</li> </ul>"},{"location":"temp-prompts-refactored/file-modularity/#tests","title":"Tests","text":"<ul> <li>Unit tests for extracted components</li> </ul>"},{"location":"temp-prompts-refactored/file-modularity/#docs-gaps","title":"Docs gaps","text":"<ul> <li>Documentation for new file structure</li> </ul>"},{"location":"temp-prompts-refactored/file-modularity/#open-questions","title":"Open questions","text":"<ul> <li>How to handle circular dependencies</li> <li>Should we include type definitions in the extraction?</li> </ul>"},{"location":"temp-prompts-refactored/fix/","title":"Fix","text":"<p>Trigger: $1</p> <p>Purpose: $2</p> <p>You are a CLI assistant focused on helping contributors with the task: $3</p> <ol> <li>Gather context by running <code>git log --pretty='- %h %s' -n 20</code> for the recent commits; running <code>git ls-files | sed -n '1,400p'</code> for the repo map (first 400 files).</li> <li>$4: $5</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: $6</li> <li>Provide unified diff-style patches when recommending code changes.</li> <li>Offer prioritized, actionable recommendations with rationale.</li> </ul> <p>Example Input: $7</p> <p>Expected Output:</p> <pre><code>$8\n</code></pre> <p>Regression test: $9</p>"},{"location":"temp-prompts-refactored/gemini-map/","title":"Gemini map","text":"<p>Gemini\u2192Codex Mapper</p> <p>You are a translator that converts a $1 TOML command into a Codex prompt file.</p> <p>Steps:</p> <p>1) Read TOML with <code>description</code> and <code>prompt</code>. 2) Extract the task, inputs, and outputs implied by the TOML. 3) Write a Codex prompt file \u2264 300 words:</p> <pre><code>- Role line `You are ...`\n- Numbered steps\n- Output section\n- Example input and expected output\n- `Usage: /$2` line\n- YAML-like metadata at top\n</code></pre> <p>4) Choose a short, hyphenated filename \u2264 32 chars. 5) Emit a ready-to-run bash snippet: <code>cat &gt; ~/.codex/prompts/&lt;filename&gt;.md &lt;&lt; 'EOF'</code> \u2026 <code>EOF</code>. 6) Do not include destructive commands or secrets.</p> <p>Example input:</p> <pre><code>$6\n</code></pre> <p>Expected output:</p> <p>A $7 file with the structure above and a bash cat &gt; block.</p> <p>Usage: /$2</p> <p>Output format</p> <p>The output must be a Codex prompt file containing: - Role line: \"You are a translator that converts a $1 TOML command into a Codex prompt file.\" - Numbered steps (1-6) matching $5 - Output section specifying the format - Example input and expected output - <code>Usage: /$2</code> line - YAML metadata: <code>name: $1</code>, <code>command: $2</code>, <code>tags: $3</code>, <code>scope: $4</code></p> <p>ensure - \u22647 placeholders - no verbatim sentences from input - literal <code>$</code> tokens remain</p>"},{"location":"temp-prompts-refactored/generate-readme/","title":"$1","text":"<p>$2</p>"},{"location":"temp-prompts-refactored/generate-readme/#features","title":"Features","text":"<ul> <li>$3</li> </ul>"},{"location":"temp-prompts-refactored/generate-readme/#setup","title":"Setup","text":"<pre><code>$4\n</code></pre>"},{"location":"temp-prompts-refactored/generate-readme/#usage","title":"Usage","text":"<pre><code>$5\n</code></pre>"},{"location":"temp-prompts-refactored/generate-readme/#contributing","title":"Contributing","text":"<p>$6</p>"},{"location":"temp-prompts-refactored/generate-readme/#license","title":"License","text":"<p>$7</p>"},{"location":"temp-prompts-refactored/generate-readme/#additional-info","title":"Additional Info","text":"<ul> <li>Version: $8</li> <li>Author: $9</li> <li>Last Updated: $10</li> </ul>"},{"location":"temp-prompts-refactored/generate/","title":"Generate","text":"<p>Generate Unit Tests</p> <p>Trigger: $1</p> <p>Purpose: $2</p> <p>You are a CLI assistant focused on helping contributors with the task: $2.</p>"},{"location":"temp-prompts-refactored/generate/#steps","title":"Steps","text":"<ol> <li>$3</li> <li>$4</li> <li>$5</li> <li>$6</li> </ol>"},{"location":"temp-prompts-refactored/generate/#output","title":"Output","text":"<ul> <li>$7</li> <li>$8</li> <li>$9</li> <li>$10</li> <li>$11</li> </ul>"},{"location":"temp-prompts-refactored/grep/","title":"Grep","text":"<p>CLI Search Guide</p> <p>You are a CLI assistant focused on helping contributors with the task: Recursive text search with ripgrep/grep injection.</p> <ol> <li>Gather context by running <code>rg -n $1 . || grep -RIn $1 .</code>.</li> <li>Show matched lines with file paths and line numbers.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Recursive text search with ripgrep/grep injection.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: $2</p> <p>Expected Output: $3</p>"},{"location":"temp-prompts-refactored/iac-bootstrap/","title":"IaC bootstrap","text":"<p>$1</p> <p>Trigger: <code>/iac-bootstrap $2</code></p> <p>Purpose: $3</p> <p>Steps:  1. $4 2. $4 3. $4 4. $4</p> <p>Output format: $5</p> <p>Examples: $6</p> <p>Notes: $7</p>"},{"location":"temp-prompts-refactored/instruction-file/","title":"Instruction file","text":"<p>How-to: Create Instruction File</p>"},{"location":"temp-prompts-refactored/instruction-file/#instruction-file","title":"Instruction File","text":"<p>Trigger: $1</p> <p>Purpose: $2</p>"},{"location":"temp-prompts-refactored/instruction-file/#steps","title":"Steps","text":"<ol> <li>$3</li> <li>$4</li> <li>$5</li> <li>$6</li> </ol>"},{"location":"temp-prompts-refactored/instruction-file/#output-format","title":"Output format","text":"<ul> <li>$7</li> </ul>"},{"location":"temp-prompts-refactored/instruction-file/#affected-files","title":"Affected files","text":"<ul> <li><code>cursor.rules</code></li> <li><code>windsurf.rules</code></li> <li><code>claude.md</code></li> </ul>"},{"location":"temp-prompts-refactored/instruction-file/#root-cause","title":"Root cause","text":"<ul> <li>No specific root cause identified in this context</li> </ul>"},{"location":"temp-prompts-refactored/instruction-file/#proposed-fix","title":"Proposed fix","text":"<ul> <li>Not applicable; this is a template for creating new instructions</li> </ul>"},{"location":"temp-prompts-refactored/instruction-file/#tests","title":"Tests","text":"<ul> <li>Not applicable; this is a template for creating new instructions</li> </ul>"},{"location":"temp-prompts-refactored/instruction-file/#docs-gaps","title":"Docs gaps","text":"<ul> <li>Not applicable; this is a template for creating new instructions</li> </ul>"},{"location":"temp-prompts-refactored/instruction-file/#open-questions","title":"Open questions","text":"<ul> <li>Not applicable; this is a template for creating new instructions</li> </ul>"},{"location":"temp-prompts-refactored/integration-test/","title":"Integration test","text":"<p>E2E Test Generation Prompt</p>"},{"location":"temp-prompts-refactored/integration-test/#integration-test","title":"Integration Test","text":"<p>Trigger: $1</p> <p>Purpose: $2</p>"},{"location":"temp-prompts-refactored/integration-test/#steps","title":"Steps","text":"<ol> <li>Detect framework from <code>package.json</code> or repo (Playwright/Cypress/Vitest).</li> <li>Identify critical path scenarios from <code>PLAN.md</code>.</li> <li>Produce test files under <code>e2e/</code> with arrange/act/assert and selectors resilient to DOM changes.</li> <li>Include login helpers and data setup. Add CI commands.</li> </ol>"},{"location":"temp-prompts-refactored/integration-test/#output-format","title":"Output format","text":"<ul> <li>$3</li> </ul>"},{"location":"temp-prompts-refactored/integration-test/#examples","title":"Examples","text":"<ul> <li>Login, navigate to dashboard, create record, assert toast.</li> </ul>"},{"location":"temp-prompts-refactored/integration-test/#notes","title":"Notes","text":"<ul> <li>Prefer data-test-id attributes. Avoid brittle CSS selectors.</li> </ul>"},{"location":"temp-prompts-refactored/license-report/","title":"License report","text":"<p>You are a CLI assistant focused on helping contributors with the task: $1.</p> <ol> <li>Gather context by running $2 for license tools if present.</li> <li>Create a license inventory with notices of copyleft/unknown licenses.</li> <li>Synthesize insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: $1.</li> <li>Organize details under clear subheadings so contributors can scan quickly.</li> <li>Flag copyleft or unknown licenses and suggest remediation timelines.</li> </ul> <p>Example Input: (none \u2013 command runs without arguments)</p> <p>Expected Output:</p> <ul> <li>$3 \u2014 $4</li> <li>$3 \u2014 $5</li> </ul>"},{"location":"temp-prompts-refactored/logging-strategy/","title":"Logging strategy","text":""},{"location":"temp-prompts-refactored/logging-strategy/#1","title":"$1","text":"<p>Trigger: $2</p> <p>Purpose: $3</p>"},{"location":"temp-prompts-refactored/logging-strategy/#steps","title":"Steps","text":"<p>$4</p> <p>$5</p> <p>$6</p> <p>$7</p>"},{"location":"temp-prompts-refactored/logging-strategy/#output-format","title":"Output format","text":"<ul> <li>Diff hunks and a short guideline section.</li> </ul>"},{"location":"temp-prompts-refactored/migration-plan/","title":"Migration plan","text":"<p>Migration Plan Template</p> <p>Trigger: $1</p> <p>Purpose: Produce safe up/down migration steps with checks and rollback notes.</p> <p>Steps:</p> <ol> <li>$3</li> <li>$4</li> </ol> <p>Output format: <code>Plan</code>, <code>SQL</code>, <code>Rollback</code>, <code>Checks</code> sections.</p> <p>Examples: $2.</p> <p>Notes: $5</p> <p>Additional requirements: $6 and $7 with $8 flag.</p>"},{"location":"temp-prompts-refactored/missing-docs/","title":"Missing docs","text":"<p>/   $1 = Original prompt text   $2 = 'Missing Docs' (inferred genre)   $3 = Max placeholders (default=7) /</p> <p>Missing Docs</p> <p>(See the source markdown for the full context)</p> <p>The following sections are required to complete this analysis:</p> <ul> <li>Affected files: $1</li> <li>Root cause: $2</li> <li>Proposed fix: $3</li> <li>Tests: $4</li> <li>Docs gaps: $5</li> <li>Open questions: $6</li> <li>Additional context: $7</li> </ul>"},{"location":"temp-prompts-refactored/model-evaluation/","title":"Model evaluation","text":"<p>/ Placeholder mapping: $1 = Trigger phrase $2 = Purpose statement $3 = Step 1 (define benchmark) $4 = Step 2 (run candidates) $5 = Step 3 (analyze failures) $6 = Output format description $7 = Expected metrics (optional) /</p>"},{"location":"temp-prompts-refactored/model-evaluation/#model-evaluation","title":"Model Evaluation","text":"<p>$1</p> <p>Purpose: $2</p>"},{"location":"temp-prompts-refactored/model-evaluation/#steps","title":"Steps","text":"<ol> <li>$3</li> <li>$4</li> <li>$5</li> </ol>"},{"location":"temp-prompts-refactored/model-evaluation/#output-format","title":"Output format","text":"<p>$6</p> <p>Expected sections (add if missing): - Expected metrics - Failure analysis - Adoption recommendations</p>"},{"location":"temp-prompts-refactored/model-strengths/","title":"Model strengths","text":"<p>Model Strengths</p> <p>(Trigger: $1)</p> <p>(Purpose: $2)</p> <p>($3)</p> <p>($4)</p> <p>(Recommended output format: $5)</p>"},{"location":"temp-prompts-refactored/modular-architecture/","title":"Modular Architecture","text":"<p>Trigger: $1</p> <p>Purpose: $2</p>"},{"location":"temp-prompts-refactored/modular-architecture/#steps","title":"Steps","text":"<p>$3</p>"},{"location":"temp-prompts-refactored/modular-architecture/#output-format","title":"Output format","text":"<p>$4</p>"},{"location":"temp-prompts-refactored/modular-architecture/#affected-files","title":"Affected files","text":"<p>To be filled</p>"},{"location":"temp-prompts-refactored/modular-architecture/#root-cause","title":"Root cause","text":"<p>To be filled</p>"},{"location":"temp-prompts-refactored/modular-architecture/#proposed-fix","title":"Proposed fix","text":"<p>To be filled</p>"},{"location":"temp-prompts-refactored/modular-architecture/#tests","title":"Tests","text":"<p>To be filled</p>"},{"location":"temp-prompts-refactored/modular-architecture/#docs-gaps","title":"Docs gaps","text":"<p>To be filled</p>"},{"location":"temp-prompts-refactored/modular-architecture/#open-questions","title":"Open questions","text":"<p>To be filled</p>"},{"location":"temp-prompts-refactored/monitoring-setup/","title":"Monitoring Setup","text":"<p>Trigger: $1</p> <p>Purpose: $2</p> <p>Steps:</p> <ol> <li>$3</li> <li>$4</li> <li>$5</li> </ol> <p>Output format: $6</p> <p>Examples: $7</p> <p>Notes: $8</p>"},{"location":"temp-prompts-refactored/monitoring-setup/#affected-files","title":"Affected files","text":""},{"location":"temp-prompts-refactored/monitoring-setup/#root-cause","title":"Root cause","text":""},{"location":"temp-prompts-refactored/monitoring-setup/#proposed-fix","title":"Proposed fix","text":""},{"location":"temp-prompts-refactored/monitoring-setup/#tests","title":"Tests","text":""},{"location":"temp-prompts-refactored/monitoring-setup/#docs-gaps","title":"Docs gaps","text":""},{"location":"temp-prompts-refactored/monitoring-setup/#open-questions","title":"Open questions","text":""},{"location":"temp-prompts-refactored/openapi-generate/","title":"OpenAPI Generate","text":"<p>Trigger: $1</p> <p>Purpose: $2</p> <p>Steps:</p> <ol> <li>$3</li> <li>$4</li> <li>$5</li> <li>$6</li> <li>$7</li> </ol> <p>Output format: $8</p> <p>Examples: $9</p> <p>Notes: $10</p>"},{"location":"temp-prompts-refactored/openapi-generate/#affected-files","title":"Affected files","text":""},{"location":"temp-prompts-refactored/openapi-generate/#root-cause","title":"Root cause","text":""},{"location":"temp-prompts-refactored/openapi-generate/#proposed-fix","title":"Proposed fix","text":""},{"location":"temp-prompts-refactored/openapi-generate/#tests","title":"Tests","text":""},{"location":"temp-prompts-refactored/openapi-generate/#docs-gaps","title":"Docs gaps","text":""},{"location":"temp-prompts-refactored/openapi-generate/#open-questions","title":"Open questions","text":""},{"location":"temp-prompts-refactored/owners/","title":"Owners","text":"<p>Owners Suggestion Prompt</p> <p>You are a CLI assistant focused on helping contributors with the task: $2.</p> <ol> <li>Gather context by inspecting $3 for codeowners (if present); running $4 for recent authors of the path.</li> <li>Based on codeowners and git history, suggest owners.</li> <li>Synthesize the insights into the requested format with clear priorities.</li> </ol> <p>Output: - Begin with a concise summary restating the goal: $2 - Reference evidence from $3 or git history for each owner suggestion. - Document the evidence used to maintain trust.</p> <p>Example input: $5</p> <p>Expected output: - Likely reviewers: \\(6 (\\)7)</p>"},{"location":"temp-prompts-refactored/plan-delta/","title":"Plan delta","text":"<p>How-to: $2</p> <p>Trigger: $1</p> <p>Purpose: $2</p> <p>Steps:</p> <ol> <li>Discover repository context:</li> <li>Detect tasks file path: prefer $3; else search <code>**/$3</code>.</li> <li>Detect latest plan doc: prefer $4; else <code>**/*(prd|spec|plan)*.md</code>.</li> <li>Snapshot:</li> <li>Create $5 if missing.</li> <li>Copy current tasks file to <code>$5/tasks-$(date +%$6).json</code> using: <code>cp -f &lt;tasks.json&gt; $5/tasks-$(date +%$6).json</code>.</li> <li>Input collection:</li> <li>Read new objectives, constraints, and findings from user input.</li> <li>Parse selection rules to choose mode: $7.</li> <li>Delta Doc generation:</li> <li>Create <code>$5/delta-$(date +%$6).md</code> containing sections:<ul> <li>Objectives (new)</li> <li>Constraints (new)</li> <li>Impacts</li> <li>Decisions</li> <li>Evidence log (sources, dates, links)</li> </ul> </li> <li>Task graph update:</li> <li>Never alter historical states (<code>done</code>/<code>in_progress</code>/<code>blocked</code>) of existing tasks.</li> <li>Do not reuse IDs. For replaced tasks, set <code>superseded_by</code> on old tasks and include ID in new task's <code>supersedes[]</code>.</li> <li>Add <code>source_doc</code>, <code>lineage[]</code> on new/changed tasks.</li> <li>Create new tasks only for new/changed work. Link predecessors via <code>dependencies</code> or <code>relations</code>.</li> <li>Keep deprecated tasks with <code>status: \"deprecated\"</code> and <code>reason</code>.</li> <li>Tests:</li> <li>Recompute dependency order and validate acyclicity.</li> <li>Flag contradictions as <code>blocked</code> with machine-readable <code>blocked_reason</code>.</li> <li>Verify critical-path tasks are correctly prioritized.</li> <li>Affected files:</li> <li>\\(5/tasks-\\)(date +%$6).json</li> <li>\\(5/delta-\\)(date +%$6).md</li> <li>Readiness and selection:</li> <li>Implement <code>ready/next()</code> to select tasks with all dependencies <code>done</code> and not <code>blocked</code>.</li> <li>Produce readiness report grouped by <code>ready | blocked | deprecated</code>.</li> <li>Outputs:</li> <li>Write updated tasks file in-place.</li> <li>Persist Delta Doc under $5.</li> <li>Emit decision hooks: one line per change stating what it enables.</li> </ol> <p>Output format: - Produce three artifacts:   1. Updated tasks file: Valid JSON. Preserve existing fields. Append new/changed tasks and relations.   2. Delta document: Markdown with sections <code># Delta</code>, <code>## Objectives</code>, <code>## Constraints</code>, <code>## Impacts</code>, <code>## Decisions</code>, <code>## Evidence</code>.   3. Readiness report: Plain text with sections <code>READY</code>, <code>BLOCKED</code>, <code>DEPRECATED</code>. Format: <code>- &lt;id&gt; &lt;title&gt;</code> (blocked items add <code>[reason=&lt;code&gt;]</code>). - Print Decision hooks as lines starting with <code>HOOK: &lt;id&gt; enables &lt;capability&gt;</code>.</p> <p>Open questions: - What evidence is missing to resolve inputs? - How to handle partial scope changes (&lt;20%)? - Should deprecated tasks be automatically archived?</p>"},{"location":"temp-prompts-refactored/planning-process/","title":"Planning process","text":"<p>Planning Process Prompt</p>"},{"location":"temp-prompts-refactored/planning-process/#planning-process","title":"Planning Process","text":"<p>Trigger: $2</p> <p>Purpose: Draft, refine, and execute a feature plan with strict scope control and progress tracking.</p>"},{"location":"temp-prompts-refactored/planning-process/#steps","title":"Steps","text":"<ol> <li>If no plan file exists, create $2. If it exists, load it.</li> <li>Draft sections: Goal, User Story, Milestones, Tasks, Won't do, Ideas for later, Validation, Risks.</li> <li>Trim bloat. Convert vague bullets into testable tasks with acceptance criteria.</li> <li>Tag each task with an owner and estimate. Link to files or paths that will change.</li> <li>Maintain two backlogs: Won't do (explicit non-goals) and Ideas for later (deferrable work).</li> <li>Mark tasks done after tests pass. Append commit SHAs next to completed items.</li> <li>After each milestone: run tests, update Validation, then commit $2.</li> </ol>"},{"location":"temp-prompts-refactored/planning-process/#output-format","title":"Output format","text":"<ul> <li>Update or create $2 with the sections above.</li> <li>Include a checklist for Tasks. Keep lines under $3 chars.</li> </ul>"},{"location":"temp-prompts-refactored/planning-process/#examples","title":"Examples","text":"<p>Input: $1</p> <p>Output:</p> <ul> <li>Goal: Let users sign in with Google.</li> <li>Tasks: [ ] add Google client, [ ] callback route, [ ] session, [ ] E2E test.</li> <li>Won't do: org SSO.</li> <li>Ideas for later: Apple login.</li> </ul>"},{"location":"temp-prompts-refactored/planning-process/#notes","title":"Notes","text":"<ul> <li>Planning only. No code edits.</li> <li>Assume a Git repo with test runner available.</li> </ul>"},{"location":"temp-prompts-refactored/pr-desc/","title":"PR desc","text":"<p>PR Description Template</p> <p>Trigger: /pr-desc $1</p> <p>Purpose: Draft a PR description from the branch diff.</p> <ol> <li>Gather context by running <code>git diff --name-status $5</code> for the changed files; <code>git diff --shortstat $4</code> for high-level stats.</li> <li>Create a crisp PR description following this structure: $6</li> <li>Base branch: $2</li> <li>User context: $3</li> <li>Synthesize insights into the requested format.</li> </ol> <p>Output requirements: - Begin with a concise summary: $7 - Prioritized recommendations with rationale - Test coverage gaps and validation steps - Workflow triggers, failing jobs, and proposed fixes</p> <p>Affected Files: $5 Root Cause: [Optional] Proposed Fix: [Optional] Test Plan: [Optional] Risk: [Optional] Rollback Plan: [Optional] Release Notes: [Optional]</p>"},{"location":"temp-prompts-refactored/prd-generator/","title":"PRD generator","text":"<p>PRD Generator Template</p> <p>Output a plain-text file named <code>prd.txt</code> containing only these sections in this order (separated by one blank line):</p>"},{"location":"temp-prompts-refactored/prd-generator/#overview","title":"Overview","text":""},{"location":"temp-prompts-refactored/prd-generator/#core-features","title":"Core Features","text":""},{"location":"temp-prompts-refactored/prd-generator/#user-experience","title":"User Experience","text":""},{"location":"temp-prompts-refactored/prd-generator/#technical-architecture","title":"Technical Architecture","text":""},{"location":"temp-prompts-refactored/prd-generator/#development-roadmap","title":"Development Roadmap","text":""},{"location":"temp-prompts-refactored/prd-generator/#logical-dependency-chain","title":"Logical Dependency Chain","text":""},{"location":"temp-prompts-refactored/prd-generator/#risks-and-mitigations","title":"Risks and Mitigations","text":""},{"location":"temp-prompts-refactored/prd-generator/#appendix","title":"Appendix","text":"<p>Output Format</p> <ul> <li><code># Overview</code>: $3</li> <li><code># Core Features</code>: Each includes What, Why, High-level How, and BDD criteria:   <code>Given ...</code> <code>When ...</code> <code>Then ...</code></li> <li><code># User Experience</code>: Personas, key flows, UI/UX, accessibility</li> <li><code># Technical Architecture</code>: Components, data models, APIs/integrations, infrastructure, NFRs</li> <li><code># Development Roadmap</code>: MVP and Future Enhancements with acceptance criteria (no dates)</li> <li><code># Logical Dependency Chain</code>: Work ordering for foundations, earliest front end, extensible units</li> <li><code># Risks and Mitigations</code>: Each includes Description, Likelihood, Impact, Mitigation</li> <li><code># Appendix</code>:   \u2022 Assumptions (bulleted)   \u2022 Research findings from $1   \u2022 Context notes (<code>- &lt;visible text&gt; \u2014 inferred topic</code>)   \u2022 Technical specs</li> </ul> <p>Validation Checks</p> <ul> <li>Headers present and ordered</li> <li>All BDD criteria included for features/fallbacks</li> <li>Risks include likelihood and impact</li> <li>No URLs/secrets; exactly one blank line between sections</li> <li>$1 contains only visible link text (no external browsing)</li> </ul>"},{"location":"temp-prompts-refactored/prettier-adopt_Migration_report/","title":"Prettier migration report","text":"<pre><code>&lt;!--\n$1=Task description\n$2=Template name (inferred as 'Prettier Migration Guide')\n$3=Summary of the report\n$4=Prioritized recommendations\n$5=Rationale for recommendations\n$6=Evidence used\n$7=Example input (none)\n$8=Expected output structure\n--&gt;\n\n**$2**\n\n1. $1\n\n2. $3\n\n3. $4\n\n4. $5\n\n5. $6\n\n6. $7\n\n7. $8\n\n\n---\n\n### Affected files\n\n- $1 (to be populated with file paths)\n\n### Root cause\n\n- $1 (to be populated with migration challenges)\n\n### Proposed fix\n\n- $1 (to be populated with specific steps)\n\n### Tests\n\n- $1 (to be populated with test cases)\n\n### Docs gaps\n\n- $1 (to be populated with missing documentation)\n\n### Open questions\n\n- $1 (to be populated with unresolved issues)\n</code></pre>"},{"location":"temp-prompts-refactored/problem-analyzer/","title":"Problem analyzer","text":""},{"location":"temp-prompts-refactored/problem-analyzer/#problem-analyzer","title":"problem-analyzer","text":"<p> $1 </p> <p>Tasks: 1. Locate all files/modules affected by the issue. List paths and why each is implicated. 2. Explain the root cause(s): what changed, how it propagates to the failure, and any environmental factors. 3. Propose the minimal, safe fix. Include code-level steps, side effects, and tests to add/update. 4. Flag any missing or outdated documentation/configs/schemas that should be updated or added (especially if code appears outdated vs. current behavior).</p> <p>Output format: - Affected files:   - <code>$1</code>: <code>&lt;reason&gt;</code> - Root cause:   - <code>$2</code>: <code>&lt;concise explanation&gt;</code> - Proposed fix:   - <code>$3</code>: <code>&lt;steps/patch outline&gt;</code>   - Tests: - Documentation gaps:   - <code>$4</code>: <code>&lt;doc_section_what_to_update_add&gt;</code> - Open questions/assumptions:   - <code>$5</code>: <code>&lt;items&gt;</code></p> <p>DON'T CODE YET.</p>"},{"location":"temp-prompts-refactored/prompt-sequence-generator/","title":"Prompt: Generate Prompt Execution Sequence","text":"<p>Purpose: Given a high-level goal and a set of available prompts, generate the logical execution sequence required to accomplish that goal by chaining the prompts together.</p>"},{"location":"temp-prompts-refactored/prompt-sequence-generator/#inputs","title":"Inputs","text":"<ul> <li> <p>High-Level Goal: {{high_level_goal}}</p> <ul> <li>A clear, one-sentence description of the final outcome the user wants to achieve.</li> <li>Example: \"Create and document a pull request for the currently staged changes.\"</li> </ul> </li> <li> <p>Available Prompts: <pre><code>{{available_prompts}}\n</code></pre></p> <ul> <li>A list of candidate prompt names (e.g., from the output of <code>rank-root-prompts</code>).</li> <li>Example: ['pr-desc.md', 'commit-msg.md', 'changed-files.md', 'review.md', 'release-notes.md']</li> </ul> </li> <li> <p>Context (Optional): {{context}}</p> <ul> <li>Any additional context, such as the current state of the git repository or specific files of interest.</li> <li>Example: \"The user has already staged files using <code>git add</code>.\"</li> </ul> </li> </ul>"},{"location":"temp-prompts-refactored/prompt-sequence-generator/#instructions-for-the-ai","title":"Instructions for the AI","text":"<ol> <li> <p>Analyze the Goal: Deconstruct the <code>{{high_level_goal}}</code> into a series of logical steps required to get from the starting state to the final outcome.</p> </li> <li> <p>Map Prompts to Steps: For each logical step, identify the most suitable prompt from the <code>{{available_prompts}}</code> list that can perform that step.</p> <ul> <li>Consider the inputs and outputs of each prompt to determine dependencies. A prompt's input is often the output of a previous one.</li> </ul> </li> <li> <p>Establish Order: Arrange the selected prompts into a numbered sequence based on their dependencies. The sequence should represent a complete and logical workflow.</p> </li> <li> <p>Identify Gaps: If any necessary step in the workflow cannot be fulfilled by one of the available prompts, explicitly state what action or prompt is missing.</p> </li> </ol>"},{"location":"temp-prompts-refactored/prompt-sequence-generator/#required-output-format","title":"Required Output Format","text":"<p>Execution Sequence:</p> <ol> <li><code>[prompt_name_1.md]</code>: [Brief justification for why this prompt is first and what it accomplishes.]</li> <li><code>[prompt_name_2.md]</code>: [Brief justification for why this prompt is second, and how it uses the output of the previous step.]</li> <li>...</li> </ol> <p>Identified Gaps (if any):</p> <ul> <li>[Description of a missing step or prompt needed to complete the workflow.]</li> </ul>"},{"location":"temp-prompts-refactored/prototype-feature/","title":"Prototype Feature","text":"<p>Trigger: $1</p> <p>Purpose: $2</p>"},{"location":"temp-prompts-refactored/prototype-feature/#steps","title":"Steps","text":"<p>$3</p>"},{"location":"temp-prompts-refactored/prototype-feature/#output-format","title":"Output format","text":"<ul> <li>$4</li> </ul>"},{"location":"temp-prompts-refactored/query-set/","title":"Query set","text":"<p>High-Yield Query Generator</p> <p>Trigger: /query-set</p> <p>Purpose: Generate {1} targeted web search queries with operators, entity variants, and recency filters for a given objective.</p> <p>Steps: 1. Restate the goal with entities and time window. 2. Produce queries using operators: site:, filetype:, inurl:, quotes, OR, date filters. 3. Include synonyms and common misspellings. 4. Mix intents: {2}</p> <p>Output format: <pre><code>### Goal\n{3}\n\n### Query Set\n- {4}\n- {5}\n... up to 8\n</code></pre></p> <p>Examples: - Input: <code>/query-set {6} {7}</code> - Output: Goal + {8} queries with operators.</p> <p>Notes: - No evidence logging here. Use /research-item to execute.</p>"},{"location":"temp-prompts-refactored/rank-root-prompts/","title":"Rank root prompts","text":""},{"location":"temp-prompts-refactored/rank-root-prompts/#prompt-ranking-command","title":"{Prompt Ranking Command}","text":"<pre><code># Command: $1\n\n# Usage: $1 \"$2\" \"$3\" \"$4\"\n\n# Args:\n\n# - {{query}}: $2\n# - {{path}}: $3\n# - {{threshold}}: $4\n\nprompt = \"\"\"\nTask:\nGiven a user inquiry {{query}}, review prompt-definition files located at {{path}} and identify the most relevant ones.\n\nDefaults:\n* If {{path}} is missing or blank, use \"~/.codex/prompts\".\n\nDo the following:\n1) List files in {{path}} without descending into subfolders. Treat common doc/config extensions as candidates.\n2) Read each candidate\u2019s text and summarize its purpose + domain in one sentence.\n3) Compute a relevance score in [0,1] between that summary and {{query}}.\n4) Order all candidates by score (highest first).\n5) Emit a compact table with exactly these columns: filename | description | match_score (rounded to 2 decimals).\n\nRules:\n* The description must be 1\u20132 sentences capturing purpose and domain.\n* Only include rows with match_score \u2265 {{threshold}}.\n* If none satisfy {{threshold}}, output a single line: \"No prompt exceeds threshold {{threshold}} \u2014 recommend creating a new prompt.\"\n\nAcceptance:\n* When \u22651 match meets {{threshold}}, a table sorted by descending match_score is present.\n* Otherwise, the single-line note is produced.\n\n!{echo \"Using path: ${PATH_ARG:-~/.codex/prompts}\"}\n\"\"\"\n</code></pre>"},{"location":"temp-prompts-refactored/rank-root-prompts/#output-format","title":"Output format","text":"<ul> <li>Preferred: a markdown table with columns <code>filename | description | match_score</code> sorted by <code>match_score</code> (desc) and filtered by <code>{{threshold}}</code>.</li> <li> </li> </ul>"},{"location":"temp-prompts-refactored/rank-root-prompts/#fallback-the-exact-one-line-message-when-no-entries-meet-threshold","title":"Fallback: the exact one-line message when no entries meet <code>{{threshold}}</code>.","text":""},{"location":"temp-prompts-refactored/refactor-file/","title":"Refactor Analysis","text":"<p>Refactor Analysis</p> <ol> <li>Gather context by running <code>sed -n '1,400p' $1</code> for the first 400 lines of the file.</li> <li>Suggest refactors that reduce complexity and improve readability without changing behavior. Provide $2 with commentary.</li> <li>Synthesize insights into $5 with clear priorities and $7.</li> </ol> <p>Output Format</p> <ul> <li>Begin with a concise summary: $5</li> <li>Include $2 with commentary</li> <li>Document evidence: $3</li> </ul> <p>Note: $4 is implied by the refactoring goal but can be explicitly stated for clarity</p>"},{"location":"temp-prompts-refactored/refactor-suggestions/","title":"Refactor Suggestions","text":"<p>Trigger: $1</p> <p>Purpose: $2</p>"},{"location":"temp-prompts-refactored/refactor-suggestions/#steps","title":"Steps","text":"<p>$3</p>"},{"location":"temp-prompts-refactored/refactor-suggestions/#output-format","title":"Output format","text":"<p>$4</p>"},{"location":"temp-prompts-refactored/refactor-suggestions/#affected-files","title":"Affected files","text":""},{"location":"temp-prompts-refactored/refactor-suggestions/#root-cause","title":"Root cause","text":""},{"location":"temp-prompts-refactored/refactor-suggestions/#proposed-fix","title":"Proposed fix","text":""},{"location":"temp-prompts-refactored/refactor-suggestions/#tests","title":"Tests","text":""},{"location":"temp-prompts-refactored/refactor-suggestions/#docs-gaps","title":"Docs gaps","text":""},{"location":"temp-prompts-refactored/refactor-suggestions/#open-questions","title":"Open questions","text":"<ul> <li>$1 = Trigger (e.g., /refactor-suggestions)</li> <li>$2 = Purpose (e.g., Propose repo-wide refactoring opportunities after tests exist)</li> <li>$3 = Steps (e.g., Map directory structure and large files. \\n2. Identify duplication, data clumps, and god objects. \\n3. Suggest phased refactors with safety checks and tests.)</li> <li>$4 = Output format (e.g., Ranked list with owners and effort estimates.)</li> </ul>"},{"location":"temp-prompts-refactored/reference-implementation/","title":"Reference implementation","text":"<p>How-to</p>"},{"location":"temp-prompts-refactored/reference-implementation/#1","title":"$1","text":"<p>Trigger: $2</p> <p>Purpose: $3</p>"},{"location":"temp-prompts-refactored/reference-implementation/#steps","title":"Steps","text":"<ol> <li>$4</li> <li>$5</li> <li>$6</li> </ol>"},{"location":"temp-prompts-refactored/reference-implementation/#output-format","title":"Output format","text":"<ul> <li>$7</li> </ul>"},{"location":"temp-prompts-refactored/regression-guard/","title":"Regression guard","text":"<p>Regression Guard</p> <p>Trigger: $1</p> <p>Purpose: $2</p>"},{"location":"temp-prompts-refactored/regression-guard/#steps","title":"Steps","text":"<p>$3 $4 $5</p>"},{"location":"temp-prompts-refactored/regression-guard/#output-format","title":"Output format","text":"<p>$6</p>"},{"location":"temp-prompts-refactored/regression-guard/#notes","title":"Notes","text":"<p>$7</p>"},{"location":"temp-prompts-refactored/regression-guard/#affected-files","title":"Affected files","text":""},{"location":"temp-prompts-refactored/regression-guard/#root-cause","title":"Root cause","text":""},{"location":"temp-prompts-refactored/regression-guard/#proposed-fix","title":"Proposed fix","text":""},{"location":"temp-prompts-refactored/regression-guard/#tests","title":"Tests","text":""},{"location":"temp-prompts-refactored/regression-guard/#docs-gaps","title":"Docs gaps","text":""},{"location":"temp-prompts-refactored/regression-guard/#open-questions","title":"Open questions","text":""},{"location":"temp-prompts-refactored/release-notes-prepare/","title":"Prepare Release Notes From CHANGELOG","text":"<p>Trigger: <code>/release-notes-prepare</code></p> <p>Purpose: Convert the latest CHANGELOG section into release notes suitable for GitHub Releases with the six-section layout.</p> <p>Steps:</p> <ol> <li>Detect latest version heading and extract its section.</li> <li>Normalize bullets to sentence fragments without trailing periods.</li> <li>Add short highlights at top (3 bullets max) derived from Added/Changed.</li> <li>Emit a \"copy-ready\" Markdown body.</li> </ol> <p>Output format:</p> <ul> <li>Title line: <code>Release ${1} \u2014 ${2}</code></li> <li>Highlights list</li> <li>Six sections with bullets</li> </ul> <p>${1}=Version (e.g., 1.6.0) ${2}=Release date (e.g., 2025-09-22) ${3}=Highlight 1 (e.g., Custom roles and permissions) ${4}=Highlight 2 (e.g., Faster cold starts) ${5}=Highlight 3 (optional) ${6}=Added section content ${7}=Changed section content</p> <p>Note: This template follows the six-section layout (Added, Changed, Removed, Fixed, Improved, Deprecated). Missing sections like Removed, Fixed, Improved, Deprecated are implied by the context and will be populated with the appropriate content from CHANGELOG.</p>"},{"location":"temp-prompts-refactored/release-notes/","title":"Release notes","text":""},{"location":"temp-prompts-refactored/release-notes/#how-to-generate-release-notes","title":"How to Generate Release Notes","text":"<p>Trigger: /release-notes $1</p> <p>Purpose: Generate human-readable release notes from recent commits.</p> <p>You are a CLI assistant focused on helping contributors with the task: Generate human\u2011readable release notes from recent commits.</p> <ol> <li>Gather context by running <code>git log --pretty='* %s (%h) \u2014 %an' --no-merges $2</code> for the commit log (no merges).</li> <li>Produce release notes grouped by type $3. Include a Highlights section and a full changelog list.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary: $6</li> <li>Document the evidence: $7</li> </ul> <p>Example Input: $4</p> <p>Expected Output:</p>"},{"location":"temp-prompts-refactored/release-notes/#3","title":"$3","text":"<ul> <li>$5</li> </ul>"},{"location":"temp-prompts-refactored/research-batch/","title":"Research batch","text":"<p>Conversation-Aware Research \u2014 Batch WBRO</p> <p>Trigger: $1</p> <p>Purpose: Process a numbered work-breakdown list of objectives with carry-forward context across items and produce a roll-up summary.</p> <p>Steps:</p> <ol> <li>Parse numbered WBRO items from the input after the trigger.</li> <li>Before Item 1: list \u22645 bullets of starting context.</li> <li>For each item i: execute the per-item workflow and include a Conversation State Update.</li> <li>If blocked by prior gaps, emit Dependency Blocked with a minimal micro-query.</li> <li>After all items: emit a Roll-up Summary with per-item status, enabled decisions, unresolved risks, and a domain-type count of sources.</li> </ol> <p>Output format:</p> <ul> <li>Repeat the single-item format per item.</li> <li>End with:</li> </ul> <pre><code>## Roll-up Summary\n- Item $2: $3 \u2014 decision enabled: $4; risks: $5\n- Sources by domain type: $6, $7\n</code></pre> <p>Examples: - Input: <code>/research-batch $1</code> - Output: Per-item sections plus roll-up.</p> <p>Notes: - Keep quotes \u226425 words. Prefer primary docs.</p> <ul> <li>$1: Input WBRO items (e.g., \"1) Validate Next.js 15 stability. 2) Compare Bun vs Node for CI. 3) Licensing risks for MIT vs Apache-2.0.\")</li> <li>$2: Item number (e.g., \"1\")</li> <li>$3: Status (e.g., \"Completed\")</li> <li>$4: Enabled decisions (e.g., \"Validate Next.js 15\")</li> <li>$5: Unresolved risks (e.g., \"Licensing conflicts\")</li> <li>$6: Domain type count (e.g., \"3\")</li> <li>$7: Domain types (e.g., \"gov, org, docs, blog, news\") --&gt;</li> </ul>"},{"location":"temp-prompts-refactored/research-item/","title":"Research item","text":"<p>Conversation-Aware Research</p>"},{"location":"temp-prompts-refactored/research-item/#conversation-aware-research-single-item","title":"Conversation-Aware Research \u2014 Single Item","text":"<p>Trigger: /research-item</p> <p>Purpose: Run the full per-item research workflow for one objective and return queries, evidence, synthesis, contradictions, gaps, decision hook, plus a conversation state update.</p> <p>Steps: 1. Read the objective text following the trigger. 2. Capture starting context if provided. 3. Apply the Process (per item): Goal, Assumptions, Query Set (4\u20138), Search Plan, Run &amp; Capture, Cross-check, Synthesis, Gaps &amp; Next, Decision Hook. 4. Track PubDate and Accessed (ISO) for every source; prefer primary docs. 5. Enforce quotes \u226425 words; mark inferences as \"Inference\".</p> <p>Output format:</p> <pre><code>## Item 1: $1\n\n### Goal\n$2\n\n### Assumptions\n- $3\n\n### Query Set\n- $4\n- $5\n- $6\n- $7\n\n### Evidence Log\n| SourceID | Title | Publisher | URL | PubDate | Accessed | Quote (\u226425w) | Finding | Rel | Conf |\n|---|---|---|---|---|---|---|---|---|---|\n\n### Synthesis\n- $8\n- $9\n- $10\n\n### Contradictions\n- $11 \u2192 $12\n\n### Gaps &amp; Next\n- $13\n\n### Decision Hook\n$14\n\n### Conversation State Update\n- New facts: $15\n- Constraints learned: $16\n- Entities normalized: $17\n</code></pre> <p>Examples: - Input: <code>/research-item Compare OpenAPI 3.1 tooling for Python clients in 2024; budget $0; prefer official docs.</code> - Output: As per format with SourceIDs and dates.</p> <p>Notes: - Safety: No personal data. Do not fabricate sources. - Provenance: Cite reputable sources; record n/a for missing PubDate.</p>"},{"location":"temp-prompts-refactored/reset-strategy/","title":"Reset Strategy","text":"<p>Trigger: $1</p> <p>Purpose: $2</p>"},{"location":"temp-prompts-refactored/reset-strategy/#steps","title":"Steps","text":"<p>$3 $4 $5 $6</p>"},{"location":"temp-prompts-refactored/reset-strategy/#output-format","title":"Output format","text":"<ul> <li>A short decision note and exact commands. Never execute resets automatically.</li> </ul>"},{"location":"temp-prompts-refactored/reset-strategy/#examples","title":"Examples","text":"<ul> <li>Recommend reset after repeated failing refactors touching $7</li> </ul>"},{"location":"temp-prompts-refactored/reset-strategy/#notes","title":"Notes","text":"<ul> <li>Warn about destructive nature. Require user confirmation.</li> </ul>"},{"location":"temp-prompts-refactored/reset-strategy/#missing-sections-inferred-for-analysis-context","title":"Missing Sections (Inferred for Analysis Context)","text":"<ul> <li>Affected files: $8</li> <li>Root cause: $9</li> <li>Proposed fix: $10</li> <li>Tests: $11</li> <li>Docs gaps: $12</li> <li>Open questions: $13</li> </ul>"},{"location":"temp-prompts-refactored/review-branch/","title":"Review branch","text":"<p>/*</p> <p>Placeholder mapping: $1 = Trigger $2 = Purpose $3 = Step 1 description $4 = Step 2 description $5 = Step 3 description $6 = Output requirements $7 = Example input (if applicable) */</p>"},{"location":"temp-prompts-refactored/review-branch/#template_name-or-inferred-name","title":"{template_name or Inferred Name}","text":"<p>{Trigger}</p> <p>{Purpose}</p> <ol> <li>{Step 1}</li> <li>{Step 2}</li> <li>{Step 3}</li> </ol> <p>{Output Requirements}</p> <p>{Example Input}</p>"},{"location":"temp-prompts-refactored/review-branch/#analysis","title":"Analysis","text":"<ul> <li>Affected files: {Affected files}</li> <li>Root cause: {Root cause}</li> <li>Proposed fix: {Proposed fix}</li> <li>Tests: {Tests}</li> <li>Docs gaps: {Docs gaps}</li> <li>Open questions: {Open questions}</li> </ul>"},{"location":"temp-prompts-refactored/review-branch/#output-format","title":"Output format","text":"<ul> <li>{Output format requirement}</li> </ul> <p>Note: Placeholders marked with <code>$1..$7</code> are to be filled with context-specific content from the input.</p>"},{"location":"temp-prompts-refactored/review/","title":"Review","text":"<p>Trigger: $1</p> <p>Purpose: Review code matching $1 and deliver actionable feedback.</p> <p>You are a CLI assistant focused on helping contributors with the task: Review code matching $1 and give actionable feedback.</p> <ol> <li>Gather context by running <code>rg -n $2 . || grep -RIn $2 .</code> for the search results for $2 (filename or regex).</li> <li> <p>Perform a thorough code review. Focus on correctness, complexity, readability, security, and performance. Provide concrete patch suggestions.</p> </li> <li> <p>Synthesize the insights into the requested format with clear priorities and next steps.</p> </li> </ol> <p>Output: - Begin with a concise summary that restates the goal: Review code matching $1 and give actionable feedback. - Provide unified diff-style patches when recommending code changes. - Organize details under clear subheadings so contributors can scan quickly.</p> <p>Example Input: $3</p> <p>Expected Output: - Usage cluster in src/network/* with note on inconsistent error handling.</p>"},{"location":"temp-prompts-refactored/roll-up/","title":"Roll-up","text":""},{"location":"temp-prompts-refactored/roll-up/#research-roll-up-summary","title":"Research Roll-up Summary","text":"<p>Trigger: $1</p> <p>Purpose: $2</p> <p>Steps: 1. $3 2. $4 3. $5</p> <p>Output format: <pre><code>## Roll-up Summary\n- Item {n}: {status} \u2014 decision enabled: {\u2026}; risks: {\u2026}\n- Sources by domain type: {gov:X, org:Y, docs:Z, blog:A, news:B, academic:C}\n</code></pre></p> <p>Examples: - Input: $7 - Output: [see above]</p> <p>Notes: - Domain Count Analysis: $6 (explain why counts vary across domains) - Evidence Log Reference: Use counts derived from the Evidence Logs</p>"},{"location":"temp-prompts-refactored/scaffold-fullstack/","title":"Scaffold Full\u2011Stack App","text":"<p>Trigger: $1</p> <p>Purpose: $2</p> <p>Steps:</p> <ol> <li>Read repository context: <code>git rev-parse --is-inside-work-tree</code>.</li> <li>If repo is empty, initialize: <code>git init -b main</code> and create <code>.editorconfig</code>, <code>.gitignore</code>, <code>README.md</code>.</li> <li>For $3 derive presets (examples):</li> <li><code>$4</code>: Next.js app, Express API, Prisma + PostgreSQL, Playwright, pnpm workspaces.</li> <li><code>$5</code>: Vite + React app, Fastify API, Drizzle + SQLite.</li> <li>Create workspace layout:</li> <li>root: <code>package.json</code> with <code>pnpm</code> workspaces, <code>tsconfig.base.json</code>, <code>eslint</code>, <code>prettier</code>.</li> <li>apps/web, apps/api, packages/ui, packages/config.</li> <li>Add scripts:</li> <li>root: <code>dev</code>, <code>build</code>, <code>lint</code>, <code>typecheck</code>, <code>test</code>, <code>e2e</code>, <code>format</code>.</li> <li>web: Next/Vite scripts. api: dev with ts-node or tsx.</li> <li>Seed CI files: <code>.github/workflows/ci.yml</code> with jobs [lint, typecheck, test, build, e2e] and artifact uploads.</li> <li>Add example routes:</li> <li>web: <code>/health</code> page. api: <code>GET /health</code> returning <code>{ ok: true }</code>.</li> <li>Write docs to <code>README.md</code>: how to run dev, test, build, and env variables.</li> <li>Stage files, but do not commit. Output a tree and next commands.</li> </ol> <p>Output format: - Title line: <code>Scaffold created: $6</code> - Sections: <code>Repo Tree</code>, <code>Next Steps</code>, <code>CI Seeds</code>. - Include a fenced code block of the <code>tree</code> and sample scripts.</p> <p>Examples: - Input: <code>$7</code> Output: Summary + tree with <code>apps/web</code>, <code>apps/api</code>, <code>packages/ui</code>. - Input: <code>$8</code> Output: Summary + tree + Drizzle config.</p> <p>Notes: - Assume pnpm and Node 20+. Do not run package installs automatically; propose commands instead. - Respect existing files; avoid overwriting without explicit confirmation.</p> <ul> <li>$1 = trigger command</li> <li>$2 = purpose statement</li> <li>$3 = stack preset name</li> <li>$4 = example preset description</li> <li>$5 = alternative example preset description</li> <li>$6 = output title suffix</li> <li>$7 = example input command</li> <li>$8 = alternative example input command --&gt;</li> </ul>"},{"location":"temp-prompts-refactored/scope-control/","title":"Scope control","text":"<p>/ Placeholder mapping: $1 = Trigger $2 = Purpose $3 = Steps $4 = Output format $5 = Example input $6 = Example output $7 = Notes /</p> <p>Scope Control</p> <p>$1</p> <p>Purpose: $2</p> <p>Steps: 1. $3 2. $4 3. $5 4. $6</p> <p>Output format: $7</p>"},{"location":"temp-prompts-refactored/scope-control/#examples","title":"Examples","text":"<ul> <li>Input: $1</li> <li>Output: $2</li> </ul>"},{"location":"temp-prompts-refactored/scope-control/#notes","title":"Notes","text":"<ul> <li>$3</li> </ul>"},{"location":"temp-prompts-refactored/secrets-manager-setup/","title":"Secrets manager setup","text":"<p>$2</p> <p>Trigger: $1</p> <p>Purpose: $2</p> <p>Steps:</p> <p>$3</p> <p>Output format: $4</p> <p>Examples: $5</p> <p>Notes: $6</p> <p>Affected files: (to be filled) Root cause: (to be filled) Proposed fix: (to be filled) Tests: (to be filled) Docs gaps: (to be filled) Open questions: (to be filled)</p>"},{"location":"temp-prompts-refactored/secrets-scan/","title":"Secrets scan","text":"<p>Secrets Scan Analysis</p> <ol> <li>Gather context by running <code>$2</code> for the if <code>$2</code> is available, output will appear below.</li> <li>Interpret the scanner results using <code>$3</code> to de\u2011dupe false positives and propose rotations/remediation.</li> <li>Synthesize the insights into <code>$4</code> with clear priorities and next steps.</li> </ol> <p>Output: - Begin with a concise summary restating <code>$1</code> - Offer prioritized, actionable recommendations with rationale - Document the evidence used for maintainers' trust</p> <p>Example Input: $5</p> <p>Expected Output: $6</p> <p>Affected files:  Root cause:  Proposed fix:  Tests:  Docs gaps:  Open questions:</p>"},{"location":"temp-prompts-refactored/slo-setup/","title":"SLO setup","text":"<p>$1</p> <p>Trigger: $2</p> <p>Purpose: $3</p> <p>Steps:</p> <p>$4</p> <p>Output format: $5</p> <p>Examples: $6</p> <p>Notes: $7</p>"},{"location":"temp-prompts-refactored/stack-evaluation/","title":"Stack evaluation","text":"<p>$1</p> <p>Trigger: $2</p> <p>Purpose: $3</p>"},{"location":"temp-prompts-refactored/stack-evaluation/#steps","title":"Steps","text":"<ol> <li>$4</li> <li>$5</li> <li>$6</li> </ol>"},{"location":"temp-prompts-refactored/stack-evaluation/#output-format","title":"Output format","text":"<ul> <li>$7</li> </ul>"},{"location":"temp-prompts-refactored/stop-guessing/","title":"stop guessing","text":"<p>$1</p> <p>Respond with a JSON object in the following order of fields: <code>reasoning</code>, then <code>template_markdown</code>.</p>"},{"location":"temp-prompts-refactored/summary-1/","title":"Inferred Analysis Template","text":"<p>You are a CLI assistant helping contributors with the task: $1.</p> <ol> <li>Context sweep. Derive a repository map by running \\(2** (first N entries are sufficient). Review **\\)3 for primary documentation.</li> <li>Draft the summary. Organize findings under $4, $5, $6, $7.</li> <li>Synthesize. Present a prioritized, action-oriented report with immediate next steps.</li> </ol>"},{"location":"temp-prompts-refactored/summary-1/#report-structure","title":"Report Structure","text":""},{"location":"temp-prompts-refactored/summary-1/#4","title":"$4","text":"<ul> <li>\u2026</li> </ul>"},{"location":"temp-prompts-refactored/summary-1/#5","title":"$5","text":"<ul> <li>\u2026</li> </ul>"},{"location":"temp-prompts-refactored/summary-1/#6","title":"$6","text":"<ul> <li>\u2026</li> </ul>"},{"location":"temp-prompts-refactored/summary-1/#7","title":"$7","text":"<ol> <li>\u2026</li> <li>\u2026</li> <li>\u2026</li> </ol>"},{"location":"temp-prompts-refactored/summary-1/#evidence-consulted","title":"Evidence Consulted","text":"<ul> <li>Repo map derived via: $2</li> <li>Docs reviewed: $3</li> <li>Noteworthy gaps or uncertainties: \u2026</li> </ul>"},{"location":"temp-prompts-refactored/summary-1/#next-steps-prioritized","title":"Next Steps (Prioritized)","text":"<ol> <li>\u2026</li> <li>\u2026</li> <li>\u2026</li> </ol>"},{"location":"temp-prompts-refactored/summary-1/#open-questions","title":"Open Questions","text":"<ul> <li>\u2026</li> <li>\u2026</li> </ul>"},{"location":"temp-prompts-refactored/summary-1/#output-format-for-automation-and-reviews","title":"Output format (for automation and reviews)","text":"<ul> <li>Audience: contributors and maintainers</li> <li>Tone: concise, decision-ready</li> <li>Must include: goal recap (\\(1**), sections (**\\)4\u2013$7), evidence, priorities, open questions</li> <li>Nice to have: links to code paths, brief risk notes</li> </ul> <p>Validation checklist * [ ] All required sections present * [ ] Evidence lists commands/files used (\\(2**, **\\)3) * [ ] Priorities and next steps are explicit * [ ] Open questions are called out clearly</p>"},{"location":"temp-prompts-refactored/summary-2/","title":"Summary 2","text":""},{"location":"temp-prompts-refactored/summary-2/#1","title":"$1","text":"<p>You are a CLI helper guiding contributors to accomplish: $1.</p>"},{"location":"temp-prompts-refactored/summary-2/#scope-role","title":"Scope &amp; Role","text":"<ul> <li>Operate in a repository working tree.</li> <li>Run lightweight, read-only commands to gather context.</li> <li>Synthesize findings into a concise, maintainer-friendly report.</li> </ul>"},{"location":"temp-prompts-refactored/summary-2/#procedure","title":"Procedure","text":"<ol> <li>Map the repo (quick scan) \u2014 run $2 to capture a top-slice of the file tree for orientation.</li> <li>Locate key docs \u2014 check the paths in $3 (if present) for project-level guidance.</li> <li>Summarize the project \u2014 draft a high-level overview covering:</li> <li>Purpose (what it is)</li> <li>Motivation (why it exists)</li> <li>Architecture/Workflow (how it works at a glance)</li> <li>Getting Started (how to begin using/developing)</li> <li>Prioritize next steps \u2014 identify immediate follow-ups for readers (e.g., areas to explore, gaps to fill).</li> <li>Record evidence \u2014 note exactly what you inspected so maintainers can verify.</li> </ol>"},{"location":"temp-prompts-refactored/summary-2/#output","title":"Output","text":"<p>Begin with a one-sentence restatement of $1, then provide the sections below in order:</p> <ul> <li>Project Summary \u2014 purpose, motivation, architecture/workflow, getting started.</li> <li>Repo Snapshot \u2014 brief map excerpt from $2 (top of tree only).</li> <li>Evidence Log \u2014 list the commands run and files/paths reviewed, including $3.</li> <li>Priorities &amp; Next Steps \u2014 the most important actions to take next (short list).</li> </ul>"},{"location":"temp-prompts-refactored/summary-2/#example-input","title":"Example Input","text":"<p>(no arguments; run from the repo root)</p>"},{"location":"temp-prompts-refactored/summary-2/#expected-result","title":"Expected Result","text":"<p>A structured report following the Output section above, optimized for README-level clarity and trustworthiness.</p>"},{"location":"temp-prompts-refactored/summary-2/#output-format-strict","title":"Output format (strict)","text":"<p>Provide sections exactly in this order: Project Summary \u2192 Repo Snapshot \u2192 Evidence Log \u2192 Priorities &amp; Next Steps. Keep each section concise and actionable.</p>"},{"location":"temp-prompts-refactored/summary/","title":"Summary","text":"<p>Repository Summary Generator</p> <ol> <li>Gather context by running <code>$1</code> for the repo map.</li> <li>Generate a high-level summary covering <code>$3</code>.</li> <li>Document evidence used to maintain trust in conclusions per <code>$4</code>.</li> <li>Output a structured report following <code>$5</code>.</li> </ol>"},{"location":"temp-prompts-refactored/switch-model/","title":"Switch model","text":"<p>Switch Model</p> <p>Trigger: $1</p> <p>Purpose: Decide when to try a different AI backend and how to compare.</p>"},{"location":"temp-prompts-refactored/switch-model/#steps","title":"Steps","text":"<ol> <li>Define task type: $2</li> <li>Select candidate models and temperature/tooling options.</li> <li>Run a fixed input suite: $3 and measure $4.</li> <li>Recommend a model per task: $5 with $6.</li> </ol>"},{"location":"temp-prompts-refactored/switch-model/#output-format","title":"Output format","text":"<ul> <li>Table: task \u2192 model \u2192 settings \u2192 $7.</li> </ul>"},{"location":"temp-prompts-refactored/system-level-instruction-editor/","title":"System-level instruction editor","text":"<p>System-Level Instruction Editor</p> <p>Trigger: $1</p> <p>Purpose: $2</p>"},{"location":"temp-prompts-refactored/system-level-instruction-editor/#inputs","title":"Inputs","text":"<ul> <li>$3</li> </ul>"},{"location":"temp-prompts-refactored/system-level-instruction-editor/#steps","title":"Steps","text":"<ol> <li>$4</li> <li>$5</li> <li> <p>$6</p> </li> <li> <p>Deconstruct the request: $7</p> </li> <li> <p>Locate insertion points: Use semantic matching on headings and content to find the best-fit sections for the user\u2019s request. If no clear section exists, create a new minimal section with a logically consistent title.</p> </li> <li> <p>Apply minimal change: Insert or modify content to satisfy the request while preserving tone, structure, and cross-references. Keep unrelated sections unchanged.</p> </li> <li> <p>Run invariants:</p> </li> <li> <p>The entire file must be present (no placeholders, no truncation).</p> </li> <li>Markdown structure and formatting must remain valid.</li> <li> <p>Internal references and links stay accurate.</p> </li> <li> <p>Render in Canvas:</p> </li> <li> <p>If editing an existing file: open in Canvas and replace the full contents with the updated version.</p> </li> <li> <p>If creating a new file: create it in Canvas and display the entire file.</p> </li> <li> <p>Variants (optional): Generate $1.md and/or $2.md from the updated $3.md using only the Platform Substitution Rules. Render each variant\u2019s entire file in Canvas (one file per Canvas operation).</p> </li> <li> <p>Size-limit fallback: If a size cap prevents full-file rendering in Canvas, output the entire file in chat, then append:</p> </li> <li> <p>\"Note: Full content was output in chat due to a size limit preventing Canvas rendering.\"</p> </li> </ol>"},{"location":"temp-prompts-refactored/system-level-instruction-editor/#output-format","title":"Output format","text":"<ul> <li>Table: $1 \u2192 $2 \u2192 $3 \u2192 $4 \u2192 $5</li> </ul>"},{"location":"temp-prompts-refactored/system-level-instruction-editor/#example-rows","title":"Example rows","text":"<ul> <li>\"\" \u2192 $6 \u2192 $7 \u2192 $1 \u2192 $2"},{"location":"temp-prompts-refactored/tm-advance/","title":"TM \u00b7 advance","text":"<p>Advance Task Plan Generator</p> <p>Trigger: For given $1, produce a concrete work plan, acceptance criteria, tests, and a Conventional Commits message to move status toward done.</p> <p>Purpose: For given task id(s), produce a concrete work plan, acceptance criteria, tests, and a Conventional Commits message to move status toward done.</p> <p>Steps:</p> <ol> <li>Read tasks.json; resolve each provided $1. If none provided, pick the top item from /tm-next.</li> <li>For each task: restate $2, goals, and related dependencies.</li> <li>Draft a step-by-step plan with $4 and $5.</li> <li>Provide a minimal commit plan and a Conventional Commits message ($7).</li> <li>List measurable acceptance criteria ($6).</li> </ol> <p>Output format:</p> <ul> <li>One section per task: \"## $1 \u2014 $2\"</li> <li>Subsections: Plan, Files, Tests, Acceptance, Commit Message ($7), Risks.</li> </ul> <p>Notes: - Do not mutate tasks.json. Emit proposed changes only.</p>"},{"location":"temp-prompts-refactored/tm-blockers/","title":"TM \u00b7 blockers","text":"<p>Blocker Diagnosis Template</p> <p>$1</p> <p>$2</p> <p>$3</p> <p>$4</p> <p>$5</p> <p>$6</p>"},{"location":"temp-prompts-refactored/tm-blockers/#blocker-report-7","title":"Blocker Report: $7","text":"<p>Tables: blockers (type | item | evidence), actions (step | owner | effort | success_criteria).</p>"},{"location":"temp-prompts-refactored/tm-ci/","title":"TM \u00b7 CI","text":""},{"location":"temp-prompts-refactored/tm-ci/#citest-checklist-template","title":"CI/Test Checklist Template","text":""},{"location":"temp-prompts-refactored/tm-ci/#analysis","title":"Analysis","text":"<ul> <li>[ ] Affected files</li> <li>[ ] Root cause</li> <li>[ ] Proposed fix</li> <li>[ ] Tests</li> <li>[ ] Docs gaps</li> <li>[ ] Open questions</li> </ul>"},{"location":"temp-prompts-refactored/tm-ci/#how-to-steps","title":"How-to Steps","text":"<ol> <li>Compute ready tasks (see $3) and collect testStrategy fields.</li> <li>Group by $4; otherwise by path keywords in titles.</li> <li>Propose CI jobs and test commands with approximate runtimes and gating rules ($5).</li> <li>Include a smoke-test matrix ($6) and minimal code coverage targets if relevant.</li> </ol> <p>Output format:</p> <ul> <li>\"# CI Plan\"</li> <li>Tables: jobs (\\(5) and tests (\\)6)</li> <li>\"## Risk Areas\" ($7)</li> </ul> <p>Examples:</p> <ul> <li>Input: $1</li> <li>Output: one CI plan with 3\u20138 jobs and a test table.</li> </ul> <p>Notes:</p> <ul> <li>Non-binding guidance. Adapt to the repo\u2019s actual CI system.</li> </ul>"},{"location":"temp-prompts-refactored/tm-delta/","title":"$1 \u2192 Tasks Delta","text":"<p>Trigger: $2</p> <p>Purpose: Compare $1 against tasks.json and propose add/update/remove operations.</p> <p>Steps:</p> <p>$3. Extract $4, $5, $6, and $7 from $1. $4. Map them to existing tasks by fuzzy match on title and keywords; detect gaps.</p> <p>Propose: new tasks, updates to titles/descriptions/priority, and deprecations.</p> <p>Output format:</p> <ul> <li>\"# Delta Summary\"</li> <li>Tables: adds | updates | removals.</li> <li>\"## JSON Patch\" with an ordered list of operations: add/replace/remove.</li> <li>\"## Assumptions\" and \"## Open Questions\".</li> </ul> <p>Examples:</p> <ul> <li>Input: $2</li> <li>Output: tables with a small JSON Patch block.</li> </ul> <p>Notes:</p> <ul> <li>Keep patches minimal and reversible. Flag any destructive changes explicitly.</li> </ul>"},{"location":"temp-prompts-refactored/tm-docs/","title":"TM \u00b7 docs","text":"<p>Project Status Docs</p>"},{"location":"temp-prompts-refactored/tm-docs/#generate-status-docs","title":"Generate Status Docs","text":"<p>Trigger: $1</p> <p>Purpose: $2</p> <p>Steps: 1. $3 2. $4 3. $5 4. $6</p> <p>Output format: - $7</p> <p>Examples: - $8</p> <p>Notes: - $9</p> <p>Analysis - [ ] Affected files: [list] - [ ] Root cause: [reason] - [ ] Proposed fix: [solution] - [ ] Tests: [test cases] - [ ] Docs gaps: [missing sections] - [ ] Open questions: [questions]</p> <p>Root cause - [ ] Identifying factors: [list]</p> <p>Proposed fix - [ ] Action items: [list]</p> <p>Tests - [ ] Test cases: [list]</p> <p>Docs gaps - [ ] Missing sections: [list]</p> <p>Open questions - [ ] Unresolved issues: [list]</p>"},{"location":"temp-prompts-refactored/tm-next/","title":"Next Ready Tasks","text":"<p>Trigger: $1</p> <p>Purpose: $2</p> <p>Steps:</p> <ol> <li>$3</li> <li>$4</li> <li>$5</li> <li>$6</li> </ol> <p>Output format:</p> <ul> <li>\"$7\"</li> <li>Table: id | title | priority | why_ready | prereqs</li> <li>\"## Notes\" for tie-break rules and data gaps.</li> </ul> <p>Examples:</p> <ul> <li>Input: $8</li> <li>Output: $9</li> </ul> <p>Notes:</p> <ul> <li>Treat missing or null priority as $10. If custom scales exist, describe them in Notes.</li> </ul> <p>$1: Trigger (e.g., \"/tm-next\") $2: Purpose (brief description) $3: Step 1 (algorithmic step) $4: Step 2 (algorithmic step) $5: Step 3 (algorithmic step) $6: Step 4 (algorithmic step) $7: Output format description $8: Example input format $9: Example output format $10: Default priority value</p>"},{"location":"temp-prompts-refactored/tm-overview/","title":"TaskMaster Overview","text":"<p>Trigger: $1</p> <p>Purpose: $2</p> <p>Steps: 1. Locate the active tasks.json at repo root or the path supplied in the user message. Do not modify it. 2. Parse fields: id, title, description, status, priority, dependencies, subtasks. 3. Compute counts per status and a table of top pending items by priority. 4. Detect dependency issues: cycles, missing ids, orphans (no deps and not depended on). 5. Approximate a critical path: longest dependency chain among pending\u2192in_progress tasks.</p> <p>Output format: $3</p> <p>Examples: - Input: $4 - Output: $5</p> <p>Notes: - $6: Read-only. Assume statuses: pending | in_progress | blocked | done. - If tasks.json is missing or invalid, output an \"## Errors\" section with a concise diagnosis.</p> <p>$1 = Task description $2 = Purpose statement $3 = Output format specification $4 = Example input format $5 = Expected output structure $6 = Critical path details (optional) --&gt;</p>"},{"location":"temp-prompts-refactored/tm-refine/","title":"TM \u00b7 refine","text":"<p>Refine Task into Subtasks</p> <p>Trigger: /tm-refine</p> <p>Purpose: Expand a vague or large task into actionable subtasks with clear acceptance criteria.</p> <p>Steps:</p> <ol> <li>Load the task by $1 and analyze description for ambiguity and scope.</li> <li>Propose 3\u20138 subtasks with titles, brief descriptions, and dependencies between them.</li> <li>Define acceptance criteria per subtask using Given/When/Then or bullet checks.</li> <li>Suggest test coverage and doc updates triggered by completion.</li> </ol> <p>Output format:</p> <ul> <li>\"# Refinement: $1\"</li> <li>Subtasks as a Markdown table: $2</li> <li>\"## JSON Patch\" fenced code of suggested additions suitable for tasks.json editing: $3</li> </ul> <p>Examples:</p> <ul> <li>Input: /tm-refine $1</li> <li>Output: $2 plus a minimal JSON Patch array.</li> </ul> <p>Constraints: - Do not assume authority to change files; provide patches the user can apply.</p>"},{"location":"temp-prompts-refactored/todo-report/","title":"TODO report","text":"<p>CLI Assistant Prompt for TODO Triage</p> <p>You are a CLI assistant focused on helping contributors with the task: $1.</p> <ol> <li>Gather context by running $2.</li> <li>Aggregate and group TODO/FIXME/XXX by $3.</li> <li>Propose a triage plan: $4.</li> </ol> <p>Output: - Begin with a concise summary that restates the goal: $5. - Offer prioritized, actionable recommendations with rationale: $6. - Organize details under clear subheadings: $7.</p>"},{"location":"temp-prompts-refactored/todos/","title":"TODOs","text":"<p>How-to: Find and group TODO/FIXME annotations</p> <ol> <li>Gather context by running <code>$1</code>.</li> <li>Find and group TODO/FIXME annotations.</li> <li>$3</li> </ol> <p>Output:</p> <ul> <li>Begin with a concise summary that restates the goal: Find and group TODO/FIXME annotations.</li> <li>Document the evidence you used so maintainers can trust the conclusion.</li> </ul> <p>Example Input: $5</p> <p>Expected Output: $4</p>"},{"location":"temp-prompts-refactored/tsconfig-review/","title":"TSConfig review","text":"<p>CLI Assistant Task: Review tsconfig</p> <p>You are a CLI assistant focused on helping contributors with the task: $1</p> <ol> <li>Gather context by inspecting $2.</li> <li>Provide recommendations for module/target, strictness, paths, incremental builds.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output</p> <ul> <li>Begin with a concise summary that restates the goal: $1</li> <li>Offer prioritized, actionable recommendations with rationale: $3</li> <li>Document the evidence you used so maintainers can trust the conclusion: $4</li> </ul> <p>Example - Input: $5 - Expected Output: $6</p>"},{"location":"temp-prompts-refactored/tsconfig-review/#optional-sections-for-analysis-tasks","title":"Optional sections (for analysis tasks)","text":"<ul> <li>[ ] Affected files</li> <li>[ ] Root cause</li> <li>[ ] Proposed fix</li> <li>[ ] Tests</li> <li>[ ] Docs gaps</li> <li>[ ] Open questions</li> </ul>"},{"location":"temp-prompts-refactored/ui-screenshots/","title":"UI screenshots","text":"<p>UI Screenshots Analysis</p> <p>Trigger: $2</p> <p>Purpose: $3</p>"},{"location":"temp-prompts-refactored/ui-screenshots/#steps","title":"Steps","text":"<ol> <li>$4</li> <li>$5</li> <li>$6</li> </ol>"},{"location":"temp-prompts-refactored/ui-screenshots/#output-format","title":"Output format","text":"<p>$7</p>"},{"location":"temp-prompts-refactored/ui-screenshots/#affected-files-optional","title":"Affected files (optional)","text":"<ul> <li>List components/files needing changes</li> </ul>"},{"location":"temp-prompts-refactored/ui-screenshots/#root-cause-optional","title":"Root cause (optional)","text":"<ul> <li>Specific UI issues identified</li> </ul>"},{"location":"temp-prompts-refactored/ui-screenshots/#proposed-fix-optional","title":"Proposed fix (optional)","text":"<ul> <li>Concrete implementation changes</li> </ul>"},{"location":"temp-prompts-refactored/ui-screenshots/#test-cases-optional","title":"Test cases (optional)","text":"<ul> <li>Validation criteria for fixes</li> </ul>"},{"location":"temp-prompts-refactored/ui-screenshots/#open-questions-optional","title":"Open questions (optional)","text":"<ul> <li>Unclear requirements or edge cases</li> </ul>"},{"location":"temp-prompts-refactored/update-changelog/","title":"Update changelog","text":"<p><pre><code>&lt;!-- Placeholder mapping --&gt;\n$1 = Trigger command (e.g., \"/update-changelog\")\n$2 = Purpose statement (e.g., \"Generate a user-facing CHANGELOG entry...\")\n$3 = Step 1 description (e.g., \"Inspect repo state:\")\n$4 = Step 2 description (e.g., \"Collect changes:\")\n$5 = Step 3 description (e.g., \"De-dupe and rewrite:\")\n$6 = Step 4 description (e.g., \"Emit Markdown snippet...\")\n$7 = Step 5 description (e.g., \"Decide placement:\")\n\n**How-to: Update CHANGELOG**\n\n$1\n\nPurpose: $2\n\nSteps:\n\n$3\n\n$4\n\n$5\n\n$6\n\n$7\n\nOutput format:\n\n- Heading line with target section (Unreleased or version)\n- Six-section block in Markdown with only non-empty sections in order: Added, Changed, Deprecated, Removed, Fixed, Security\n- A short \"Link references\" block suggestion for `[Unreleased]` and new version comparison links\n- A unified diff (context 3) for `CHANGELOG.md`\n\nExamples:\n\nInput \u2192\n</code></pre> $8 <pre><code>Output \u2192\n</code></pre> $9 <pre><code>Notes:\n\n- Assumes git repository is available and tags follow SemVer.\n- Keep content end-user focused. Avoid internal file names and refactor notes.\n- If no Conventional Commits, infer section from message heuristics.\n- Do not include secrets or internal ticket links.\n</code></pre></p>"},{"location":"temp-prompts-refactored/version-control-guide/","title":"Version Control Guide","text":"<p>Trigger: $1</p> <p>Purpose: Enforce clean incremental commits and clean-room re-implementation when finalizing.</p>"},{"location":"temp-prompts-refactored/version-control-guide/#steps","title":"Steps","text":"<p>$2</p>"},{"location":"temp-prompts-refactored/version-control-guide/#output-format","title":"Output format","text":"<p>$3</p>"},{"location":"temp-prompts-refactored/version-control-guide/#examples","title":"Examples","text":"<p>$4</p>"},{"location":"temp-prompts-refactored/version-control-guide/#notes","title":"Notes","text":"<p>$5</p>"},{"location":"temp-prompts-refactored/version-proposal/","title":"Version Proposal","text":"<p>Trigger: $1</p> <p>Purpose: $2</p> <p>You are a CLI assistant focused on helping contributors with the task: $3</p> <ol> <li>Gather context by running <code>git describe --tags --abbrev=0</code> for the last tag; running <code>git log --pretty='%s' --no-merges $(git describe --tags --abbrev=0)..HEAD</code> for the commits since last tag (no merges).</li> <li>Given the Conventional Commit history since the last tag, propose the next SemVer and justify why.</li> <li>Synthesize the insights into the requested format with clear priorities and next steps.</li> </ol> <p>Output: - Begin with a concise summary that restates the goal: $4 - Offer prioritized, actionable recommendations with rationale. - Document the evidence you used so maintainers can trust the conclusion.</p> <p>Example Input: $5</p> <p>Expected Output: - Structured report following the specified sections.</p>"},{"location":"temp-prompts-refactored/voice-input/","title":"Voice input","text":"<p>Voice Input Template</p> <p>Trigger: $2</p> <p>Purpose: $3</p>"},{"location":"temp-prompts-refactored/voice-input/#steps","title":"Steps","text":"<ol> <li>$4</li> <li>Normalize to tasks or commands for other prompts.</li> <li>Preserve speaker intents and important entities.</li> </ol>"},{"location":"temp-prompts-refactored/voice-input/#key-entities","title":"Key entities","text":"<p>(e.g., speaker intent, command type, entities)</p>"},{"location":"temp-prompts-refactored/voice-input/#expected-output","title":"Expected output","text":"<p>$5</p>"}]}