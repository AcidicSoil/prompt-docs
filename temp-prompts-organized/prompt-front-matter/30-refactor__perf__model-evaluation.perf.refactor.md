# Model Evaluation

## Metadata

- identifier: model-evaluation  
- category: evaluation  
- stage: analyze  
- dependencies: []  
- provided_artifacts: 
  - summary table  
  - adoption recommendations  
- summary: Evaluate models against a baseline to achieve comparative performance insights.

## Steps

1. Define a benchmark set from recent tasks.
2. Run candidates and collect outputs and metrics.
3. Analyze failures and summarize where each model excels.

## Output format

- Summary table and recommendations to adopt or not.
